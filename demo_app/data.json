[{"model": "contenttypes.contenttype", "pk": 1, "fields": {"app_label": "admin", "model": "logentry"}}, {"model": "contenttypes.contenttype", "pk": 2, "fields": {"app_label": "auth", "model": "permission"}}, {"model": "contenttypes.contenttype", "pk": 3, "fields": {"app_label": "auth", "model": "group"}}, {"model": "contenttypes.contenttype", "pk": 4, "fields": {"app_label": "auth", "model": "user"}}, {"model": "contenttypes.contenttype", "pk": 5, "fields": {"app_label": "contenttypes", "model": "contenttype"}}, {"model": "contenttypes.contenttype", "pk": 6, "fields": {"app_label": "sessions", "model": "session"}}, {"model": "contenttypes.contenttype", "pk": 7, "fields": {"app_label": "yacms", "model": "cmspaths"}}, {"model": "contenttypes.contenttype", "pk": 8, "fields": {"app_label": "yacms", "model": "cmstags"}}, {"model": "contenttypes.contenttype", "pk": 9, "fields": {"app_label": "yacms", "model": "cmsmarkups"}}, {"model": "contenttypes.contenttype", "pk": 10, "fields": {"app_label": "yacms", "model": "cmscontents"}}, {"model": "contenttypes.contenttype", "pk": 11, "fields": {"app_label": "yacms", "model": "cmstemplates"}}, {"model": "contenttypes.contenttype", "pk": 12, "fields": {"app_label": "yacms", "model": "cmspagetypes"}}, {"model": "contenttypes.contenttype", "pk": 13, "fields": {"app_label": "yacms", "model": "cmsentries"}}, {"model": "contenttypes.contenttype", "pk": 14, "fields": {"app_label": "mycms", "model": "cmscontents"}}, {"model": "contenttypes.contenttype", "pk": 15, "fields": {"app_label": "mycms", "model": "cmsentries"}}, {"model": "contenttypes.contenttype", "pk": 16, "fields": {"app_label": "mycms", "model": "cmsmarkups"}}, {"model": "contenttypes.contenttype", "pk": 17, "fields": {"app_label": "mycms", "model": "cmspagetypes"}}, {"model": "contenttypes.contenttype", "pk": 18, "fields": {"app_label": "mycms", "model": "cmspaths"}}, {"model": "contenttypes.contenttype", "pk": 19, "fields": {"app_label": "mycms", "model": "cmstags"}}, {"model": "contenttypes.contenttype", "pk": 20, "fields": {"app_label": "mycms", "model": "cmstemplates"}}, {"model": "contenttypes.contenttype", "pk": 21, "fields": {"app_label": "authtoken", "model": "token"}}, {"model": "sessions.session", "pk": "0re6hvxdvwmozw5yrg6t4g9dexqbouvg", "fields": {"session_data": "NTJiNGI0ZTI2OTVlZWVmMjkxNTU4NjlhNjQ2N2U0M2I2M2RkODllNTp7Il9hdXRoX3VzZXJfaWQiOiIyIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJkNGM1ZTkzZjY1Y2U4ZDhmZTdkYzU5YzkzMmEyMTc4ZTkzNjlmMzQyIn0=", "expire_date": "2018-04-17T16:14:49.723Z"}}, {"model": "sessions.session", "pk": "3sju4w3jl51mce58pmy4feqhjxpes6iy", "fields": {"session_data": "NTUxZTNkMWQyYTE4NGViYzZiYzg0NjhjZDNkYzgzZTNjYjViZmUxNDp7Il9hdXRoX3VzZXJfaWQiOiIyIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIwMTQ1YzA1NmZlMGI3YjhmZDY1ZDcxZDY3YzZlYzVhMmI2MTA3YTQ2In0=", "expire_date": "2018-03-22T13:19:08.915Z"}}, {"model": "sessions.session", "pk": "89v1yvw2sltvne84wg4ll0bhduaj0au0", "fields": {"session_data": "NTJiNGI0ZTI2OTVlZWVmMjkxNTU4NjlhNjQ2N2U0M2I2M2RkODllNTp7Il9hdXRoX3VzZXJfaWQiOiIyIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJkNGM1ZTkzZjY1Y2U4ZDhmZTdkYzU5YzkzMmEyMTc4ZTkzNjlmMzQyIn0=", "expire_date": "2018-04-10T15:24:42.280Z"}}, {"model": "sessions.session", "pk": "a95ms9on2xliar8a7dmqeo159djlxwz8", "fields": {"session_data": "NmNhYmI2ODhlODJmN2M0NjE5NWRlYTY0M2UxZTlhZDdlYTk0NDYzNDp7Il9hdXRoX3VzZXJfaGFzaCI6IjE2ZGYyZjY1YTliZDAwYjc1N2Q0MjQ4ODM0ODlkZDE2Mjg5YTgxZWMiLCJfYXV0aF91c2VyX2lkIjoiMSIsIl9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIn0=", "expire_date": "2016-04-29T09:57:56.787Z"}}, {"model": "sessions.session", "pk": "agauvgixxt71f0ml1fu8o4gv4wsoetnh", "fields": {"session_data": "ZjAxZGVhMWEwNDhiOWQzM2I3NDcxZGE0YzhiOTk3YWQwZWUyYTVlYjp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJmNTVjNmY3ZGRkOGM3YTRlOWM0ZDIwZGY1ZmU4NTBkMjMwZTY3YjQ3In0=", "expire_date": "2018-04-25T17:16:05.217Z"}}, {"model": "sessions.session", "pk": "c7zu870736pc5vb34v0nuayrwd7gfm34", "fields": {"session_data": "MjE0OGFiZDE2MGFmZTFjNDdmZDI3MWMzODI5YzhjNGY0OWEzZjJlNTp7Il9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIiwiX2F1dGhfdXNlcl9oYXNoIjoiMTZkZjJmNjVhOWJkMDBiNzU3ZDQyNDg4MzQ4OWRkMTYyODlhODFlYyIsIl9hdXRoX3VzZXJfaWQiOiIxIn0=", "expire_date": "2016-04-25T09:54:16.092Z"}}, {"model": "sessions.session", "pk": "e2sp74alzn28697mk5s6krx36gidzvl5", "fields": {"session_data": "MTJlMDVjOWMyZGI5OTE0YmQyMWE3MDQ2ZGJiMzRkMGMzNjNmMzFlMDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIwMjFkYjNjZmU2MjUwNWRkMGUzMjA5Y2UwZTNlZDlkYmQ0YTdhOThlIn0=", "expire_date": "2017-09-25T18:39:57.660Z"}}, {"model": "sessions.session", "pk": "gu0pm01g0cfqqn3mxk8zq4ip0n21dul0", "fields": {"session_data": "OGQ1MWI1NGNjZWE3ZWE2ZDU5ZmZkMTgwNmQ4MWY5ZGE2YjUwNDFhZTp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9oYXNoIjoiMTZkZjJmNjVhOWJkMDBiNzU3ZDQyNDg4MzQ4OWRkMTYyODlhODFlYyIsIl9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIn0=", "expire_date": "2016-05-13T14:10:44.241Z"}}, {"model": "sessions.session", "pk": "h4sf9u3l62tcuzdlesk1pq4wlr2hy5wm", "fields": {"session_data": "ZWRiZDk2NTE3YmJhOTU4ODc0NjEyYzUxY2IyM2Q5NWRiZDc5OTY5ODp7Il9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIiwiX2F1dGhfdXNlcl9oYXNoIjoiMmFlZGQxMWM0ZGU5MGFjNDRjM2Q3NWQwNGZjMWIyMjE3ZjlmN2ExZSIsIl9hdXRoX3VzZXJfaWQiOiIxIn0=", "expire_date": "2017-03-01T20:44:23.206Z"}}, {"model": "sessions.session", "pk": "ke5n01gmy5ai08e1hh80gq3see040ezj", "fields": {"session_data": "NTJiNGI0ZTI2OTVlZWVmMjkxNTU4NjlhNjQ2N2U0M2I2M2RkODllNTp7Il9hdXRoX3VzZXJfaWQiOiIyIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJkNGM1ZTkzZjY1Y2U4ZDhmZTdkYzU5YzkzMmEyMTc4ZTkzNjlmMzQyIn0=", "expire_date": "2018-03-23T17:36:10.829Z"}}, {"model": "sessions.session", "pk": "nsgsehpn6vvog1obs4leadqvoi68b1u4", "fields": {"session_data": "OGQ1MWI1NGNjZWE3ZWE2ZDU5ZmZkMTgwNmQ4MWY5ZGE2YjUwNDFhZTp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9oYXNoIjoiMTZkZjJmNjVhOWJkMDBiNzU3ZDQyNDg4MzQ4OWRkMTYyODlhODFlYyIsIl9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIn0=", "expire_date": "2016-05-06T18:33:17.117Z"}}, {"model": "sessions.session", "pk": "rbyvmccs84jtt8k1g294yb1ix8v92luq", "fields": {"session_data": "NTJiNGI0ZTI2OTVlZWVmMjkxNTU4NjlhNjQ2N2U0M2I2M2RkODllNTp7Il9hdXRoX3VzZXJfaWQiOiIyIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJkNGM1ZTkzZjY1Y2U4ZDhmZTdkYzU5YzkzMmEyMTc4ZTkzNjlmMzQyIn0=", "expire_date": "2018-04-08T09:17:21.016Z"}}, {"model": "sessions.session", "pk": "trglo1s3k2zd5pg1plv7fgzdv65w4lqm", "fields": {"session_data": "MTJlMDVjOWMyZGI5OTE0YmQyMWE3MDQ2ZGJiMzRkMGMzNjNmMzFlMDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIwMjFkYjNjZmU2MjUwNWRkMGUzMjA5Y2UwZTNlZDlkYmQ0YTdhOThlIn0=", "expire_date": "2017-09-24T19:31:20.528Z"}}, {"model": "sessions.session", "pk": "v5yuz1yky6is368jnv450m6mhz16r8sz", "fields": {"session_data": "MjU2NTgxMmIyM2ExODFkM2ZjODRlMjUwZTI4OGQ5NWRhYWViMjkzYzp7Il9hdXRoX3VzZXJfaGFzaCI6IjE2ZGYyZjY1YTliZDAwYjc1N2Q0MjQ4ODM0ODlkZDE2Mjg5YTgxZWMiLCJfYXV0aF91c2VyX2JhY2tlbmQiOiJkamFuZ28uY29udHJpYi5hdXRoLmJhY2tlbmRzLk1vZGVsQmFja2VuZCIsIl9hdXRoX3VzZXJfaWQiOiIxIn0=", "expire_date": "2016-04-23T21:35:23.190Z"}}, {"model": "sessions.session", "pk": "wkzrdulsbm9604w4wxxpdlj6rlqo3u0a", "fields": {"session_data": "NTJiNGI0ZTI2OTVlZWVmMjkxNTU4NjlhNjQ2N2U0M2I2M2RkODllNTp7Il9hdXRoX3VzZXJfaWQiOiIyIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJkNGM1ZTkzZjY1Y2U4ZDhmZTdkYzU5YzkzMmEyMTc4ZTkzNjlmMzQyIn0=", "expire_date": "2018-04-10T15:26:57.838Z"}}, {"model": "sessions.session", "pk": "wxnswzj9403mfbtlakh0g1d2s4uw0ytp", "fields": {"session_data": "MTJlMDVjOWMyZGI5OTE0YmQyMWE3MDQ2ZGJiMzRkMGMzNjNmMzFlMDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIwMjFkYjNjZmU2MjUwNWRkMGUzMjA5Y2UwZTNlZDlkYmQ0YTdhOThlIn0=", "expire_date": "2017-09-18T10:36:20.636Z"}}, {"model": "sessions.session", "pk": "x5nfsdadl3o1usvzjqlboa9vq96nqjym", "fields": {"session_data": "NjFmMWIwMjlkMGNlMDlkZTQ2YjA3NmE2MDIxN2I1M2FlZDUxNjQ1OTp7Il9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIiwiX2F1dGhfdXNlcl9pZCI6IjEiLCJfYXV0aF91c2VyX2hhc2giOiIyYWVkZDExYzRkZTkwYWM0NGMzZDc1ZDA0ZmMxYjIyMTdmOWY3YTFlIn0=", "expire_date": "2017-04-04T20:16:55.294Z"}}, {"model": "sessions.session", "pk": "xie1b5cm1iwisewj6cen6fypu9uo1eem", "fields": {"session_data": "MTJlMDVjOWMyZGI5OTE0YmQyMWE3MDQ2ZGJiMzRkMGMzNjNmMzFlMDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIwMjFkYjNjZmU2MjUwNWRkMGUzMjA5Y2UwZTNlZDlkYmQ0YTdhOThlIn0=", "expire_date": "2017-10-02T13:24:59.732Z"}}, {"model": "sessions.session", "pk": "ya5d3mr1i9tjlws9370rsmcphc2wss7j", "fields": {"session_data": "NjFmMWIwMjlkMGNlMDlkZTQ2YjA3NmE2MDIxN2I1M2FlZDUxNjQ1OTp7Il9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIiwiX2F1dGhfdXNlcl9pZCI6IjEiLCJfYXV0aF91c2VyX2hhc2giOiIyYWVkZDExYzRkZTkwYWM0NGMzZDc1ZDA0ZmMxYjIyMTdmOWY3YTFlIn0=", "expire_date": "2016-05-21T18:57:11.112Z"}}, {"model": "sessions.session", "pk": "ybsezaptrblqk32a4ooa01aqc59zrgmt", "fields": {"session_data": "NTJiNGI0ZTI2OTVlZWVmMjkxNTU4NjlhNjQ2N2U0M2I2M2RkODllNTp7Il9hdXRoX3VzZXJfaWQiOiIyIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJkNGM1ZTkzZjY1Y2U4ZDhmZTdkYzU5YzkzMmEyMTc4ZTkzNjlmMzQyIn0=", "expire_date": "2018-04-19T13:39:36.851Z"}}, {"model": "sessions.session", "pk": "z9312bazazm4ja3c6nv77qbr38ekohfd", "fields": {"session_data": "OGQ1MWI1NGNjZWE3ZWE2ZDU5ZmZkMTgwNmQ4MWY5ZGE2YjUwNDFhZTp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9oYXNoIjoiMTZkZjJmNjVhOWJkMDBiNzU3ZDQyNDg4MzQ4OWRkMTYyODlhODFlYyIsIl9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIn0=", "expire_date": "2016-05-20T13:05:32.335Z"}}, {"model": "mycms.cmspaths", "pk": 1, "fields": {"path": "/", "parent": null}}, {"model": "mycms.cmspaths", "pk": 2, "fields": {"path": "/sysadmin", "parent": 1}}, {"model": "mycms.cmspaths", "pk": 3, "fields": {"path": "/programming", "parent": 1}}, {"model": "mycms.cmspaths", "pk": 4, "fields": {"path": "/blog", "parent": 1}}, {"model": "mycms.cmspaths", "pk": 5, "fields": {"path": "/sysadmin/linux", "parent": 2}}, {"model": "mycms.cmspaths", "pk": 6, "fields": {"path": "/about", "parent": 1}}, {"model": "mycms.cmspaths", "pk": 7, "fields": {"path": "/sysadmin/linux/lvm-resources", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 8, "fields": {"path": "/sysadmin/linux/lvm-resources/create-a-new-lvm-partition-on-an-extra-disk", "parent": 7}}, {"model": "mycms.cmspaths", "pk": 9, "fields": {"path": "/sysadmin/linux/top-ten-linux-commands-to-check-hardware-information-on-linux", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 10, "fields": {"path": "/sysadmin/linux/how-to-create-an-init-script-for-redhat-or-centos-or-fedora", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 11, "fields": {"path": "/sysadmin/linux/label-a-linux-partition", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 12, "fields": {"path": "/sysadmin/linux/how-to-recover-root-password-under-centos-with-single-user-mode", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 13, "fields": {"path": "/sysadmin/linux/how-to-setup-crontab-under-linux-or-unix", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 14, "fields": {"path": "/sysadmin/linux/how-to-check-swap-usage-on-linux", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 15, "fields": {"path": "/sysadmin/linux/how-to-list-all-hidden-files-in-a-directory-recursively", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 16, "fields": {"path": "/sysadmin/linux/rhel", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 17, "fields": {"path": "/sysadmin/linux/rhel/howto-change-add-remove-luks-passphrases", "parent": 16}}, {"model": "mycms.cmspaths", "pk": 18, "fields": {"path": "/sysadmin/linux/rhel/howto-configure-luks-on-centos--rhel", "parent": 16}}, {"model": "mycms.cmspaths", "pk": 19, "fields": {"path": "/sysadmin/linux/mail-server-administration", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 20, "fields": {"path": "/sysadmin/linux/mail-server-administration/postfix-store-and-foreward-howto-with-anti-spam-configuration", "parent": 19}}, {"model": "mycms.cmspaths", "pk": 21, "fields": {"path": "/sysadmin/linux/systemd", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 22, "fields": {"path": "/sysadmin/linux/systemd/switch-from-networkmanager-to-systemd-networkd-on-linux", "parent": 21}}, {"model": "mycms.cmspaths", "pk": 23, "fields": {"path": "/sysadmin/os-x", "parent": 2}}, {"model": "mycms.cmspaths", "pk": 24, "fields": {"path": "/sysadmin/os-x/installing-nginx-and-php-on-os-x", "parent": 23}}, {"model": "mycms.cmspaths", "pk": 25, "fields": {"path": "/sysadmin/os-x/install-nodejs-and-npm-using-homebrew-on-os-x", "parent": 23}}, {"model": "mycms.cmspaths", "pk": 26, "fields": {"path": "/programming/bash", "parent": 3}}, {"model": "mycms.cmspaths", "pk": 27, "fields": {"path": "/programming/javascript", "parent": 3}}, {"model": "mycms.cmspaths", "pk": 28, "fields": {"path": "/programming/python", "parent": 3}}, {"model": "mycms.cmspaths", "pk": 29, "fields": {"path": "/programming/python/programming-in-python", "parent": 28}}, {"model": "mycms.cmspaths", "pk": 30, "fields": {"path": "/programming/python/python-howtos", "parent": 28}}, {"model": "mycms.cmspaths", "pk": 31, "fields": {"path": "/programming/git", "parent": 3}}, {"model": "mycms.cmspaths", "pk": 32, "fields": {"path": "/programming/git/create-and-manage-git-branches", "parent": 31}}, {"model": "mycms.cmspaths", "pk": 33, "fields": {"path": "/sysadmin/linux/rhel/rhcsa-7-exam-guide", "parent": 16}}, {"model": "mycms.cmspaths", "pk": 34, "fields": {"path": "/sysadmin/linux/rhel/rhcsa-7-exam-guide/understand-and-use-essential-tools", "parent": 33}}, {"model": "mycms.cmspaths", "pk": 36, "fields": {"path": "/programming/python/python-design-patterns", "parent": 28}}, {"model": "mycms.cmspaths", "pk": 37, "fields": {"path": "/programming/python/python-design-patterns/publish-subscribe-pattern", "parent": 36}}, {"model": "mycms.cmspaths", "pk": 38, "fields": {"path": "/programming/python/python-design-patterns/observer-pattern", "parent": 36}}, {"model": "mycms.cmspaths", "pk": 39, "fields": {"path": "/sysadmin/linux/rhel/rhcsa-7-exam-guide/operate-running-systems", "parent": 33}}, {"model": "mycms.cmspaths", "pk": 40, "fields": {"path": "/sysadmin/linux/rhel/rhcsa-7-exam-guide/configure-local-storage", "parent": 33}}, {"model": "mycms.cmspaths", "pk": 41, "fields": {"path": "/sysadmin/linux/rhel/rhcsa-7-exam-guide/create-and-configure-file-systems", "parent": 33}}, {"model": "mycms.cmspaths", "pk": 42, "fields": {"path": "/sysadmin/linux/rhel/rhcsa-7-exam-guide/deploy-configure-and-maintain-systems", "parent": 33}}, {"model": "mycms.cmspaths", "pk": 43, "fields": {"path": "/sysadmin/linux/rhel/rhcsa-7-exam-guide/manage-users-and-groups", "parent": 33}}, {"model": "mycms.cmspaths", "pk": 44, "fields": {"path": "/programming/python/python-design-patterns/the-singleton-design-pattern", "parent": 36}}, {"model": "mycms.cmspaths", "pk": 45, "fields": {"path": "/sysadmin/linux/rhel/rhcsa-7-exam-objective-tutorials", "parent": 16}}, {"model": "mycms.cmspaths", "pk": 46, "fields": {"path": "/sysadmin/linux/rhel/rhcsa-7-exam-objective-tutorials/archiving", "parent": 45}}, {"model": "mycms.cmspaths", "pk": 47, "fields": {"path": "/sysadmin/linux/a-close-look-at-the-systemd-boot-process", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 48, "fields": {"path": "/sysadmin/puppet-cookbook", "parent": 2}}, {"model": "mycms.cmspaths", "pk": 49, "fields": {"path": "/sysadmin/puppet-cookbook/puppet-apply-a-local-manifest-or--module", "parent": 48}}, {"model": "mycms.cmspaths", "pk": 50, "fields": {"path": "/sysadmin/linux/dns-servers", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 51, "fields": {"path": "/sysadmin/linux/dns-servers/how-to-configure-bind-for-your-internal-network", "parent": 50}}, {"model": "mycms.cmspaths", "pk": 52, "fields": {"path": "/sysadmin/linux/rhel/linux--acls---access-control-lists", "parent": 16}}, {"model": "mycms.cmspaths", "pk": 53, "fields": {"path": "/sysadmin/linux/logging-user-actions-with-audit", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 54, "fields": {"path": "/sysadmin/linux/how-to-change-timezone-on-a-centos-6-and-7", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 55, "fields": {"path": "/sysadmin/linux/rhel/scheduling-jobs-with-cron-", "parent": 16}}, {"model": "mycms.cmspaths", "pk": 56, "fields": {"path": "/sysadmin/os-x/install-vagrant-on-osx-1011-el-capitan", "parent": 23}}, {"model": "mycms.cmspaths", "pk": 57, "fields": {"path": "/sysadmin/linux/how-to-use-ssh-config-file-for-multiple-ssh-keys", "parent": 5}}, {"model": "mycms.cmspaths", "pk": 58, "fields": {"path": "/sysadmin/databases", "parent": 2}}, {"model": "mycms.cmspaths", "pk": 59, "fields": {"path": "/sysadmin/databases/postgresql", "parent": 58}}, {"model": "mycms.cmspaths", "pk": 60, "fields": {"path": "/sysadmin/databases/postgresql/install-phppgadmin-on-centos-7", "parent": 59}}, {"model": "mycms.cmspaths", "pk": 61, "fields": {"path": "/sysadmin/databases/postgresql/install-postgresql-on-centos-65-via-yum", "parent": 59}}, {"model": "mycms.cmspaths", "pk": 62, "fields": {"path": "/sysadmin/databases/postgresql/howto-backup-and-restore-your-postgresql-databases", "parent": 59}}, {"model": "mycms.cmspaths", "pk": 63, "fields": {"path": "/sysadmin/virtualisation", "parent": 2}}, {"model": "mycms.cmspaths", "pk": 64, "fields": {"path": "/sysadmin/virtualization", "parent": 2}}, {"model": "mycms.cmspaths", "pk": 65, "fields": {"path": "/sysadmin/virtualization/vmware", "parent": 64}}, {"model": "mycms.cmspaths", "pk": 66, "fields": {"path": "/sysadmin/virtualization/vmware/kvm", "parent": 65}}, {"model": "mycms.cmspaths", "pk": 67, "fields": {"path": "/sysadmin/virtualization/vmware/kvm/install-vmware-on-esxi-in-kvm", "parent": 66}}, {"model": "mycms.cmspaths", "pk": 68, "fields": {"path": "/sysadmin/virtualization/vmware/kvm/add-extra-space-to-kvm-guest-root-partition", "parent": 66}}, {"model": "mycms.cmspaths", "pk": 69, "fields": {"path": "/sysadmin/virtualization/vmware/kvm/install-kvm-guest-using-command-line", "parent": 66}}, {"model": "mycms.cmspaths", "pk": 70, "fields": {"path": "/programming/python/programming-in-python/underscores-in-python", "parent": 29}}, {"model": "mycms.cmspaths", "pk": 71, "fields": {"path": "/programming/python/programming-in-python/signals-and-slots-implementation-in-python", "parent": 29}}, {"model": "mycms.cmspaths", "pk": 72, "fields": {"path": "/blog/my-ramblings-and-stupidity", "parent": 4}}, {"model": "mycms.cmspaths", "pk": 73, "fields": {"path": "/blog/techstuff", "parent": 4}}, {"model": "mycms.cmspaths", "pk": 74, "fields": {"path": "/sysadmin", "parent": 2}}, {"model": "mycms.cmspaths", "pk": 97, "fields": {"path": "/blog/adding-a-test", "parent": 4}}, {"model": "mycms.cmsmarkups", "pk": 1, "fields": {"markup": "Creole"}}, {"model": "mycms.cmscontents", "pk": 1, "fields": {"title": null, "content": "This is the best contents bacause basically what we want to do is to make sure that this is updated properly. \n\n===This is a test\n\n==If you go to court to settle", "timestamp": "2018-03-15T21:07:48.517Z", "markup": 1, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 2, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-09T21:36:11.420Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 3, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-09T21:36:19.816Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 4, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-09T21:36:42.214Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 5, "fields": {"title": null, "content": "==What is jnvilo.com?\n\njnvilo.com is a technology sysadmin resource website and is also my (Jason Viloria) personal website. It started out as a cgi script written in perl , storing the blog entries in text files under the domain name jasonlinux.com. I wrote the first iteration of jasonlinux.com in 2002 and then migrated to jnvilo.com in 2007. In the course of a decade, I moved from perl, to php and now currently python. I have removed much of the old contents keeping only the latest years updates so in effect this is a new website.\n\n==What does jnvilo stand for?\n\njnvilo is an abbreviation of my name and surname concatinated together. It was my first unix account name. In 1996 I was given a unix account at the university of Malta and the account was \"jnvilo\". I don't use it anymore as a username of course so there is no need to try brute forcing any servers you think I have access to with that username.\n\n==What is your motivation for maintaining this website?\n\nI am a sysadmin throughout my career although nowadays I do more system architecture design and deployment rather than daily sysadmin operations work. As a result since I started I have always kept some form of documentation website or wiki. This website serves as my wiki. Also I have always been a wannabe webmaster and developer. I actually spend a lot of time as a python developer at my workplace nowadays, writing python code to maintain our in house cloud infrastructure and automation. JNVILO.,com acts as a pet project where I try out webdev. It runs on a custom cms.", "timestamp": "2016-04-09T21:38:03.873Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 6, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-09T21:39:37.675Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 7, "fields": {"title": null, "content": "This article deals with showing how to configure a second disk using LVM. This could be for example in a situation where the server currently has 1 disk but no LVM configured and now you have added a second disk. The examples use KVM virtual machine hence the device names are vd* while if you were using vmware or physical disks they would be sd* .\n\n== Create a partition on the new disk using fdisk. \n\nThe first thing we do is to create a partition on the new disk using fdisk. \n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# fdisk /dev/vdc\nDevice contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabel\nBuilding a new DOS disklabel with disk identifier 0x1b480d00.\nChanges will remain in memory only, until you decide to write them.\nAfter that, of course, the previous content won't be recoverable.\n\nWarning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)\n\nWARNING: DOS-compatible mode is deprecated. It's strongly recommended to\n         switch off the mode (command 'c') and change display units to\n         sectors (command 'u').\n\nCommand (m for help): p\n\nDisk /dev/vdc: 8589 MB, 8589934592 bytes\n16 heads, 63 sectors/track, 16644 cylinders\nUnits = cylinders of 1008 * 512 = 516096 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x1b480d00\n\n   Device Boot      Start         End      Blocks   Id  System\n\nCommand (m for help): n\nCommand action\n   e   extended\n   p   primary partition (1-4)\np\nPartition number (1-4): 1\nFirst cylinder (1-16644, default 1): \nUsing default value 1\nLast cylinder, +cylinders or +size{K,M,G} (1-16644, default 16644): \nUsing default value 16644\n\nCommand (m for help): t\nSelected partition 1\nHex code (type L to list codes): 8e\nChanged system type of partition 1 to 8e (Linux LVM)\n\nCommand (m for help): w\nThe partition table has been altered!\n\nCalling ioctl() to re-read partition table.\nSyncing disks.\n[root@rhel-lab1 ~]#\n\n<</code>>\n\nIn the above, once fdisk is launched, press p and then 1 to create the partition and I have accepted the default start and size of the partition [using the whole disk] and then pressed *t* to set the type of the partition to *8e*\n\n\n== Create Physical Volume \n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# pvcreate /dev/vdc1 \n  Physical volume \"/dev/vdc1\" successfully created\n<</code>>\n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# pvdisplay /dev/vdc1\n  \"/dev/vdc1\" is a new physical volume of \"8.00 GiB\"\n  --- NEW Physical volume ---\n  PV Name               /dev/vdc1\n  VG Name               \n  PV Size               8.00 GiB\n  Allocatable           NO\n  PE Size               0   \n  Total PE              0\n  Free PE               0\n  Allocated PE          0\n  PV UUID               fUnT5I-wL5j-u8nN-cTD4-oMPu-0Ff5-zKKWJe\n <</code>>\n\n==Create a new Volume Group\nIn this example we want to create a new volume group. [For example in the case where there is no volume groups yet]\n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# vgcreate VolumeGroupHome /dev/vdc1 \n  Volume group \"VolumeGroupHome\" successfully created\n<</code>>\n\nWe can examine the newly created VolumeGroup as:\n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# vgdisplay VolumeGroupHome\n  --- Volume group ---\n  VG Name               VolumeGroupHome\n  System ID             \n  Format                lvm2\n  Metadata Areas        1\n  Metadata Sequence No  1\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                0\n  Open LV               0\n  Max PV                0\n  Cur PV                1\n  Act PV                1\n  VG Size               8.00 GiB\n  PE Size               4.00 MiB\n  Total PE              2047\n  Alloc PE / Size       0 / 0   \n  Free  PE / Size       2047 / 8.00 GiB\n  VG UUID               Tzd0l6-A4Ji-zR9n-cjGx-2ou3-EggK-2xDJWK\n<</code>>\n\n==The final step is to create the Logical Volume \n<<code ext=bash>>\n[root@rhel-lab1 ~]# lvcreate -L 2G -n lv_home VolumeGroupHome\n  Logical volume \"lv_home\" created\n<</code>>", "timestamp": "2018-03-16T08:24:09.529Z", "markup": 1, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 8, "fields": {"title": null, "content": "Am sure you know this already, there are a lot of commands  to check information about the hardware of a system running linux.  There are also some GUI tools that consolidates them all but in this article we shall look at my favourite ten command line tools that we can use to find the hardware information.  The list includes lscpu, hwinfo, lshw, dmidecode, lspci etc.\n\n==1. lscpu\nIf we want to find out anything about our CPU, then lscpu is the command to run. True to unix philosophy, it does only one thing. It has no other features.\n\n<<code>>\n[jnvilo@linuxbox~] $ lscpu\nArchitecture:          x86_64\nCPU op-mode(s):        32-bit, 64-bit\nByte Order:            Little Endian\nCPU(s):                2\nOn-line CPU(s) list:   0,1\nThread(s) per core:    1\nCore(s) per socket:    1\nSocket(s):             2\nNUMA node(s):          1\nVendor ID:             GenuineIntel\nCPU family:            6\nModel:                 42\nModel name:            Intel(R) Core(TM) i5-2500S CPU @ 2.70GHz\nStepping:              7\nCPU MHz:               2700.032\nBogoMIPS:              5400.06\nVirtualization:        VT-x\nHypervisor vendor:     VMware\nVirtualization type:   full\nL1d cache:             32K\nL1i cache:             32K\nL2 cache:              256K\nL3 cache:              6144K\nNUMA node0 CPU(s):     0,1\n<</code>>\n\n==2. lshw - List Hardware\nA very short command that can tell you a lot of information about your hardware. lshw gets all its information from /proc.  Unlike lscpu, lshw has a number of interesting options. \n\n<<code>>\n[root@macfedora ~] $ lshw --help\nHardware Lister (lshw) - B.02.17\nusage: lshw [-format] [-options ...]\n       lshw -version\n\n\t-version        print program version (B.02.17)\n\nformat can be\n\t-html           output hardware tree as HTML\n\t-xml            output hardware tree as XML\n\t-short          output hardware paths\n\t-businfo        output bus information\n\t-X              use graphical interface\n\noptions can be\n\t-dump OUTFILE   save hardware tree to a file\n\t-class CLASS    only show a certain class of hardware\n\t-C CLASS        same as '-class CLASS'\n\t-c CLASS        same as '-class CLASS'\n\t-disable TEST   disable a test (like pci, isapnp, cpuid, etc. )\n\t-enable TEST    enable a test (like pci, isapnp, cpuid, etc. )\n\t-quiet          don't display status\n\t-sanitize       sanitize output (remove sensitive information like serial numbers, etc.)\n\t-numeric        output numeric IDs (for PCI, USB, etc.)\n<</code>>\n\n== 4. lspci - List PCI\nThe lspci command lists out all the pci buses and details about the devices connected to them.\nThe vga adapter, graphics card, network adapter, usb ports, sata controllers, etc all fall under this category.\n\nBelow is the output from a small vm running fedora on a mac host.\n<<code>>\n[root@macfedora ~] $ lspci\n00:00.0 Host bridge: Intel Corporation 440BX/ZX/DX - 82443BX/ZX/DX Host bridge (rev 01)\n00:01.0 PCI bridge: Intel Corporation 440BX/ZX/DX - 82443BX/ZX/DX AGP bridge (rev 01)\n00:07.0 ISA bridge: Intel Corporation 82371AB/EB/MB PIIX4 ISA (rev 08)\n00:07.1 IDE interface: Intel Corporation 82371AB/EB/MB PIIX4 IDE (rev 01)\n00:07.3 Bridge: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)\n00:07.7 System peripheral: VMware Virtual Machine Communication Interface (rev 10)\n00:0f.0 VGA compatible controller: VMware SVGA II Adapter\n00:10.0 SCSI storage controller: LSI Logic / Symbios Logic 53c1030 PCI-X Fusion-MPT Dual Ultra320 SCSI (rev 01)\n00:11.0 PCI bridge: VMware PCI bridge (rev 02)\n00:15.0 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:15.1 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:15.2 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:15.3 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:15.4 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:15.5 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:15.6 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:15.7 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:16.0 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:16.1 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:16.2 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:16.3 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:16.4 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:16.5 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:16.6 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:16.7 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:17.0 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:17.1 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:17.2 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:17.3 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:17.4 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:17.5 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:17.6 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:17.7 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:18.0 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:18.1 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:18.2 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:18.3 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:18.4 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:18.5 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:18.6 PCI bridge: VMware PCI Express Root Port (rev 01)\n00:18.7 PCI bridge: VMware PCI Express Root Port (rev 01)\n02:00.0 USB controller: VMware USB1.1 UHCI Controller\n02:01.0 Ethernet controller: Intel Corporation 82545EM Gigabit Ethernet Controller (Copper) (rev 01)\n02:02.0 Multimedia audio controller: Ensoniq ES1371 / Creative Labs CT2518 [AudioPCI-97] (rev 02)\n02:03.0 USB controller: VMware USB2 EHCI Controller\n<</code>>\n\n==5. lsscsi - List scsi devices\n\n==6. lsusb - List usb buses and device details\n\n<<code>>\n[root@macfedora ~] $ lsusb\nBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 002 Device 004: ID 0e0f:0008 VMware, Inc. \nBus 002 Device 003: ID 0e0f:0002 VMware, Inc. Virtual USB Hub\nBus 002 Device 002: ID 0e0f:0003 VMware, Inc. Virtual Mouse\nBus 002 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\n<</code>>\n\n==7. dmidecode \nFor a long time, this was the only command I needed to get a peek at the hardware running a linux system. If there is any command that you should know then this is it. The output is too long. I suggest just simply try it out and have a look.\n\n\n==8. lsblk - List block devices\nList Information about your drives and storage. Here is a sample from my fedora vmware box.\n\n<<code>>\n[root@macfedora ~] $ lsblk\nNAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\nsda               8:0    0   20G  0 disk \n\u251c\u2500sda1            8:1    0  500M  0 part /boot\n\u2514\u2500sda2            8:2    0 19.5G  0 part \n  \u251c\u2500fedora-swap 253:0    0    2G  0 lvm  [SWAP]\n  \u2514\u2500fedora-root 253:1    0 17.5G  0 lvm  /\nsr0              11:0    1  1.4G  0 rom  /run/media/jasonviloria/Fedora-Live-WS-x86_64-21-5\n<</code>>\n\n==9. free \n\n==10 fdisk\n\n\n\n==", "timestamp": "2016-04-09T21:46:23.264Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 9, "fields": {"title": null, "content": "Here is a skeleton init.d script for use in RedHat/Centos/Fedora and most probably will also work in any other SystemV init style systems.\n\n<<code ext=bash>>\n#!/bin/bash\n#\n#       /etc/rc.d/init.d/<servicename>\n#\n#       <description of the *service*>\n#       <any general comments about this init script>\n#\n# <tags -- see below for tag definitions.  *Every line* from the top\n#  of the file to the end of the tags section must begin with a #\n#  character.  After the tags section, there should be a blank line.\n#  This keeps normal comments in the rest of the file from being\n#  mistaken for tags, should they happen to fit the pattern.>\n\n# Source function library.\n. /etc/init.d/functions\n\n<define any local shell functions used by the code that follows>\n\nstart() {\n        echo -n \"Starting <servicename>: \"\n        <start daemons, perhaps with the daemon function>\n        touch /var/lock/subsys/<servicename>\n        return <return code of starting daemon>\n}\n\nstop() {\n        echo -n \"Shutting down <servicename>: \"\n        <stop daemons, perhaps with the killproc function>\n        rm -f /var/lock/subsys/<servicename>\n        return <return code of stopping daemon>\n}\n\ncase \"$1\" in\n    start)\n        start\n        ;;\n    stop)\n        stop\n        ;;\n    status)\n        <report the status of the daemons in free-form format,\n        perhaps with the status function>\n        ;;\n    restart)\n        stop\n        start\n        ;;\n    reload)\n        <cause the service configuration to be reread, either with\n        kill -HUP or by restarting the daemons, in a manner similar\n        to restart above>\n        ;;\n    condrestart)\n        <Restarts the servce if it is already running. For example:>\n        [ -f /var/lock/subsys/<service> ] && restart || :\n    probe)\n        <optional.  If it exists, then it should determine whether\n        or not the service needs to be restarted or reloaded (or\n        whatever) in order to activate any changes in the configuration\n        scripts.  It should print out a list of commands to give to\n        $0; see the description under the probe tag below.>\n        ;;\n    *)\n        echo \"Usage: <servicename> {start|stop|status|reload|restart[|probe]\"\n        exit 1\n        ;;\nesac\nexit $?\n<</code>>", "timestamp": "2016-04-09T21:47:44.301Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 10, "fields": {"title": null, "content": "So if you are asking yourself, how do I label a partition,  then here's the answer. You need to use e2label or tune2fs command line to change the label on an ext2/ext3 filesystem. e2label will display or change the filesystem label on the ext2 filesystem located on device.\n\n== Display current label\n\nIf the optional argument new-label is not present, e2label will simply display the current filesystem label.\n<<code ext=bash>>\n$ sudo e2label /dev/sda1\n<</code>>\nor\n<<code ext=bash>>\n# e2label /dev/sda1\n<</code>>\n\nSample output:\n\n<<code ext=bash>>\n/boot\n<</code>>\n\nSet a new label\n\nIf the optional argument new-label is present, then e2label will set the filesystem label to be new-label. Ext2 filesystem labels can be at most 16 characters long; if new-label is longer than 16 characters, e2label will truncate it and print a warning message. To set a new label, enter:\n\n<<code ext=bash>>\n# e2label /dev/sdb2 usbstroage\n<</code>>\n\nIt is also possible to set the filesystem label using the -L option of tune2fs, enter:\n\n<<code ext=bash>>\n# tune2fs -L usbstroage /dev/sdb2\n<</code>>", "timestamp": "2016-04-09T21:49:40.332Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 11, "fields": {"title": null, "content": "It happens sometime that you can't remember root password. On Linux, recovering root password can be done by booting Linux under a specific mode: single user mode.\nThis tutorial will show how to boot Linux in single user mode when using GRUB and finally how to change root password.\n\nDuring normal usage, a Linux OS runs under runlevels between 2 and 5 which corresponds to various multi-user modes. Booting Linux under runlevel 1 will allow one to enter into a specific mode, single user mode. Under such a level, you directly get a root prompt. From there, changing root password is a piece of cake.\n\n===1. Entering Runlevel 1\n\nSome Linux distribution, such as Ubuntu for instance, offer a specific boot menu entry where it is stated \"Recovery Mode\" or \"Single-User Mode\". If this is your case, selecting this menu entry will boot your machine into single user mode, you can carry on with the next part. If not, you might want to read this part.\n\nUsing GRUB, you can manually edit the proposed menu entry at boot time. To do so, when GRUB is presenting the menu list (you might need to press ESC first), follow those instructions:\n\nuse the arrows to select the boot entry you want to modify.\npress e to edit the entry\nuse the arrows to go to kernel line\npress e to edit this entry\nat the end of the line add the word single\npress ESC to go back to the parent menu\npress b to boot this kernel\nThe kernel should be booting as usual (except for the graphical splash screen you might be used to), and you will finally get a root prompt (sh#).\n\nHere we are, we have gained root access to the filesystem, let's finally change the password.\n\n===2. Changing Root Password\n\nAs root, changing password does not ask for your old password, therefore running the command:", "timestamp": "2016-04-09T21:54:03.660Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 12, "fields": {"title": null, "content": "How do I add a cronjob on Linux? Thats a question even some veterans ask all the time, something that is easily forgotten. At times I have forgotten the exact incantation so I wrote this down. I hope it is useful to someone else as it is for me. We use cron jobs to schedule commands to be executed periodically. Entries in the cron can be commands as you would execute them on the command line or they can be scripts. The cron service runs in the background and reads the /etc/crontab and the /etc/cron,* directories. It also checks entries in /var/spool/cron directory. Users also have their own cron. \n\n==Editing cron entries. \n\nAlthough you can edit the files directly with your favourite editor, (vi , emacs, nano.. etc..) you should instead invoke your default system editor using the \"crontab\" command. This will open the file and load up the cron entries and also do other things such as validation on save. Each user can also have their own crontab file. These files are saved in /var/spool/cron/crontabs. Running \"crontab\" as a normal user will open the user's relevant crontab file. \n\n==The linux system crontab vs user crontab\n\n* **/etc/crontab** aka system crontab. This is owned by root and anything placed in here runs as root by default. This is usually for jobs that requires root privileges. However you can also put the user in the 6th field and it will run the command as the user.\n\n* **The user crontabs**: Normal users can not edit the system crontab. However they have their own crontab entries. All commands run as the user who setup the crontab. One could of course use sudo to get around this if they have the sudo rights. \n\n==How Do I Install or create or edit my own cron jobs.\n\n<<code ext=\"bash\">>\ncrontab -e\n<</code>>\n\nThe syntax of crontab is as follows:\n\n<<code ext=\"bash\">>\n1 2 3 4 5 /path/to/command arg1 arg2\n <</code>>\nOR\n<<code ext=\"bash\">>\n1 2 3 4 5 /root/backup.sh\n<</code>>\n\nWhere,\n\n1: Minute (0-59)\n2: Hours (0-23)\n3: Day (0-31)\n4: Month (0-12 [12 == December])\n5: Day of the week(0-7 [7 or 0 == sunday])\n/path/to/command - Script or command name to schedule\nEasy to remember format:\n\n<<code ext=\"bash\">>\n* * * * * command to be executed\n- - - - -\n| | | | |\n| | | | ----- Day of week (0 - 7) (Sunday=0 or 7)\n| | | ------- Month (1 - 12)\n| | --------- Day of month (1 - 31)\n| ----------- Hour (0 - 23)\n------------- Minute (0 - 59)\n<</code>>\n\nYour cron job looks as follows for system jobs:\n\n<<code ext=\"bash\">>\n1 2 3 4 5 USERNAME /path/to/command arg1 arg2\n<</code>>\nOR\n<<code ext=\"bash\">>\n1 2 3 4 5 USERNAME /path/to/script.sh\n<</code>>\n\n==Special operator for time settings.\n\nHow do I use operators?\n\nAn operator allows you to specifying multiple values in a field. There are three operators:\n\n* The asterisk (*) : This operator specifies all possible values for a field. For example, an asterisk in the hour time field would be equivalent to every hour or an asterisk in the month field would be equivalent to every month.\n* The comma (,) : This operator specifies a list of values, for example: \"1,5,10,15,20, 25\".\n* The dash (-) : This operator specifies a range of values, for example: \"5-15\" days , which is equivalent to typing \"5,6,7,8,9,....,13,14,15\" using the comma operator.\n* The separator (/) : This operator specifies a step value, for example: \"0-23/\" can be used in the hours field to specify command execution every other hour. Steps are also permitted after an asterisk, so if you want to say every two hours, just use */2.\n\nhttp://www.cyberciti.biz/faq/how-do-i-add-jobs-to-cron-under-linux-or-unix-oses/", "timestamp": "2016-04-09T21:58:40.708Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 13, "fields": {"title": null, "content": "How do I check swap (paging) usage under Linux operating systems from the command line?Swap space (also known as paging) is nothing but computer memory management involving swapping regions of memory to and from storage. You can see swap usage summary by device using any one of the following commands. You may have to login as root user to use the following commands. The maximum useful size of a swap area depends on the architecture and the kernel version. For Linux kernels after v2.3.3+ there is no such limitation on swap size.\n\n===Method 1: Read /proc/swaps file\n<<code ext=\"bash\">>\n#cat /proc/swaps\n<</code>>\n\nThe output looks something like as follows: \n\n<<code ext=\"bash\">>\nFilename\t\t\t\tType\t\tSize\tUsed\tPriority\n/dev/dm-1                               partition\t8273916\t0\t-1\n<</code>>\n\n===Method 2: free command\n\n<<code ext=\"bash\">>\n# free -g\n# free -k\n# free -m\n\n<</code>>\n", "timestamp": "2016-04-09T22:24:16.457Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 14, "fields": {"title": null, "content": "We were all new to linux at one point and using the find command was the first thing I learnt.  If  you need to find and list all hidden files and directories  You need to use the find command to list all hidden files recursively on a Linux or Unix like systems.\n\n\n=== The basic command is as follows:\n\n<<code ext=\"bash\">>\nfind /dir/to/search/ -name \".*\" -print\n<</code>>\nOR\n\n<<code ext=\"bash\">>\nfind /dir/to/search/ -name \".*\" -ls\n<</code>>\nOR search only hidden files:\n<<code ext=\"bash\">>\nfind /dir/to/search/ -type f -iname \".*\" -ls\n<</code>>\nOR search only hidden directories:\n<<code ext=\"bash\">>\nfind /dir/to/search/ -type d -iname \".*\" -ls\n<</code>>\nOR\n<<code ext=\"bash\">>\nfind /dir/to/search -path '*/.*' -print\nfind /dir/to/search -path '*/.*' -ls\n<</code>>\n\nIn this example, search $HOME for all hidden files and dirs:\n\n<<code ext=\"bash\">>\nfind $HOME -name \".*\" -ls\n <</code>>\n", "timestamp": "2016-04-09T22:26:22.767Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 15, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-09T22:28:32.532Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 16, "fields": {"title": null, "content": "In the article [[http://www.jnvilo.com/cms/sysadmin/linux/rhel/howto-configure-luks-on-centos--rhel| HowTo: Configure Luks On CentsOS/RHEL ]] I wen through setting up encryption on my /home partition. There are a few other things that are needed such as changing the passphrase, or removing it, or even adding another passphrase to be shared with another user of /home. \n\n==Changing LUKS passphrase\n\n<<code ext=bash>>\ntelint 3\numount /home\ncruptsetup luksClose lv_home_encrypted\ncryptsetup luksChangeKey /dev/VolGroupHome/lv_home\n<verify and change your passphrase>\ncryptsetup luksOpen /dev/VolGroupHome/lv_home lv_home_encrypted\nmount /home\n<</code>>\n\n==Add a new LUKS password\n\n<<code ext=bash>>\ncryptsetup luksAddKey /dev/VolGroupHome/lv_home \n< enter any current passphrase and then add the new passphrase when asked >\n<</code>>\n\nNow, let's close and then open the partition to test the new passphrase\n<<code ext=bash>>\numount /home\ncryptsetup luksClose lv_home_encrypted\ncryptsetup luksOpen /dev/VolGroupHome/lv_home lv_home_encrypted\n< enter the new passphrase>>\n<</code>>\n\n\n==Remove LUKS Passphrase\n\n<<code ext=bash>>\numount /home\ncryptsetup luksClose lv_home_encrypted\ncruptsetup luksRemoveKey /dev/VolGroupHome/lv_home \n< enter the passphrase that you want to remove >\n<</code>>\n\nThe passphrase is now removed. Verify by trying to use the passphrase when doing a luksOpen\n\n<<code ext=bash>>\ncryptsetup luksOpen /dev/VolGroupHome/lv_home lv_home_encrypted\n<</code>>\n\n", "timestamp": "2016-04-09T22:29:05.987Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 17, "fields": {"title": null, "content": "LUKS is the standard for Linux hard disk encryption. By providing a standard on-disk-format, it does not only facilitate compatibility among distributions, but also provides secure management of multiple user passwords. If you use a laptop then you are best advised to ensure that at least your home partition is encrypted. This HowTo will show you how to do this for CentOS / RHEL and also applies to Fedora. \n\n\n\n==Summary\nIn this howto we assume we have a laptop with /home mounted at /dev/VolumeGroupHome/lv_home and we have backed up all the contents of this directory and we can wipe it.\n\nHere are the steps in summary for the impatient :\n\n* cryptsetup -y -v luksFormat /dev/xvdc\n* cryptsetup luksOpen /dev/xvdc backup2\n* cryptsetup -v status backup2\n* cryptsetup luksDump /dev/xvdc\n* cryptsetup luksAddKey /dev/xvdc\n* cryptsetup luksRemoveKey /dev/xvdc\n* cryptsetup luksChangeKey /dev/xvdc\n\nThe examples will instead focus on changing an LVM partition \n\n* login as root and make sure nothing is writing to /home so you can unmount it. Alternatively login as root and do the command *telinit 1*\n* umount /home\n* cryptsetup -y -v luksFormat /dev/VolumeGroupHome/lv_home \n* cryptsetup luksOpen /dev/VolumeGroupHome/lv_home lv_home_encrypted\n* mount /dev/mapper/lv_home_encrypted /home\n* edit /etc/crypttab and add  the line:  lv_home_encrypted /dev/mapper/lv_home none \n* update your /etc/fstab to reflect that you should now mount /dev/mapper/lv_home_encrypted instead of lv_home\n* if you have selinux:  /sbin/restorecon -v -R /home\n\n\n== Install the required package. \n\nInstalling is as simple as: \n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# yum install cryptsetup-luks\n<</code>>\n\n== Configure the partition to use LUKS\n\nIn this example I have decided to turn /dev/VolumeGroupHome/lv_home LVM device into an encrypted device. \n\n=== The first step is to format the partition with luksFormat\nwarning: This will totally wipe the partition so make sure that you have a backup. \n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# cryptsetup -y -v luksFormat /dev/VolumeGroupHome/lv_home \n\nWARNING!\n========\nThis will overwrite data on /dev/VolumeGroupHome/lv_home irrevocably.\n\nAre you sure? (Type uppercase yes): YES\nEnter LUKS passphrase: \nVerify passphrase: \nCommand successful.\n<</code>>\n\n=== Next step we initialize and create the mapping. \n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# cryptsetup luksOpen /dev/VolumeGroupHome/lv_home lv_home_encrypted\nEnter passphrase for /dev/VolumeGroupHome/lv_home: \n<</code>>\n\nThe above command maps the /dev/VolumeGroupHome/lv_home as an encrypted device called /dev/mapper/lv_home_encrypted. Note that the passphrase it is asking for is the LUKS passphrase that you setup earlier above. \n\nWe can see the details about the created device as follows:\n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# cryptsetup -v status lv_home_encrypted\n/dev/mapper/lv_home_encrypted is active.\n  type:  LUKS1\n  cipher:  aes-cbc-essiv:sha256\n  keysize: 256 bits\n  device:  /dev/mapper/VolumeGroupHome-lv_home\n  offset:  4096 sectors\n  size:    8384512 sectors\n  mode:    read/write\nCommand successful.\n<</code>>\n\n==Final steps: \n\nThe encrypted device we created must be filled with zeros before we started using it. To do this we use dd. \n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# dd if=/dev/zero of=/dev/mapper/lv_home_encrypted\n<</code>>\n\nThe above command might take a bit of time before finishing. A faster way would be as follows:\n\n<<code ext=bash>>\npv -tpreb /dev/zero | dd of=/dev/mapper/backup2 bs=128M\n<</code>>\n\n=== Finally we format and mount the encrypted partition\n<<code ext=bash>>\nmkfs.ext4 /dev/mapper/lv_home_encrypted\n<</code>>\n\n<</code ext=bash>>\nmount /dev/mapper/lv_home_encrypted /home\n<</code>>\n\n== And before rebooting ensure that our mapped device gets recreated.\n\n<<code ext=bash>>\ndd if=/dev/random of=/root/luks.key bs=32 count=1\ncryptsetup luksAddKey /dev/VolumeGroupHome/lv_home /root/luks.key\necho \"lv_home_encrypted /dev/VolumeGroupHome/lv_home /root/luks.key\" > /etc/crypttab \n<</code>>\n", "timestamp": "2016-04-09T22:31:37.882Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 18, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-09T22:33:29.074Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 19, "fields": {"title": null, "content": "A Postfix store and foreward configuration is needed when setting up a secondary MTA. If your primary MTA is down, then all mails will be sent to the secondary \"store and forward\" postfix server. As the name implies, all emails will be recieved and stored locally until your primary MTA comes back online.  \n\n==Motivation\n\nThe main reasons we want a store and forward server is:\n\n* Redundancy - Even though MTA's will keep retrying to send emails when the destination is unreachable, the sender is notified of this. With a \"store and forward\" postfix server we have a server that acts as a failover. It will happily recieve emails and store them, waiting for your primary MTA to be reachable. \n\n* Security - Using a store and forward, you can hide your internal mail system from the internet.  Your store and forward instances can also be placed in high bandwidth datacenters which can handle spam traffic,  while keeping your main MTA in your office , happily knowing that all emails arriving to it are valid. \n\n* Load Distribution -  Your store and forward servers can be configured to filter emails, remove spam, run antivirus etc.. before accepting to forward an email.\n\n\n==DNS Configuration\n\nEmail for a domain is through the MX record. Let's take cisco.com for example. If I do \"dig mx cisco.com\" I get the following answer:\n\n<<code ext=\"bash\">>\n;; ANSWER SECTION:\ncisco.com.\t\t86400\tIN\tMX\t30 aer-mx-01.cisco.com.\ncisco.com.\t\t86400\tIN\tMX\t10 alln-mx-01.cisco.com.\n<</code>>\n\nThis means cisco has three public MTA , these may or may not be store and forward, but all that we need to know is that according to the numbers on the 5th column, alln-mx-01.cisco.com is the first MTA to be tried, and if that is not accessible then try  aer-mx-01.cisco.com.\n\nSo  as an email admin, you have to create MX records for your domain in a similar manner.\n\n== Enough Talk and Let's Install/Configure Postfix Already!\n\nIn these example, I will be using the scenario where  mail.jnvilo.com is my primary MTA and mail-store.jnvilo.com is the new postfix store and forward server that we are building. Thus we should have the DNS MX records as:\n\n<<code ext=\"bash\">>\n;; ANSWER SECTION:\njnvilo.com.\t\t86400\tIN\tMX\t10 mail.jnvilo.com.\njnvilo.com.\t\t86400\tIN\tMX\t20 mail-store.jnvilo,com.\n<</code>>\n\nAlso, mail.jnvilo.com  handles emails for maltacentral.com and rpmbrew.com . \n\n===1. Install the OS and the required packages.\nI am going to be installing on a Centos 7.0 server. Install intructions are out of the scope but to ensure that you can repeat my steps, i did the following \n\n<<code ext=\"bash\">>\n* yum -y update #Always update the server\n<</code>>\n\nUser your favourite editor [In my case vi] to edit /etc/selinux/config and disable SELINUX for now. You can enable it again once you know everything is working and setup your selinux rules to fix any denials. \n<<code ext=\"bash\">>\n# This file controls the state of SELinux on the system.\n# SELINUX= can take one of these three values:\n#     enforcing - SELinux security policy is enforced.\n#     permissive - SELinux prints warnings instead of enforcing.\n#     disabled - No SELinux policy is loaded.\nSELINUX=enforcing\n# SELINUXTYPE= can take one of these two values:\n#     targeted - Targeted processes are protected,\n#     minimum - Modification of targeted policy. Only selected processes are protected. \n#     mls - Multi Level Security protection.\nSELINUXTYPE=targeted \n<</code>>\n\nand change the line: \n<<code ext=\"bash\">>\nSELINUX=enforcing\n<</code>>\n\nto:\n<<code ext=\"bash\">>\nSELINUX=enforcing\n<</code>>\n\nEnsure you have in your hosts file , the IP of the server.\n<<code ext=\"bash\">>\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.100.1   mail-store.jnvilo.com  mail-store\n<</code>>\n\nAnd also ensure that hostname is set properly. \n<<code ext=\"bash\">>\n[root@mail-store ~]$ hostname \nmail-store.jnvilo.com\n<</code>>\n\nCentos7 ships with firewalld which may have incoming port 25 closed. Make sure this is open.\n<<code ext=\"bash\">>\n\n<</code>>\n\n===2. Install the required packages.\n\n<<code>> \nyum -y install postfix \nsystemctl enable postfix\nsystemctl restart postfix\n<</code>>\n\n===3. PostFix Configuration as Store and Forward MTA\n\n====3.1 Configure mail-store  - We assume that the main mail server is already up and running so here we configure our mail store and forward. \nOpen /etc/postfix/main.cf in your favorite editor [vi or emacs or nano or pico] and  modify the following lines as follows:\n<<code ext=\"bash\">>\nrelay_domains = jnvilo.com, cyberciti.com, $mydestination\nrelay_recipient_maps = hash:/etc/postfix/relay_recipients\n<</code>>\n\n====3.2 Create the allowed recipients:\n\nCreate /etc/postfix/relay_recipients \n\n<<code ext=\"bash\">>\nadmin@jnvilo.com    OK\nuser1@jnvilo.com     OK\nfoo@jnvilo.com         OK\n<</code>>              \n\nsave and close the file and make sure your DB is updated\n\n<<code ext=\"bash\">>\npostmap hash:/etc/postfix/relay_recipients\n<</code>>\n\n===4. Anti SPAM \n\nEdit /etc/postfix/main.cf and add the following lines:\n\n<<code ext=\"bash\">>\nsmtpd_recipient_restrictions = permit_sasl_authenticated, permit_mynetworks,\n  reject_non_fqdn_hostname,\n  reject_non_fqdn_sender,\n  reject_non_fqdn_recipient,\n  reject_unauth_destination,\n  reject_unauth_pipelining,\n  reject_invalid_hostname,\n  reject_rbl_client zen.spamhaus.org\n# helo required\nsmtpd_helo_required = yes\n# disable vrfy command\ndisable_vrfy_command = yes\nsmtpd_data_restrictions =\n            reject_unauth_pipelining,\n            permit\n<</code>>\n\nMake sure to reload postfix to ensure changes are read.\n\n<<code ext=\"bash\">>\nservice postfix reload\n<</code>>\n\n\nreferences:\nhttp://www.akadia.com/services/postfix_mx_backup.html", "timestamp": "2016-04-28T16:36:12.417Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 20, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-09T22:36:00.641Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 21, "fields": {"title": null, "content": "Systemd, the big move away from init that caused great flame wars over the internet is now over. RedHat 7 and Fedora and others have moved to systemd. Suffice to say, old hats like me now need to learn it. I was just getting used to the quirks of NetworkManager and here we are, another way to configure networking. So without further ado this tutorial aims to introduce you to systemd-networkd and how to move your server to using it instead of  NetworkManager. \n\nWith systemd-networkd we can:\n* Manage DHCP/static IP networking\n* Create and configure Bridges, tunnels and VLANs\n* WiFI Networking via wpa_supplicant hooked up to systemd-networkd\n\n\nBut for those of you who want to try out systemd-networkd, you can read on, and find out in this tutorial how to switch from NetworkManager to systemd-networkd on Linux.\n\n\nFirst, disable Network Manager service, and enable systemd-networkd as follows.\n\n<<code>>\n$ sudo systemctl disable NetworkManager\n$ sudo systemctl enable systemd-networkd\n<</code>>\n\nYou also need to enable systemd-resolved service, which is used by systemd-networkd for network name resolution. This service implements a caching DNS server.\n\n<<code>>\n$ sudo systemctl enable systemd-resolved\n$ sudo systemctl start systems-resolved\n<</code>>\n\nOnce started, systemd-resolved will create its own resolv.conf somewhere under /run/systemd directory. However, it is a common practise to store DNS resolver information in /etc/resolv.conf, and many applications still rely on /etc/resolv.conf. Thus for compatibility reason, create a symlink to /etc/resolv.conf as follows.\n\n<<code>>\n$ sudo rm /etc/resolv.conf\n$ sudo ln -s /run/systemd/resolve/resolv.conf /etc/resolv.conf\n<</code>>\n\nConfigure Network Connections with Systemd-networkd\nTo configure network devices with systemd-networkd, you must specify configuration information in text files with .network extension. These network configuration files are then stored and loaded from /etc/systemd/network. When there are multiple files, systemd-networkd loads and processes them one by one in lexical order.\n\nLet's start by creating a folder /etc/systemd/network.\n\n<<code>>\n$ sudo mkdir /etc/systemd/network\n<</code>>\n\nDHCP Networking\n\nLet's configure DHCP networking first. For this, create the following configuration file. The name of a file can be arbitrary, but remember that files are processed in lexical order.\n\n<<code>>\n$ sudo vi /etc/systemd/network/20-dhcp.network\n[Match]\nName=enp3*\n\n[Network]\nDHCP=yes\n<</code>>\nAs you can see above, each network configuration file contains one or more \"sections\" with each section preceded by [XXX] heading. Each section contains one or more key/value pairs. The [Match] section determine which network device(s) are configured by this configuration file. For example, this file matches any network interface whose name starts with ens3 (e.g., enp3s0, enp3s1, enp3s2, etc). For matched interface(s), it then applies DHCP network configuration specified under [Network] section.\n\nStatic IP Networking\nIf you want to assign a static IP address to a network interface, create the following configuration file.\n\n$ sudo vi /etc/systemd/network/10-static-enp3s0.network\n[Match]\nName=enp3s0\n\n[Network]\nAddress=192.168.10.50/24\nGateway=192.168.10.1\nDNS=8.8.8.8\nAs you can guess, the interface enp3s0 will be assigned an address 192.168.10.50/24, a default gateway 192.168.10.1, and a DNS server 8.8.8.8. One subtlety here is that the name of an interface enp3s0, in facts, matches the pattern rule defined in the earlier DHCP configuration as well. However, since the file \"10-static-enp3s0.network\" is processed before \"20-dhcp.network\" according to lexical order, the static configuration takes priority over DHCP configuration in case of enp3s0 interface.\n\nOnce you are done with creating configuration files, restart systemd-networkd service or reboot.\n\n$ sudo systemctl restart systemd-networkd\nCheck the status of the service by running:\n\n$ systemctl status systemd-networkd\n$ systemctl status systemd-resolved\n\n\n<alert>\n\n\n</alert>", "timestamp": "2016-04-22T19:04:44.726Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 22, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-09T22:38:28.549Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 23, "fields": {"title": null, "content": "I hate using PHP. There was a time I loved it and looked forward to the release of PHP 5. These days I I use it only when I really have to, for example being asked to update or troubleshoot an old code base.  Normally I would just create a virtual machine with linux on it, but this time I thought I would use homebrew to instal a local stack on my Maverick development machine. So here goes:\n\n* Mac OS X Maverick\n* Nginx \n* PHP 5.4 as a FastCGI using PHP-FPM\n\n==Installing Homebrew\n\n<<alert level=block>>\nIf you already have homebrew installed then skip to the next section.  If you use ports or fink, then this tutorial is not for you. Installing homebrew with ports or fink is doable but you are on your own.\n<</alert>>\n\nIf you have not used or heard of homebrew before, then Homebrew is a package manager very similar to gentoo's package management system. It will download and compile and install any open souirce software you need.  \n\n===First install Apple Command Line Developer Tools\n\nThe command line developer tools can be downloaded from Apple's developer website at https://developer.apple.com/downloads/index.action?name=for%20Xcode%20-\n\nOnce the command line tools have been installed, installing Homebrew is as simple as: \n\n<<code ext=\"bash\">>\nruby -e \"$(curl -fsSkL raw.github.com/mxcl/homebrew/go)\"\n    ...\n    ==> /usr/bin/sudo /usr/bin/chgrp admin /usr/local/. /usr/local/bin\n    ==> Downloading and Installing Homebrew...\n    ==> Installation successful!\n    You should run `brew doctor' *before* you install anything.\n<</code>>\n\n===Install PHP 5.4 With FPM on Mac OS X \n\n<<code ext=\"bash\">>\nbrew search php\n<</code>>\n\nThis will give you a long list of available brews for php 5.2, 5.3, 5.4 packages. We need 5.4 and specifically from a certain brew\n\n<<code ext=\"bash\">>\nbrew tap josegonzales/php\nbrew tap homebrew/dupes\n<</code>>\n\nWe can list the options for installing php54 with the following command.\n\n<<code ext=\"bash\">>\nbrew options php54\n<</code>>\n\nWe shall build it with the following command\n\n<<code ext=\"bash\">>\nbrew install php54 --with-fpm  --with-imap  --without-apache --with-debug\n<</code>>\n\nThis will take some time. Go make some coffee, play with your kids if you have any or whatever.. After a long wait we can verify the php and php-fpm version we have installed using the following commands:\n\n<<code ext=\"bash\">>\nphp -v\nphp-fpm\n<</code>>\n\n===Ensuring that PHP-FPM starts when we start OS X\n\n<<alert level=\"info\">>\nNote that: If you will follow my configurations section, then you do not need this part since we will not be using these start/stop scripts. Skip directly to Configuration. \n<</alert>>\nIf you want that php-fpm is automatically started do:\n\n<<code ext=\"bash\">>\ncp /usr/local/Cellar/php54/5.4.15/homebrew-php.josegonzalez.php54.plist ~/Library/LaunchAgents/\n<</code>>\n\nOtherwise you can use the following to start and stop\n\n**To Start**:\n<<code ext=\"bash\">>\nlaunchctl load -w ~/Library/LaunchAgents/homebrew-php.josegonzalez.php54.plist\n<</code>>\n\n**To Stop**:\n<<code ext=\"bash\">>\nlaunchctl unload -w ~/Library/LaunchAgents/homebrew-php.josegonzalez.php54.plist\n<</code>>\n\n==Installing Nginx on Mac OS X\n<<code ext=\"bash\">>\nbrew install nginx\n<</code>>\n\n<<alert level=\"info\">>\nThe following steps are  only if you are going to use the standard setup and configuration found in /usr/local/etc/nginx/..  The configuration method I will show does not use this method so skip this step if you wish to configure your OS X development box like how I show you.\n<</alert>>\n\nCopy the start/stop script. If you plan to use them. On my development machine, I do not use them since I prefer to use my own start stop scripts and also use custom configurations which will become clear further down in the Configurations Section. You can just skip this part if you wish. \n\n<<code ext=\"bash\">>\ncp /usr/local/Cellar/nginx/1.4.1/homebrew.mxcl.nginx.plist ~/Library/LaunchAgents/\n<</code>>\n\n**To Start**\n<<code ext=\"bash\">>\nlaunchctl load -w ~/Library/LaunchAgents/homebrew.mxcl.nginx.plist\n<</code>>\n\n**To Stop**\n<<code ext=\"bash\">>\nlaunchctl unload -w ~/Library/LaunchAgents/homebrew.mxcl.nginx.plist\n<</code>>\n\n==Configuration\n\nOK we now have the required software in place. We only now need to configure.  For my projects and websites I like to have the following structure. At the minimum below is what I have:\n\n<<code ext=\"bash\">>\n$PROJECT_HOME/bin          # The bin directory shall contain our start/stop scripts\n$PROJECT_HOME/etc          # The etc directory  shall contain the nginx and php-fpm configuration\n$PROJECT_HOME/htdocs    # This is where the website home is. \n$PROJECT_HOME/logs        #  This is where we keep the logs \n<</code>>\n", "timestamp": "2016-04-09T22:39:11.583Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 24, "fields": {"title": null, "content": "Homebrew, the missing package manager for OS X. The standard Node.js and npm install method for OS X is to download a pre-built installer for your platform, install it, and make sure it\u2019s on your $PATH. But since you have homebrew, you have a better way of installing it and its as easy as pie!\n\n==Install Node.js and npm with Homebrew\n\nFirst you need to install homebrew if you do not have it. \n<<code>>\nruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n<</code>>\n\nThats going to chug away for a while. Then, brew update to ensure your Homebrew is up to date.\n\n<<code>>\nbrew update\n<</code>>\n\nAll homebrew users know that they should make it habitual to run brew doctor. So lets run it right now, even though if you just installed homebrew you don't need it yet.,\n<<code>>\nbrew doctor\n<</code>>\n\nMake sure that homebrew is in your path. I do this by putting the following in my ~/.bash_profile\n\n<<code>>\nexport PATH=\"/usr/local/bin:$PATH\"\n<</code>>\n\n\nAnd finally we  install Node (npm will be installed with node):\n<<code>>\nbrew install node\n<</code>>\n\nWe test out our Node and npm install, try installing Grunt.\n\n<<code>>\nnpm install -g grunt-cli\n<</code>>\n\nIf that worked, congrats, you\u2019re good to go with Node.js, npm, and Grunt. If not, retrace your steps.", "timestamp": "2016-04-09T22:42:16.232Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 25, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-10T10:11:21.597Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 26, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-10T10:11:33.355Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 27, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-10T10:11:44.437Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 28, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-10T10:12:16.249Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 29, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-10T10:12:28.424Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 30, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-10T10:13:17.266Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 31, "fields": {"title": null, "content": "I am not an expert at this but here are my notes on creating and managing Git Branches. Why do we create branches? Well the main reason we use version control is so that we can always go back to a point in time in our sources where we know what the state of the code is.  Having branches make that easy. The master branch contains the latest and greatest \"working\" version of the code. Everytime we make a change, we create a new branch, make our changes, test, and then when finally ready , we merge it back to our master branch. At this time when we are ready to push say to production, we create a \"tag\" or another branch. \n\n==Notes on git branch commands\n===Create the branch on your local machine and switch in this branch :\n<<code>>\n$ git checkout -b [name_of_your_new_branch]\n<</code>>\n\nPush the branch on github :\n\n<<code>>\n$ git push origin [name_of_your_new_branch]\n<</code>>\n\nWhen you want to commit something in your branch, be sure to be in your branch.\n\nYou can see all branches created by using :\n\n<<code>>\n$ git branch\n<</code>>\n\nWhich will show :\n<<code>>\n* approval_messages\n  master\n  master_clean\n<</code>>\n\n===Add a new remote for your branch :\n\n<<code>>\n$ git remote add [name_of_your_remote] \n<</code>>\n\nPush changes from your commit into your branch :\n\n<<code>>\n$ git push origin [name_of_your_remote]\n<</code>>\n\nUpdate your branch when the original branch from official repository has been updated :\n\n<<code>>\n$ git fetch [name_of_your_remote]\n<</code>>\n\nThen you need to apply to merge changes, if your branch is derivated from develop you need to do :\n\n<<code>>\n$ git merge [name_of_your_remote]/develop\n<</code>>\n\n===Delete a branch on your local filesystem :\n<<code>>\n$ git branch -d [name_of_your_new_branch]\n<</code>>\n\nTo force the deletion of local branch on your filesystem :\n\n<<code>>\n$ git branch -D [name_of_your_new_branch]\n<</code>>\n\nDelete the branch on github :\n\n<<code>>\n$ git push origin :[name_of_your_new_branch]\n<</code>>\n\nThe only difference is the : to say delete, you can do it too by using github interface to remove branch : https://help.github.com/articles/deleting-unused-branches.\n\n==Hard Reset:  Loose all Local Changes and Get the Remote \n\n<<code>>\ngit fetch --all\ngit reset --hard origin/master\n<</code>>\n\n\nOR If you are on some other branch\n<<code>>\ngit fetch --all\ngit reset --hard origin/your_branch\n<</code>>\n\n===Explanation:\ngit fetch downloads the latest from remote without trying to merge or rebase anything.\n\nThen the git reset resets the master branch to what you just fetched. The --hard option changes all the files in your working tree to match the files in origin/master\n\n[*]: It's worth noting that it is possible to maintain current local commits by creating a branch from master before resetting:\n\ngit checkout master\ngit branch new-branch-to-save-current-commits\ngit fetch --all\ngit reset --hard origin/master\nAfter this, all of the old commits will be kept in new-branch-to-save-current-commits. Uncommitted changes however (even staged), will be lost. Make sure to stash and commit anything you need.", "timestamp": "2018-03-21T19:16:32.621Z", "markup": 1, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 32, "fields": {"title": null, "content": "Here you will find resources (tutorials, book review, quiz, sample exams, etc) about the RHCSA exam (Red Hat Certified System Administrator) for RHEL 7 (Red Hat Enterprise Linux 7).The exam, also called EX200, is a performance-based exam lasting 2 hours and half, focusing on installation and server configuration. You can take the exam in a classroom setting monitored by a proctor or in a Individual Exam Session (IES) remotely monitored. A FAQ about IES is available on the Red Hat website.\n\nOfficial information about the exam can be found at: http://www.redhat.com/training/courses/\n\nYou can take the exam in a classroom setting monitored by a proctor or in a Individual Exam Session (IES) remotely monitored. A FAQ about IES is available on the Red Hat website.\n\n<<H1>>Exam Topics Overview<</H1>>\n\nUnderstand and use essential tools\n\nAccess a shell prompt and issue commands with correct syntax.\nUse input-output redirection (>, >>, |, 2>, etc.).\nUse grep and regular expressions to analyze text.\nAccess remote systems using ssh.\nLog in and switch users in multiuser targets.\nArchive, compress, unpack, and uncompress files using tar, star, gzip, and bzip2.\nCreate and edit text files.\nCreate, delete, copy, and move files and directories.\nCreate hard and soft links.\nList, set, and change standard ugo/rwx permissions.\nLocate, read, and use system documentation including man, info, and files in /usr/share/doc.\nNOTE: Red Hat may use applications during the exam that are not included in Red Hat Enterprise Linux for the purpose of evaluating candidate\u2019s abilities to meet this objective.\nOperate running systems\n\nBoot, reboot, and shut down a system normally.\nBoot systems into different targets manually.\nInterrupt the boot process in order to gain access to a system.\nIdentify CPU/memory intensive processes, adjust process priority with renice, and kill processes.\nLocate and interpret system log files and journals.\nAccess a virtual machine\u2019s console.\nStart and stop virtual machines.\nStart, stop, and check the status of network services.\nSecurely transfer files between systems.\nConfigure local storage\n\nList, create, delete partitions on MBR and GPT disks.\nCreate and remove physical volumes, assign physical volumes to volume groups, and create and delete logical volumes.\nConfigure systems to mount file systems at boot by Universally Unique ID (UUID) or label.\nAdd new partitions and logical volumes, and swap to a system non-destructively.\nCreate and configure file systems\nCreate, mount, unmount, and use vfat, ext4 and xfs file systems.\nMount and unmount CIFS and NFS network file systems.\nExtend existing logical volumes.\nCreate and configure set-GID directories for collaboration.\nCreate and manage Access Control Lists (ACLs).\nDiagnose and correct file permission problems.\nDeploy, configure, and maintain systems\n\nConfigure networking and hostname resolution statically or dynamically.\nSchedule tasks using at and cron.\nStart and stop services and configure services to start automatically at boot.\nConfigure systems to boot into a specific target automatically.\nInstall Red Hat Enterprise Linux automatically using Kickstart.\nConfigure a physical machine to host virtual guests.\nInstall Red Hat Enterprise Linux systems as virtual guests.\nConfigure systems to launch virtual machines at boot.\nConfigure network services to start automatically at boot.\nConfigure a system to use time services.\nInstall and update software packages from Red Hat Network, a remote repository, or from the local file system.\nUpdate the kernel package appropriately to ensure a bootable system.\nModify the system bootloader.\nManage users and groups\n\nCreate, delete, and modify local user accounts.\nChange passwords and adjust password aging for local user accounts.\nCreate, delete, and modify local groups and group memberships.\nConfigure a system to use an existing authentication service for user and group information.\nManage security\n\nConfigure firewall settings using firewall-config, firewall-cmd, or iptables.\nConfigure key-based authentication for SSH.\nSet enforcing and permissive modes for SELinux.\nList and identify SELinux file and process context.\nRestore default file contexts.\nUse boolean settings to modify system SELinux settings.\nDiagnose and address routine SELinux policy violations.", "timestamp": "2016-04-14T20:50:21.671Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 33, "fields": {"title": null, "content": "<<H1>>Working on the shell prompt<</H1>> \nThe RHCSA exam requires that you are proficient in using the terminal , use of basic commands and text processing. This involves output redirection. In this article we shall tackle the required basic commands and text processing.\n\n\n==Use input-output redirection (>, >>, |, 2>, etc.)\n\n*  >   Redirects stdout to a file and it creates the file if not present otherwise it will overwrite it. \n\n* >> Redirects stdout to a file appending to the file. \n\nExamples:\n\n<<code>>\nls -al > files.txt  # will list all the directories and write the output to a file called files.txt \nls -al >>files.txt # will do as above but will append to the file rather than overwriting it. \n<</code>>\n\n==M>N Redirection\n\nThe above > and >> works only for stdout. In order to redirect the stderr we must use the form M>N where M and N are file descriptors. 1 is the file descriptor for stdout and 2 is for the stderr.\n\nAs such the following are equivalents:\n\n<<code>>\nls -al 1> files.txt \nls -al > files.txt\n<</code>>\n\nKnowing that \"2\" signifies stderr, it follows that if we only want the stderr to be redirected, the format is as follows:\n\n<<code>>\n2> files.txt  \n<</code>>\n\nRedirect both stdout and stderr \n<<code>>\nls -al &> files.txt\n<</code>>\n\nM>&N where M is a file descriptor which defaults to 1 if not set. \n\n<<code>>\nls -al 2>&1  # will redirect 2 \"stderr\" to 1 \"stdout\"\n<</code>>\n\n=The < redirect\n\nThis reads a file line by line and feeds it to the command provided to the left. \n\n<<code>>\ngrep keyword < FILENAME\n<</code>>\n\n===Combining <  > and & operators\n\n<<code>>\nls -yz >> files.txt 2>&1  # Will redirect output of ls-yz for both stderr and stdout.\n<</code>>\n\n===Pipe - The general purpose process and command chaning tool.\n\n<<code>>\ncat *.txt | sort | uniq > result-file\n<</code>>\n\n\n\n<<H1>>Use grep and regular expressions to analyse text<</H1>>\n\n===Access remote systems using ssh.\n\nThe RHCSA Objectives lists this requirements. This is weird because not knowing ssh is like trying to go for a race without not being able to even walk yet. We shall skip this.\n\n<<H1>>Log in and switch users in multiuser targets.<</H1>>\n\n\n\n\n<<H1>> Working with archive tools <</H1>>\n\n\n<<H1>>Working with Files, Directories and Links <</H1>>\nCreate and edit text files.\nCreate, delete, copy, and move files and directories.\nCreate hard and soft links.\n\n<<H1>>User Permissions <</H1>>\nList, set, and change standard ugo/rwx permissions.\nLocate, read, and use system documentation including man, info, and files in /usr/share/doc.\n\n==Exam Objectives Checklist", "timestamp": "2016-04-14T20:57:06.232Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 34, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-12T10:13:07.132Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 35, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-12T10:13:49.893Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 36, "fields": {"title": null, "content": "\n<<code>>\nclass Provider:\n\n    def __init__(self):\n        self.msg_queue = []\n        self.subscribers = {}\n\n    def notify(self, msg):\n        self.msg_queue.append(msg)\n\n    def subscribe(self, msg, subscriber):\n        self.subscribers.setdefault(msg, []).append(subscriber)\n\n    def unsubscribe(self, msg, subscriber):\n        self.subscribers[msg].remove(subscriber)\n\n    def update(self):\n        for msg in self.msg_queue:\n            if msg in self.subscribers:\n                for sub in self.subscribers[msg]:\n                    sub.run(msg)\n        self.msg_queue = []\n\n\nclass Publisher:\n\n    def __init__(self, msg_center):\n        self.provider = msg_center\n\n    def publish(self, msg):\n        self.provider.notify(msg)\n\n\nclass Subscriber:\n\n    def __init__(self, name, msg_center):\n        self.name = name\n        self.provider = msg_center\n\n    def subscribe(self, msg):\n        self.provider.subscribe(msg, self)\n\n    def unsubscribe(self, msg):\n        self.provider.unsubscribe(msg, self)\n\n    def run(self, msg):\n        print(\"{} got {}\".format(self.name, msg))\n\n\ndef main():\n    message_center = Provider()\n\n    fftv = Publisher(message_center)\n\n    jim = Subscriber(\"jim\", message_center)\n    jim.subscribe(\"cartoon\")\n    jack = Subscriber(\"jack\", message_center)\n    jack.subscribe(\"music\")\n    gee = Subscriber(\"gee\", message_center)\n    gee.subscribe(\"movie\")\n    vani = Subscriber(\"vani\", message_center)\n    vani.subscribe(\"movie\")\n    vani.unsubscribe(\"movie\")\n\n    fftv.publish(\"cartoon\")\n    fftv.publish(\"music\")\n    fftv.publish(\"ads\")\n    fftv.publish(\"movie\")\n    fftv.publish(\"cartoon\")\n    fftv.publish(\"cartoon\")\n    fftv.publish(\"movie\")\n    fftv.publish(\"blank\")\n\n    message_center.update()\n\n\nif __name__ == \"__main__\":\n    main()\n\n### OUTPUT ###\n# jim got cartoon\n# jack got music\n# gee got movie\n# jim got cartoon\n# jim got cartoon\n# gee got movie\n\n<</code>>", "timestamp": "2016-04-12T10:15:31.806Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 37, "fields": {"title": null, "content": "In the Observer design pattern, an object (Subject) maintains a list of dependents (Observers) so that the Subject can notify all the Observers about the changes that it undergoes using any of the methods defined by the Observer.\n\nIn the world of distributed applications, multiple services interact with each other to perform a larger operation that a user wants to achieve. Services can perform multiple operations, but the operation they perform is directly or heavily dependent on the state of the objects of the service that it interacts with.\n<<code>>\n\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n\"\"\"http://code.activestate.com/recipes/131499-observer-pattern/\"\"\"\n\n\nclass Subject(object):\n\n    def __init__(self):\n        self._observers = []\n\n    def attach(self, observer):\n        if observer not in self._observers:\n            self._observers.append(observer)\n\n    def detach(self, observer):\n        try:\n            self._observers.remove(observer)\n        except ValueError:\n            pass\n\n    def notify(self, modifier=None):\n        for observer in self._observers:\n            if modifier != observer:\n                observer.update(self)\n\n<</code>>\n\n\n# Example usage\n\n\n<<code>>\nclass Data(Subject):\n\n    def __init__(self, name=''):\n        Subject.__init__(self)\n        self.name = name\n        self._data = 0\n\n    @property\n    def data(self):\n        return self._data\n\n    @data.setter\n    def data(self, value):\n        self._data = value\n        self.notify()\n<</code>>\n\n<<code>>\n\nclass HexViewer:\n\n    def update(self, subject):\n        print('HexViewer: Subject %s has data 0x%x' %\n              (subject.name, subject.data))\n\n<</code>>\n\n<<code>>\nclass DecimalViewer:\n\n    def update(self, subject):\n        print('DecimalViewer: Subject %s has data %d' %\n              (subject.name, subject.data))\n\n<</code>>\n\n<<code>>\n# Example usage...\ndef main():\n    data1 = Data('Data 1')\n    data2 = Data('Data 2')\n    view1 = DecimalViewer()\n    view2 = HexViewer()\n    data1.attach(view1)\n    data1.attach(view2)\n    data2.attach(view2)\n    data2.attach(view1)\n\n    print(\"Setting Data 1 = 10\")\n    data1.data = 10\n    print(\"Setting Data 2 = 15\")\n    data2.data = 15\n    print(\"Setting Data 1 = 3\")\n    data1.data = 3\n    print(\"Setting Data 2 = 5\")\n    data2.data = 5\n    print(\"Detach HexViewer from data1 and data2.\")\n    data1.detach(view2)\n    data2.detach(view2)\n    print(\"Setting Data 1 = 10\")\n    data1.data = 10\n    print(\"Setting Data 2 = 15\")\n    data2.data = 15\n\n\nif __name__ == '__main__':\n    main()\n\n### OUTPUT ###\n# Setting Data 1 = 10\n# DecimalViewer: Subject Data 1 has data 10\n# HexViewer: Subject Data 1 has data 0xa\n# Setting Data 2 = 15\n# HexViewer: Subject Data 2 has data 0xf\n# DecimalViewer: Subject Data 2 has data 15\n# Setting Data 1 = 3\n# DecimalViewer: Subject Data 1 has data 3\n# HexViewer: Subject Data 1 has data 0x3\n# Setting Data 2 = 5\n# HexViewer: Subject Data 2 has data 0x5\n# DecimalViewer: Subject Data 2 has data 5\n# Detach HexViewer from data1 and data2.\n# Setting Data 1 = 10\n# DecimalViewer: Subject Data 1 has data 10\n# Setting Data 2 = 15\n<</code>>", "timestamp": "2016-04-22T18:49:34.760Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 38, "fields": {"title": null, "content": "<<H1>>Boot, reboot, and shut down a system normally. <</H1>>\n<<H1>>Boot systems into different targets manually.<</H1>>\n<<H1>>Interrupt the boot process in order to gain access to a system.<</H1>>\n<<H1>>Identify CPU/memory intensive processes, adjust process priority with renice, and kill processes.<</H1>>\n<<H1>>Locate and interpret system log files and journals.<</H1>>\n<<H1>>Access a virtual machine\u2019s console.<</H1>>\n<<H1>>Start and stop virtual machines.<</H1>>\n<<H1>>Start, stop, and check the status of network services.<</H1>>\n<<H1>>Securely transfer files between systems.<</H1>>", "timestamp": "2016-04-15T10:00:18.096Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 39, "fields": {"title": null, "content": "\n<<H1>>Manage Partitions<</H1>>\nList, create, delete partitions on MBR and GPT disks.\n<<H1>>LVM Management<</H1>>\nCreate and remove physical volumes, assign physical volumes to volume groups, and create and delete logical volumes.\n<<H1>>Mount FS at boot by Universally Unique ID (UUID) or label.<</H1>>\n\n", "timestamp": "2016-04-22T18:36:15.479Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 40, "fields": {"title": null, "content": "Configure networking and hostname resolution statically or dynamically.\nSchedule tasks using at and cron.\nStart and stop services and configure services to start automatically at boot.\nConfigure systems to boot into a specific target automatically.\nInstall Red Hat Enterprise Linux automatically using Kickstart.\nConfigure a physical machine to host virtual guests.\nInstall Red Hat Enterprise Linux systems as virtual guests.\nConfigure systems to launch virtual machines at boot.\nConfigure network services to start automatically at boot.\nConfigure a system to use time services.\nInstall and update software packages from Red Hat Network, a remote repository, or from the local file system.\nUpdate the kernel package appropriately to ensure a bootable system.\nModify the system bootloader.", "timestamp": "2016-04-15T10:05:09.871Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 41, "fields": {"title": null, "content": "<<H1>>Create, delete, and modify local user accounts.<</H1>>\n<<H1>>Change passwords and adjust password aging for local user accounts.<</H1>>\n<<H1>>Create, delete, and modify local groups and group memberships.<</H1>>\n<<H1>>Configure a system to use an existing authentication service for user and group information.<</H1>>", "timestamp": "2016-04-22T18:37:35.833Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 42, "fields": {"title": null, "content": "<<H1>>Create, delete, and modify local user accounts.<</H1>>\n<<H1>>Change passwords and adjust password aging for local user accounts.<</H1>>\n<<H1>>Create, delete, and modify local groups and group memberships.<</H1>>\n<<H1>>Configure a system to use an existing authentication service for user and group information.<</H1>>\n\nConfigure firewall settings using firewall-config, firewall-cmd, or iptables.\nConfigure key-based authentication for SSH.\nSet enforcing and permissive modes for SELinux.\nList and identify SELinux file and process context.\nRestore default file contexts.\nUse boolean settings to modify system SELinux settings.\nDiagnose and address routine SELinux policy violations.", "timestamp": "2016-04-22T18:38:53.163Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 43, "fields": {"title": null, "content": "The Singleton design pattern is used when we want to ensure that one and only one object of the class gets created during the lifetime of our program, and provide an access point for an object that is global to the program. Concurrent access to the resources implemented as a singleton is also protected from race conditions.\n\n\n<<code ext=\".py\">>\nclass Singleton(object):     \n    def __new__(cls):       \n        if not hasattr(cls, 'instance'):         \n            cls.instance = super(Singleton, cls).__new__(cls)       \n        return cls.instances = Singleton()print(\"Object created\", s)\n<</code>>", "timestamp": "2016-04-15T10:17:41.919Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 44, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-18T09:31:27.590Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 45, "fields": {"title": null, "content": "This is an RHCSA 7 exam objective. In this Objective, the candidate is expected to know how to compress, unpack, and uncompress files using tar, star, gzip, and bzip2.\n\no compress a file, type:\n\n<<code>>\n# gzip file\n# bzip2 file\n<</code>>\n\nTo uncompress a file, type:\n\n<<code>>\n# gunzip file.gz\n# bunzip2 file.bz2\n<</code>>\n\nTo archive and compress a directory (with the SELinux contexts), type:\n\n<<code>>\n# tar --selinux -czvf directory.tgz directory\n<</code>>\n\nNote: Try to avoid using full path when specifying the directory path, use relative path, it will be easier when restoring.\n\nAlternatively, you can group both operations (tar+compression) in one command (respectively for gzip and bzip2 content):\n\n<<code>>\n# tar cvzf directory.tgz directory\n# tar cvjf directory.bz2 directory\n<</code>>\n\nTo unpack and uncompress an archive file (respectively for gunzip and bunzip2 content) (with the SELinux contexts), type:\n\n<<code>>\n# tar --selinux xzvf directory.tgz\n# tar --selinux xjvf directory.bz2\n<</code>>\n\nTo list the archive content (respectively for gunzip and bunzip2 content), type:\n\n<<code>>\n# tar tzvf directory.tgz\n# tar tjvf directory.bz2\n<</code>>\n\nTo archive a directory with the star command (with the SELinux contexts), type:\n\n<<code>>\n# yum install -y star\n# star -xattr -H=exustar -c -f=directory.star directory\n<</code>>\n\nTo unpack a archive file, type:\n\n<<code>>\n# star -x -f=directory.star\n<</code>>", "timestamp": "2016-04-22T18:33:39.792Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 46, "fields": {"title": null, "content": "The way Linux system boots up is quite complex and there have always been need to optimize the way it works. The traditional boot up process of Linux system is mainly handled by the well know init process (also known as SysV init boot system), while there have been identified inefficiencies in the init based boot system, systemd on the other hand is another boot up manager for Linux based systems which claims to overcome the shortcomings of traditional Linux SysV init based system. We will be focusing our discussion on the features and controversies of systemd , but in order to understand it, let\u2019s see how Linux boot process is handled by traditional SysV init based system. Kindly note that Systemd is still in testing phase and future releases of Linux operating systems are preparing to replace their current boot process with Systemd Boot manager.\n\n<<H1>>Understanding Linux Boot Process<</H1>>\n\nInit is the very first process that starts when we power on our Linux system. Init process is assigned the PID of 1. It is parent process for all other processes on the system. When a Linux computer is started, the processor searches for the BIOS on the system memory, BIOS then tests system resources and find the first boot device, usually set as hard disk, it looks for Master Boot Record (MBR) on the hard disk, loads its contents to memory and passes control to it, the further boot process is controlled by MBR.\n\nMaster Boot Record initiates the Boot loader (Linux has two well know boot loaders, GRUB and LILO, 80% of Linux systems are using GRUB loaders), this is the time when GRUB or LILO loads the kernel module. Kernel module immediately looks for the \u201cinit\u201d in /sbin partition and executes it. That\u2019s from where init becomes the parent process of Linux system. The very first file read by init is /etc/inittab , from here init decides the run level of our Linux operating system. It finds partition table information from /etc/fstab file and mounts partitions accordingly. Init then launches all the services/scripts specified in the /etc/init.d directory of the default run level. This is the step where all services are initialized by init one by one.  In this process, one service at a time is started by init , all services/daemons run in the background and init keeps managing them.\n\nThe shutdown process works in pretty much the reverse function, first of all init stops all services and then filesystem is un-mounted at the last stage.\n\nThe above mentioned process has some shortcomings. The need to replace traditional init with something better have been felt from long time now. Some replacements have been developed and implemented as well. The well know replacements for this init based system as Upstart , Epoch , Mudar  and Systemd. Systemd is the one which got most attention and is considered to be better of all available alternatives.\n\n<<H1>>Understanding Systemd<</H1>>\n\nReducing the boot time and computational overhead is the main objective of developing the Systemd. Systemd (System Manager Daemon) , originally developed under GNU General Public License, is now  under GNU Lesser General Public License, it is most frequently discussed boot and services manager these days. If your Linux system is configured to use Systemd boot manager, then instead of traditional SysV init, startup  process will be handled by systemd.  One of the core feature of Systemd is that it supports post boot scripts of SysV Init  as well .\n\nSystemd introduces the parallelization boot concept, it creates a sockets  for each daemon that needs to be started, these sockets are abstracted from the processes that use them so they allow daemons to interact with each other. Systemd creates news processes and assigns every process  a control group. The processes in different control groups use kernel to communicate with each others. The way systemd handles the start up process is quite neat, and much optimized as compared to the traditional init based system. Let\u2019s review some of the core features of Systemd.\n\n* The boot process is much simpler as compared to the init\n* Systemd provides concurrent and parallel process of system boot so it ensures better boot speed\n* Processes are tracked using control groups, not by PIDs\n* Improved ways to handle boot and services dependencies.\n* Capability of system snapshots and restore\n* Monitoring of started services ; also capabale of restarting any crashed services\n* Includes systemd-login module to control user logins.\n* Ability to add and remove components\n* Low memory foot prints and ability for job scheduling\n* Journald module for event logging and syslogd module for system log.\n\nSystemd handles system shutdown process in well organized way as well. It has three script located inside /usr/lib/systemd/ directory, named systemd-halt.service , systemd-poweroff.service , systemd-reboot.service . These scripts are executed when user choose to shutdown, reboot or halt Linux system. In the event of shutdown, systemd first  un-mount all file systems and disabled all swap devices, detaches the storage devices and kills remaining processes.\n\n<<image name=\"systemd-boot-process\">>test<</image>>", "timestamp": "2016-04-22T18:33:27.520Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 47, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-24T18:16:57.528Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 48, "fields": {"title": null, "content": "Sometimes we do not always need a puppet server and instead we can copy/install our puppet manifests or module to the local host.  Using \"puppet apply\",   applies a standalone Puppet manifest  or module to to the local system. This assumes that we have  puppet installed locally. \n\n==To apply a local manifest\n<<code>>\n$ puppet apply -l /tmp/manifest.log manifest.pp\n<</code>>\n\nIf the manifest requires or references other modules then we need to state where to look for the modules as follows. \n<<code>>\n$ puppet apply -l /tmp/manifest.log --modulepath=/root/dev/modules  manifest.pp\n<</code>>\n\n==Apply a module without a manifest\n\n<<code>>\n$ puppet apply -l /tmp/manifest.log --modulepath=/path/to/modules  -e \"class {\\\"module_name\\\":}\"\n<</code>>\n\n==A Use Case:\nI use a class called wwwjnvilocom which configures a CentOS server to host this website and I test on a vm. \n\nI take the following steps to prepare the VM. \n* yum install puppet  to install puppet\n* puppet module install jfryman-nginx  #This installs the nginx module into /etc/puppet/modules\n* I then checkout my wwwjnvilocom module from my private git repo into /etc/puppet/modules \n\nAs a result, I can then just do \n\n<<code>>\npuppet apply --modulepath=/etc/puppet/modules -e 'class {\"wwwjnvilocom\":}'\n<</code>>\n", "timestamp": "2017-09-19T13:50:32.164Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 49, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2016-04-25T12:54:10.412Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 50, "fields": {"title": null, "content": "Most people will probably choose to use the DNS servers provided by their hosting company or their domain registrar. If however you have an internal network, there there are some advantages to creating your own DNS servers. You could configure an internal DNS server as a Caching or Forwarding server which will speed up your network's DNS lookups. Or Perhaps you have an internal lab and want to use internal domains.  In this guide, I will show the steps to configure Bind9 DNS server as a caching/forwarding server and also as an athoritative server for your internal domains. \n\nWe shall be using CentOS 7. CentOS 7.x ships with Bind9 which makes it relatively easy for us to install.\n\n==Install Bind 9 \n\nThe following command will download and install bind9 for us, including utilities.\n<<code>>\nyum -y install bind bind-utils\n<</code>>\nand, lets make sure its started and also that it will start on reboot\n\n<<code>>\nsystemctl start named\nsystemctl enable named\n<</code>>\n==Out of the box Configuration is already a Caching/Resolving DNS Server\n\nThe CentOS7 bind rpm already comes with a basic caching/forwarding configuration in /etc/named.conf  which looks like below without the comments:\n\n<<code>>\noptions {\n        listen-on port 53 { 127.0.0.1; };\n        listen-on-v6 port 53 { ::1; };\n        directory       \"/var/named\";\n        dump-file       \"/var/named/data/cache_dump.db\";\n        statistics-file \"/var/named/data/named_stats.txt\";\n        memstatistics-file \"/var/named/data/named_mem_stats.txt\";\n        allow-query     { localhost; };\n        recursion yes;\n        dnssec-enable yes;\n        dnssec-validation yes;\n        bindkeys-file \"/etc/named.iscdlv.key\";\n        managed-keys-directory \"/var/named/dynamic\";\n        pid-file \"/run/named/named.pid\";\n        session-keyfile \"/run/named/session.key\";\n};\n\nlogging {\n        channel default_debug {\n                file \"data/named.run\";\n                severity dynamic;\n        };\n};\n\nzone \".\" IN {\n        type hint;\n        file \"named.ca\";\n};\n\ninclude \"/etc/named.rfc1912.zones\";\ninclude \"/etc/named.root.key\";\n<</code>>\n\n\n==Initial Customization to the Caching/Forwarding DNS configuration\n\nThe default configuration works but it only works for the localhost.  So we need to do two changes: We need to add our network IP and also add the allowed network ranges.\n\nLook for the listen-on port 53 line and update it as follows. In my case I am using 172.16.16.16 as the DNS server IP. \n<<code>>\nlisten-on port 53 { 127.0.0.1; 172.16.16.16;};\n<</code>>\n\nNext add your network range so that other servers within your network can query the DNS server.\n<<code>>\nallow-query     { localhost; 172.16.16.0/16 };\n<</code>>\n\nAfter this you can restart. \n\n<<code>>\nsystemctl restart named\n<</code>>\n\nCongratulations, you now have a working DNS Caching/Forwarding server for your local network. \n\n==Add Authoritative configuration so we can answer queries for a local internal domain.\n\nIf you , like me are running a local lab, then you will want to configure your internal DNS server to resolve internal servers. For example, all my lab servers have a domain of lab.jnvilo.com and the rest are in home.jnvilo.com\n\nSo let us say we want to answer queries for:\n* lab.jnvilo.com\n* home.jnvilo.com\n\n===Add a zone definition for each of the above two sub domains.\n\n<<code>>\nzone \"lab.jnvilo.com\" {\n    type master;\n    file \"/etc/named/zones/db.lab.jnvilo.com\";\n};\n<</code>>\n\n<<code>>\nzone \"home.jnvilo.com\" {\n    type master;\n    file \"/etc/named/zones/db.home.jnvilo.com\";\n};\n<</code>>\n\n===We should also add reverse zones. In this case I am adding 172.16.16.0/24 \n<<code>>\nzone \"16.16.172.in-addr.arpa\" {\n    type master;\n    file \"/etc/named/zones/db.172.16.16\";\n};\n<</code>>\n\n===Create the Forward Zone file for lab.jnvilo.com \n\nEarlier we added a zone definition in /etc/named and referred to its configuration with an entry like \"/etc/named/zones/db.lab.jnvilo.com\". We must create this file as shown below:\n\n<<code>>\n$TTL    604800\n@       IN      SOA     ns1.example.com. admin.example.com. (\n                              5         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                         604800 )       ; Negative Cache TTL\n;\n\n; Name servers\nexample.com.    IN      NS      ns1.example.com.\nexample.com.    IN      NS      ns2.example.com.\n\n; A records for name servers\nns1             IN      A       192.0.2.1\nns2             IN      A       192.0.2.2\n\n; Other A records\n@               IN      A       192.0.2.3\nwww             IN      A       192.0.2.3\n<</code>>\n\n===Also create the Forward Zone file for home.jnvilo.com   \n<<code>>\n$TTL    604800\n@       IN      SOA     ns1.example.com. admin.example.com. (\n                              5         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                         604800 )       ; Negative Cache TTL\n;\n\n; Name servers\nexample.com.    IN      NS      ns1.example.com.\nexample.com.    IN      NS      ns2.example.com.\n\n; A records for name servers\nns1             IN      A       192.0.2.1\nns2             IN      A       192.0.2.2\n\n; Other A records\n@               IN      A       192.0.2.3\nwww             IN      A       192.0.2.3\n<</code>>\n\n===And Finally the Reverse Zone \n<<code>>\n$TTL    604800\n@       IN      SOA     example.com. admin.example.com. (\n                              5         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                         604800 )       ; Negative Cache TTL\n;\n\n; Name servers\n        IN      NS      ns1.example.com.\n        IN      NS      ns2.example.com.\n\n; PTR records\n1       IN      PTR      ns1.example.com.\n2       IN      PTR      ns2.example.com.\n3       IN      PTR      www.example.com.\n\n<</code>>\n\n", "timestamp": "2016-04-25T14:33:00.716Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 51, "fields": {"title": null, "content": "Most linux admins stop at basic file permissions and ignore using and learning Access Control Lists. ACL's is a very powerfull extenstion to basic file permissions. For example with ACLs you can set up a file in your home directory that can be read by a limited number of other users and groups. At the very least every linux admin should know how to create and manage access control lists. \n\nWith ACLs we can give selected users read, write and execute permissions to selected files in your home directory. This provides a second level of discretionary access control, a way that supports overriding the standard ugo/rwx permissions. \n\nThe two commands you need to get familiar with are:\n\n* getfacl\n* setfacl\n\n==The getfacl command disected\n\nA basic example use of getfacl is shown as follows:\n\n<<code>>\n[root@localhost]# getfacl /root\ngetfacl: Removing leading '/' from absolute path names\n# file: root\n# owner: root\n# group: root\nuser::r-x\ngroup::r-x\nother::---\n<</code>>\n\nThe above command was executed to get the attributes for /root. There are no ACL's. Access to /root is defined only by the standard ugo permissions.  \n\n==Ensuring that the filesystem supports ACL\n\nRHEL 7 by default uses XFS which have ACLs by default. Also creating ext2/ext3/ext4 filesystems in RHEL7 has ACLs by default. We can find out if our partition has ACLs enabled as follows:\n\n<<code>>\n[root@localhost~]# tune2fs -l /dev/mapper/fedora-root | grep acl\nDefault mount options:    user_xattr acl\n<</code>>\n\n==Setting and Modifying ACLs\n\nThere are four categories of ACLs per file: for an individual user, for a user group, via the effective rights mask, and for users not in the user group associated with the file. To view the existing ACLs for a file, execute the following:\n\n<<code>>\ngetfacl <file>\n<</code>>\n\nIf ACLs are enabled, the output should look similar to Listing 7.10.\n\n<<code>>\n# file: testfile\n# owner: tfox\n# group: tfox\nuser::rwx\ngroup::r-x\nmask::rwx\nother::r-x\n<</code>>\n\nTo set or modify existing ACLs, use the following syntax:\n\nsetfacl -m <rules> <file>\n\nOther useful options include --test to show the results of the command but not change the ACL and -R to apply the rules recursively.\n\nReplace <file> with one or more space-separated file or directory names. Rules can be set for four different rule types. Replace <rules> with one or more of the following, and replace <perms> in these rules with one or more of r, w, and x (which stand for read, write, and execute):\n\n    For an individual user:\n\n    u:<uid>:<perms>\n\n    For a specific user group:\n\n    g:<gid>:<perms>\n\n    For users not in the user group associated with the file:\n\n    o:<perms>\n\n    Via the effective rights mask:\n\n    m:<perms>\n\nThe first three rule types (individual user, user group, or users not in the user group for the file) are pretty self-explanatory. They allow you to give read, write, or execute permissions to users in these three categories. A user or group ID may be used, or the actual username or group name.\n\nCAUTION\n\nIf the actual username or group name is used to set an ACL, the UID or GID for it are still used to store the ACL. If the UID or GID for a user or group name changes, the ACLs are not changed to reflect the new UID or GID.\n\nBut, what is the effective rights mask? The effective rights mask restricts the ACL permission set allowed for users or groups other than the owner of the file. The standard file permissions are not affected by the mask, just the permissions granted by using ACLs. In other words, if the permission (read, write, or execute) is not in the effective rights mask, it appears in the ACLs retrieved with the getfacl command, but the permission is ignored. Listing 7.11 shows an example of this where the effective rights mask is set to read-only, meaning the read-write permissions for user brent and the group associated with the file are effectively read-only. Notice the comment to the right of the ACLs affected by the effective rights mask.\nListing 7.11. Effective Rights Mask\n\n# file: testfile\n# owner: tammy\n# group: tammy\nuser::rw-\nuser:brent:rw-                  #effective:r--\ngroup::rw-                     #effective:r--\nmask::r--\nother::rw-\n\nThe effective rights mask must be set after the ACL rule types. When an ACL for an individual user (other than the owner of the file) or a user group is added, the effective rights mask is automatically recalculated as the union of all the permissions for all users other than the owner and all groups including the group associated with the file. So, to make sure the effective rights mask is not modified after setting it, set it after all other ACL permissions.\n\nIf the ACL for one of these rule types already exists for the file or directory, the existing ACL for the rule type is replaced, not added to. For example, if user 605 already has read and execute permissions to the file, after the u:605:w rule is implemented, user 605 only has write permissions.\nSetting Default ACLs\n\nTwo types of ACLs can be used: access ACLs, and default ACLs. So far, this chapter has only discussed access ACLs. Access ACLs are set for individual files and directories. Directories, and directories only, can also have default ACLs, which are optional. If a directory has a default ACL set for it, any file or directory created in the directory with default ACLs will inherit the default ACLs. If a file is created, the access ACLs are set to what the default ACLs are for the parent directory. If a directory is created, the access ACLs are set to what the default ACLs are for the parent directory and the default ACLs for the new directory are set to the same default ACLs as the parent directory.\n\nTo set the ACL as a default ACL, prepend d: to the rule such as d:g:500:rwx to set a default ACL of read, write, and execute for user group 500. If any default ACL exists for the directory, the default ACLs must include a user, group, and other ACL at a minimum as shown in Listing 7.12.\nListing 7.12. Default ACLs\n\n<<code>>\n# file: testdir\n# owner: tfox\n# group: tfox\nuser::rwx\ngroup::r-x\nmask::rwx\nother::r-x\ndefault:user::rwx\ndefault:group::r-x\ndefault:other::r--\n<</code>>\nIf a default ACL is set for an individual user other than the file owner or for a user group other than the group associated with the file, a default effective rights mask must also exist. If one is not implicitly set, it is automatically calculated as with access ACLs. The same rules apply for the default ACL effective rights mask: It is recalculated after an ACL for any user other than the owner is set or if an ACL for any group including the group associated with the file is set, meaning it should be set last to ensure it is not changed after being set.\nRemoving ACLs\n\nThe setfacl -x <rules> <file> command can be used to remove ACL permissions by ACL rule type. The <rules> for this command use the same syntax as the setfacl -m <rules> <file> command except that the <perms> field is omitted because all rules for the rule type are removed.\n\nIt is also possible to remove all ACLs for a file or directory with:\n\nsetfacl --remove-all <file>\n\nTo remove all default ACLs for a directory:\n\nsetfacl --remove-default <dir>\n\nPreserving ACLs\n\nThe NFS and Samba file sharing clients in Red Hat Enterprise Linux recognize and use any ACLs associated with the files shared on the server. If your NFS or Samba clients are not running Red Hat Enterprise Linux, be sure to ask the operating system vendor about ACL support or test your client configuration for support.\n\nThe mv command to move files preserves the ACLs associated with the file. If it can\u2019t for some reason, a warning is displayed. However, the cp command to copy files does not preserve ACLs.\n\nThe tar and dump commands also do not preserve the ACLs associated with files or directories and should not be used to back up or archive files with ACLs. To back up or archive files while preserving ACLs use the star utility. For example, if you are moving a large number of files with ACLs, create an archive of all the files using star, copy the star archive file to the new system or directory, and unarchive the files. Be sure to use getfacl to verify that the ACLs are still associated with the files. The star RPM package must be installed to use the utility. Refer to Chapter 3 for details on package installation via Red Hat Network. The star command is similar to tar. Refer to its man page with the man star command for details. \n\n\n\n\n\n", "timestamp": "2016-05-04T19:02:19.106Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 52, "fields": {"title": null, "content": "\n\nreferences:\n\nhttp://www.woitasen.com.ar/2011/11/auditing-user-actions-after-sudo/", "timestamp": "2016-04-28T14:51:55.578Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 53, "fields": {"title": null, "content": "Changing timezone in CentOS/Redhat 7 is now different from the previous CentOS/Redhat versions. \nThis howto shows how to change the timezone in CentOS/RedHat 7 and previous versions. \n\n\n==Change TimeZone in CentOS/RedHat 7 \n\n===List all available timezones \nTo find list of all available time zones, run:\n<<code>>\n[root@server yum]# timedatectl list-timezones\n<</code>>\n\nA portion of the sample output is as shown below:\n\n<<code>>\n[root@infra-1 yum]# timedatectl list-timezones\nAfrica/Abidjan\nAfrica/Accra\nAfrica/Addis_Ababa\nAfrica/Algiers\nAfrica/Asmara\nAfrica/Bamako\nAfrica/Bangui\nAfrica/Banjul\nAfrica/Bissau\nAfrica/Blantyre\nAfrica/Brazzaville\nAfrica/Bujumbura\nAfrica/Cairo\nAfrica/Casablanca\nAfrica/Ceuta\nAfrica/Conakry\nAfrica/Dakar\n<</code>>\n\n==Set the timezone \nNow that we know what the names of the timezones are, we can now set the timezone. For example from the above command we want to set timezone to Europe/Madrid:\n\n<<code>>\n[root@server yum]# timedatectl set-timezone Europe/Madrid\n<</code>>\n\n<<alertinfo>>\nThe timedatectl command simply really just updates the symlink /etc/localtime as shown below.\n<</alertinfo>>\n\n<<code>>\n[root@server ]# ls -al /etc/localtime\nlrwxrwxrwx. 1 root root 35 May  1  2016 /etc/localtime -> ../usr/share/zoneinfo/Europe/Madrid\n<</code>>\n\n==Change or Set timezone in CentOS/RedHat 6.x\n\nUnlike in the latest CentOS/RedHat we do not have a timedatectl command. Instead we simply have an /etc/localtime symlink to a file in /usr/share/zoneinfo. So to change timezone , you must first find the timezone file in /usr/share/zoneinfo. \n\n===Find the timezone file \nThe following example gives you an idea of how to find the timezone file:\n\n<<code>>\nroot@server yum]# cd /usr/share/zoneinfo/\n[root@server zoneinfo]# ls\nAfrica      Arctic    Australia  CST6CDT  Cuba  EST5EDT  Etc     GB-Eire  GMT-0      HST       Indian  Jamaica    Libya  MST7MDT  NZ-CHAT  PST8PDT  Portugal  Singapore  US         W-SU  iso3166.tab  right America     Asia      Brazil     Canada   EET   Egypt    Europe  GMT      GMT0       Hongkong  Iran    Japan      MET    Mexico   Navajo   Pacific  ROC       Turkey     UTC        WET   posix        zone.tab Antarctica  Atlantic  CET        Chile    EST   Eire     GB      GMT+0    Greenwich  Iceland   Israel  Kwajalein  MST    NZ       PRC      Poland   ROK       UCT        Universal  Zulu  posixrules\n[root@server zoneinfo]#\n<</code>>\n\n<<alertinfo>>\nNote that /usr/share/zoneinfo as shown above also have subdirectories. So if you do not recognise a usable timezone file, dig down into the directories. For example, the file /usr/share/zoneinfo/America/New_York represents time zone for New York.\n\n<</alertinfo>>\n\n===Symlink /etc/localtime to the timezone file. \n\nFor example lets say we have decided we want to share our server to America/New_York and the timezone file is /usr/share/zoneinfo/America/New_York. \n\nSo first remove the /etc/timezone\n<<code>>\nroot@server yum]# rm /etc/localtime\n<</code>>\nFollow that with creating the symlink:\n<<code>>\nroot@server yum]# ln -s /usr/share/zoneinfo/America/New_York /etc/localtime \n<</code>>", "timestamp": "2018-03-22T19:46:09.632Z", "markup": 1, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 54, "fields": {"title": null, "content": "There will be times when you will want to schedule some task to automatically occur in the future. There are 2 solutions that are available that let\u2019s you do this \u201cat\u201d, and \u201ccron\u201d. The \u201cat\u201d utility is designed for scheduling an adhoc job, e.g. perform a patch installation at 9pm on Sunday. Whereas the \u201ccron\u201d utility is designed for scheduling a job that needs to be repeated on a regular basis, e.g. take backups at 5am every morning.\n\n\nThere are two  ways to create cron jobs:\n\n* Add an entry to the /etc/crontab file by using the crontab -e command. \n* Put scripts in /etc/cron.hourly, /etc/cron.daily, /etc/cron.weekly, or /etc/cron.monthly directories. This is via anacron.\n\n==Schedule jobs by editing /etc/crontab with the \"crontab -e\" command\n\n<<alertinfo>>\nDo not edit the /etc/crontab file directly. Instead use the command \"crontab -e\". However we can view the file with the cat command\n<</alertinfo>>\n\n<<code>>\n[root@server  zoneinfo]# cat /etc/crontab\nSHELL=/bin/bash\nPATH=/sbin:/bin:/usr/sbin:/usr/bin\nMAILTO=root\n\n# For details see man 4 crontabs\n\n# Example of job definition:\n# .---------------- minute (0 - 59)\n# |  .------------- hour (0 - 23)\n# |  |  .---------- day of month (1 - 31)\n# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...\n# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat\n# |  |  |  |  |\n# *  *  *  *  * user-name  command to be executed\n\n<</code>>", "timestamp": "2016-04-30T23:25:46.240Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 55, "fields": {"title": null, "content": "OSX is a great development platform in my opinion. If you are like me, you probably develop code that ends up being deployed to linux servers on the net and as a result your recourse is to make use of virtual machine whether it be VMware Fusion or VirtualBox on your Mac.  Vagrant is a great tool that helps in building virtual machines from a given template. This article describes how to install and introduce you to vagrant. \n\n==Installing Vagrant\n\n[[https://www.vagrantup.com/downloads.html | Download the latest installer ]] from the vagrant website. The binary will get installed in the Applications folder with a s link to the /usr/bin so its added to your default $PATH.\n\n<<alertinfo>>\nUser data  is stored in your $HOME/.vagrant.d. \n<</alertinfo>>\n\n", "timestamp": "2016-05-01T20:51:35.478Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 56, "fields": {"title": null, "content": "If you're anything like me, you probably log in and out of a half dozen remote servers (or these days, local virtual machines) on a daily basis. And if you're even more like me, you have trouble remembering all of the various usernames, remote addresses and command line options for things like specifying a non-standard connection port or forwarding local ports to the remote machine.\n\n==Shell Aliases\nLet's say that you have a remote server named dev.example.com, which has not been set up with public/private keys for password-less logins. The username to the remote account is fooey, and to reduce the number of scripted login attempts, you've decided to change the default SSH port to 2200 from the normal default of 22. This means that a typical command would look like:\n\n$ ssh fooey@dev.example.com -p 22000\npassword: *************\nNot too bad.\n\nWe can make things simpler and more secure by using a public/private key pair; I highly recommend using ssh-copy-id for moving your public keys around. It will save you quite a few folder/file permission headaches.\n\n$ ssh fooey@dev.example.com -p 22000\n# Assuming your keys are properly setup\u2026\nNow this doesn't seem all that bad. To cut down on the verbosity you could create a simple alias in your shell as well:\n\n$ alias dev='ssh fooey@dev.example.com -p 22000'\n$ dev # To connect\nThis works surprisingly well: Every new server you need to connect to, just add an alias to your .bashrc (or .zshrc if you hang with the cool kids), and voil\u00e0.\n\n~/.ssh/config\nHowever, there's a much more elegant and flexible solution to this problem. Enter the SSH config file:\n\n# contents of $HOME/.ssh/config\nHost dev\n    HostName dev.example.com\n    Port 22000\n    User fooey\nThis means that I can simply $ ssh dev, and the options will be read from the configuration file. Easy peasy. Let's see what else we can do with just a few simple configuration directives.\n\nPersonally, I use quite a few public/private keypairs for the various servers and services that I use, to ensure that in the event of having one of my keys compromised the damage is as restricted as possible. For example, I have a key that I use uniquely for my Github account. Let's set it up so that that particular private key is used for all my github-related operations:\n\n<<code>>\nHost dev\n    HostName dev.example.com\n    Port 22000\n    User fooey</p>\nHost github.com\n    IdentityFile ~/.ssh/github.key\n<</code>>\n\nThe use of IdentityFile allows me to specify exactly which private key I wish to use for authentification with the given host. You can, of course, simply specify this as a command line option for \"normal\" connections:\n\n$ ssh -i ~/.ssh/blah.key username@host.com\nbut the use of a config file with IdentityFile is pretty much your only option if you want to specify which identity to use for any git commands. This also opens up the very interesting concept of further segmenting your github keys on something like a per-project or per-organization basis:\n\nHost github-project1\n    User git\n    HostName github.com\n    IdentityFile ~/.ssh/github.project1.key</p>\nHost github-org\n    User git\n    HostName github.com\n    IdentityFile ~/.ssh/github.org.key</p>\nHost github.com\n    User git\n    IdentityFile ~/.ssh/github.key\nWhich means that if I want to clone a repository using my organization credentials, I would use the following:\n\n$ git clone git@github-org:orgname/some_repository.git\nGoing further\nAs any security-conscious developer would do, I set up firewalls on all of my servers and make them as restrictive as possible; in many cases, this means that the only ports that I leave open are 80/443 (for webservers), and port 22 for SSH (or whatever I might have remapped it to for obfuscation purposes). On the surface, this seems to prevent me from using things like a desktop MySQL GUI client, which expect port 3306 to be open and accessible on the remote server in question. The informed reader will note, however, that a simple local port forward can save you:\n\n$ ssh -f -N -L 9906:127.0.0.1:3306 coolio@database.example.com\n# -f puts ssh in background\n# -N makes it not execute a remote command\nThis will forward all local port 9906 traffic to port 3306 on the remote dev.example.com server, letting me point my desktop GUI to localhost (127.0.0.1:9906) and have it behave exactly as if I had exposed port 3306 on the remote server and connected directly to it.\n\nNow I don't know about you, but remembering that sequence of flags and options for SSH can be a complete pain. Luckily, our config file can help alleviate that:\n\nHost tunnel\n    HostName database.example.com\n    IdentityFile ~/.ssh/coolio.example.key\n    LocalForward 9906 127.0.0.1:3306\n    User coolio\nWhich means I can simply do:\n\n$ ssh -f -N tunnel\nAnd my local port forwarding will be enabled using all of the configuration directives I set up for the tunnel host. Slick.\n\nHomework\nThere are quite a few configuration options that you can specify in ~/.ssh/config, and I highly suggest consulting the online documentation or the ssh_config man page. Some interesting/useful things that you can do include: change the default number of connection attempts, specify local environment variables to be passed to the remote server upon connection, and even the use of * and ? wildcards for matching hosts.\n\nI hope that some of this is useful to a few of you. Leave a note in the comments if you have any cool tricks for the SSH config file; I'm always on the lookout for fun hacks.\n", "timestamp": "2016-05-06T13:07:02.022Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 57, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2017-02-28T13:38:56.262Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 58, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2017-02-28T13:39:24.655Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 59, "fields": {"title": null, "content": "Here is the step by step instructions on how to install phpPgAdmin on Centos 7. PostgreSQL is a great database and phpPgAdmin is a web-based administration tool for PostgreSQL. Probably most postgresql DBA's will use the command line or pgadmin3 but if you are like me, using postgresql in a vps webserver somewhere then phpPgAdmin is a great timesaver tool. \n\n==Install the required packages.\nYou need to have epel repository available on your server. If you do not have it then install it , [[https://fedoraproject.org/wiki/EPEL | Click here to take you to Fedora Project website on how to install EPEL repo]] and come back here when done.\n\nIn this section we are going to assume you are using the default http server and php packages that comes with CentOS 7.  the command below will install phpPgAdmin including php and the webserver. If the default httpd and php are already installed then the command will simply skip them. \n\n<<code>>\n yum -y install phpPgAdmin php-pgsql httpd php\n<</code>>\n\n== Allow Apache/PHP to be able to connect to database if using selinux . \nIf selinux is enabled then you need to set selinux to allow httpd to connect to your database via network sockets.\n\n<<code>>\nsetsebool -P httpd_can_network_connect_db on\nsetsebool -P httpd_can_network_connect on\n<</code>>\n\n==Configure phpPgAdmin to connect to your local postgresql database\nEdit  /etc/phpPgAdmin/config.inc.php file, we have to modify the admin file to enable the browser access.\n\n<<code>>\nvi /etc/phpPgAdmin/config.inc.php\n<</code>>\n\nAdd the localhost in the following server parameter.\n<<code>>\n$conf['servers'][0]['host'] = 'localhost';\n<</code>>\n\nIf extra login security is true, then logins via phpPgAdmin with no password or certain usernames (pgsql, postgres, root, administrator) will be denied. To enable the postgres login, change it to false.\n<<code>>\n$conf['extra_login_security'] = false;\n<</code>>\nTo simply hide other databases in the list make following condition to true \u2013 this does not in any way prevent your users from seeing other database by other means.\n\n<<code>>\n$conf['owned_only'] = true;\n<</code>>\n\n==Configuring PostgreSQL:\nphpPgAdmin connects to the local postgresql server via network. We have to configure our postgresql server to accept local connections via md5 authentication. \n\n<<code>>\nvi /var/lib/pgsql/9.3/data/pg_hba.conf\n<</code>>\n\nPlease enter the value as per your requirements inIPv4 and Ipv6 connections and make sure it accepts md5 passwords.\n<<code>>\n# IPv4 local connections:\nhost    all             all             127.0.0.1/32            md5\nhost    all             all             192.168.2.0/24         md5\n# IPv6 local connections:\nhost    all             all             ::1/128                 md5\n<</code>>\n\n==Configuring Apche:\n\nBy-default phpPgAdmin places the web config file in /etc/httpd/conf.d directory; it has the rules and access permission for the web access. In CentOS 7, web access is managed by mod_authz_core.c module; so normal allow or deny rules wont work even if you modify.\n\n<<code>>\nvi /etc/httpd/conf.d/phpPgAdmin.conf\n<</code>>\n\nDefault config will look like below.\n\n<<code>>\nAlias /phpPgAdmin /usr/share/phpPgAdmin\n<Location /phpPgAdmin>\n<IfModule mod_authz_core.c>\n# Apache 2.4\nRequire local\n#Require host example.com\n</IfModule>\n<IfModule !mod_authz_core.c>\n# Apache 2.2\nOrder deny,allow\nDeny from all\nAllow from 127.0.0.1\nAllow from ::1\n# Allow from .example.com\n</IfModule>\n</Location>\n<</code>>\n\nPlease comment Require local and add Require all granted just below to commented line, it will look like below.\nAlias /phpPgAdmin /usr/share/phpPgAdmin\n\n<<code>>\n<Location /phpPgAdmin>\n<IfModule mod_authz_core.c>\n# Apache 2.4\n# Require local\nRequire all granted\n#Require host example.com\n</IfModule>\n<IfModule !mod_authz_core.c>\n# Apache 2.2\nOrder deny,allow\nDeny from all\nAllow from 127.0.0.1\nAllow from ::1\n# Allow from .example.com\n</IfModule>\n</Location>\n<</code>>\n\nRestart the services.\n\n<<code>>\nsystemctl restart postgresql-9.3.service\nsystemctl restart httpd.service\n<</code>>\n\n==Congratulations you have installed phpPgAdmin\n\nYou can now browse to your server IP via a browser and you should get the following page:\n\n<<image description=\"Fig1: We can now browse the phpPgAdmin page via our server's IP.\">>\nphpPgAdmin_login.png\n<</image>>\n\n<<image description=\"Fig2: After login, In this example, the user jnvilo has only 1 database called test_database.\">>\nphpPgAdmin_page.png\n<</image>>", "timestamp": "2017-02-28T13:42:00.429Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 60, "fields": {"title": null, "content": "Installing PostgreSQL on a Centos 6.5 is as simple as \"yum install postgresql\" but you're probably here because you want to install a newer version of PostgreSQL and also want more information on how to configure it.  I Do not use the stock postgresql myself. I always want the latest. Centos 6.X ships with postgresql 8.4.13 but postgresql 9.x has been out for a while now. So In this howto, we are going to be installing Postgresql 9.3. \n\n\n==Add the PostGres Yum repository \n\n<<code ext=\"bash\">>\nrpm -Uvh http://yum.postgresql.org/9.3/redhat/rhel-6-x86_64/pgdg-redhat93-9.3-1.noarch.rpm\n<</code>>\n\n==Install PostgreSQL Server\nSince we added the postgres repo, we can now install rpms' from it. Use following command to install PostgreSQL on your system with yum package manager.\n\n<<code ext=\"bash\">>\n# yum install postgresql93-server postgresql93\n<</code>>\n\nIf you are going to be using python's psycopg2 then you will also probably need the devel. \n<<code ext=\"bash\">>\nyum install postgresql93-devel\n<</code>>\n\n\n==Initialize PGDATA\n\nAfter installing PostgreSQL server, It\u2019s required to initialize it before using first time. To initialize database use below command.\n\n<<code ext=\"bash\">>\n# /etc/init.d/postgresql-9.3 initdb\n<</code>>\n\nIn some cases above commands doesn't work, Then use following command.\n\n<<code ext=\"bash\">>\n# /usr/pgsql-9.3/bin/postgresql93-setup initdb\n<</code>>\n\nAbove command will take some time to initialize PostgreSQL first time. PGDATA environment variable contains path of data directory.\nPostgreSQL data directory Path: /var/lib/pgsql/9.3/data/\n\n==Start PostgreSQL Server\n\nStart PostgreSQL service using following command.\n<<code ext=\"bash\">>\n# service postgresql-9.3 start\n<</code>>\n\n==Setup PostgreSQL service to auto start on system boot.\n\n<<code ext=\"bash\">>\n# chkconfig postgresql-9.3 on\n<</code>>\n\n\n==Verify PostgreSQL Installation\nAfter completing step 4, we have installed postgres 9.3 on server, Let do a basic test to verify that installation completed successfully. To verify switch to postgres user.\n<<code ext=\"bash\">>\n# su - postgres\n<</code>>\n\n\n==Use psql command to access PostgreSQL prompt with admin privileges.\n\n<<code ext=\"bash\">>\n$ psql\n\npsql (9.3.1)\nType \"help\" for help.\n\npostgres=#\n<</code>>\n\nCongratulation\u2019s! You have successfully installed PostgreSQL Server. Read below article to install phpPgAdmin.\n\n[[http://www.jnvilo.com/cms/sysadmin/databases/postgresql/install-phppgadmin-on-centos-7| Install phpPgAdmin on Centos 7]] . The title says Centos 7 but it is exactly applicable to Centos 6\n", "timestamp": "2017-02-28T13:43:26.181Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 61, "fields": {"title": null, "content": "Every installation of postgresql datbases comes with the command line tools pg_dump and pg_restore. With this two commands we have all that we need to backup and restore our databases. Of course there are also graphical tools that we can use to backup and restore. \n\n==Backup and restore with pg_dump and pg_restore. \n\nThe TLDR; is as sample as: \n\nFor text file backups: \n\n<<code ext=\"bash\">>\nBackup:  $ pg_dump -U {user-name} {source_db} -f {dumpfilename.sql}\nRestore: $ psql -U {user-name} -d {desintation_db}-f {dumpfilename.sql}\n<</code>>\n\nFor tar.gz backups: \n\n<<code ext=\"bash\">>\nBackup:  $ pg_dump -U {user-name} {source_db} -F tar  -f {dumpfilename.tar.gz}\nRestore: $ psql -U {user-name} -d {desintation_db}-f {dumpfilename.tar.gz}\n<</code>>\n\n== Backup A Single Database\n\nThe following command will backup the \"mydatabase\" that belongs to \"dbuser\" to the file mybackup.sql\n\n<<code ext=\"bash\">>\npg_dump -h 127.0.0.1 -U dbuser mydatabase -f mybackup.sql\n<</code>>\n\nYou will be prompted for the password. If you were going to put this in a script, then you can set the environment variable PGPASSWORD and pg_dump will use it instead of prompting you as follows:\n\n<<code ext=\"bash\">>\nPGPASSWORD=\"mypassword\" \npg_dump -h 127.0.0.1 -U dbuser mydatabase -f mybackup.sql\n<</code>>\n\n== Restoring the backup\n\nAbove we created our backup.\n\nTo restore the .sql file backup assuming the database already exists:\n\n<<code ext=\"bash\">>\npg_restore -h 127.0.0.1 -U dbuser  -d mydatabase mybackup.sql\n<</code>>\n\nIf the database does not yet exist. (For example we are restoring to a new server)\n\n<<code ext=\"bash\">>\npg_restore -h 127.0.0.1 -U dbuser  -C -d  mydatabase mybackup.sql\n<</code>>", "timestamp": "2018-03-25T09:34:39.915Z", "markup": 1, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 62, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2017-03-21T20:28:48.858Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 63, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2017-03-21T20:29:26.660Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 64, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2017-03-21T20:30:29.425Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 65, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2017-03-21T20:31:18.628Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 66, "fields": {"title": null, "content": "= Steps to setup VMware ESX within a KVM VM\n\n==Install Linux on a physical system (I used latest Ubuntu 14.04)\n    Install the qemu/kvm package \n\n <<code>>apt-get install qemu-kvm<</code>>\n\n     Edit /etc/modprobe.d/kvm-intel (or kvm-amd for AMD cpus) and add\n\n<<code>>\n       options kvm ignore_msrs=1\n       options kvm-intel nested=y ept=y\n<</code>>\n\n== Setup QEMU\n\nDownload qemu-2.0.0 from http://wiki.qemu.org/Download and apply the following patch to hw/i386/pc_piix4.c line 206. Change\n\n<<code>>\n   pc_basic_device_init(isa_bus, gsi, &rtc_state, &floppy, xen_enabled(),\n      0x4);\n<</code>>\n          to\n<<code>>\n   pc_basic_device_init(isa_bus, gsi, &rtc_state, &floppy, TRUE,\n       0x4);\n<</code>>\n\n Configure the qemu 2.0.0 source with the following command:\n\n<<code>>\n./configure --enable-kvm --target-list=x86_64-linux-user,x86_64-softmmu\n<</code>>\n\n   Create /usr/local/etc/qemu/bridge.conf\n\n<<code>>\n                     allow all\n<</code>>\n\n==Install the bridge-utils package\n\n<<code>>\n                    apt-get install bridge-utils\n<</code>>\n\nConfigure a network bridge in /etc/network/interfaces as following:\n\n<<code>>\nauto br0\niface br0 inet static\naddress 192.168.88.135\nnetmask 255.255.255.0\nnetwork 192.168.88.0\nbroadcast 192.168.88.255\ngateway 192.168.88.1\ndns-nameservers 192.168.88.1\nbridge_ports eth0\nbridge_fd 0\nbridge_hello 2\nbridge_maxage 12\nbridge_stp off\n <</code>>\n\n Please notice that your ip-configuration may be different\n\n  Choose a directory for the KVM virtual machine and create the virtual machine harddisk with the following qemu-img command:\n\n<<code>>\n qemu-img create -f raw esxi00.img 16G\n<</code>>\n\n==VMWare ESX Hypervisor install \n\nDownload VMware ESX Hypervisor 5.5 from the VMware website and put the install iso file (VMware-VMvisor-Installer-5.5.0.update01-1623387.x86_64.iso) into the same directory as the harddisk file was created a step before\n\n===Start the KVM virtual machine with:\n\n<<code>>\n/usr/local/bin/qemu-system-x86_64 -enable-kvm -cpu host -m 4096 -smp 2 -cdrom VMware-VMvisor-Installer-5.5.0.update01-1623387.x86_64.iso -netdev tap,helper=/usr/local/libexec/qemu-bridge-helper,id=hostnet0 -device vmxnet3,netdev=hostnet0,id=net0 -hda esxi00.img\n<</code>>\n\nPlease notice the \"vmxnet3\" virtual network device type!\n\nGo through the (normal) VMware ESX installation procedure\n After the installation enable the SSH service on the ESX Host with is now running with the KVM VM. Then ssh into the ESX Host and set the following two parameters in /etc/vmware/config:\n\n<<code>> \n      vhv.allow = \"TRUE\"\n      hv.assumeEnabled=\"TRUE\"\n<</code>>\n\nNow please reboot the ESX Host system to activate the new configuration!\n\nWhen creating a virtual machine on the (nested virtualized) ESX Host please make sure to add the following two parameters to the VM's vmx configuration file:\n\n<<code>>\n                       vhv.enable = \"TRUE\"\n                       vmx.allowNested = \"TRUE\"\n<</code>>\n\nCongratulations! \n\nYou have successfully virtualized a VMware ESX Hypervisor with KVM!\n\nI hope you now enjoy your fully functional VMware ESX Host\n\nAdditional informations on the VMware parameters used in this howto\n\n<<code>>\n    vhv.allow = \"TRUE\" does nothing on ESX 5.1 and later\n    vhv.enable = \"TRUE\" is only going to be useful if you want to run VMs under the VMs running under ESXi running under lvm\n<</code>>    \n\nYou can add vmx.allowNested = \"TRUE\" to /etc/vmware/config in the ESXi VM to avoid having to put it in every nested VM's configuration file.\n\nThis quick howto was created with informations from https://communities.vmware.com/thread/451412", "timestamp": "2017-03-21T21:36:31.617Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 67, "fields": {"title": null, "content": "==Step1:  Add a second virtual disk using virt-manager. \n\nOpen the virtualmachine and click View->Details and click the button at the bottom left \"+Add Hardware\" select Storage and ensure Bus_Type is virtio.\n\nif you now do dmesg you will see that a new disk has been created.\n\ndoing fdisk -l will show that we have a new disk vdb\n<<code ext=bash>>\n[root@rhel-lab1 ~]# fdisk -l\n\nDisk /dev/vda: 8589 MB, 8589934592 bytes\n16 heads, 63 sectors/track, 16644 cylinders\nUnits = cylinders of 1008 * 512 = 516096 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x00010ce0\n\n   Device Boot      Start         End      Blocks   Id  System\n/dev/vda1   *           3        1018      512000   83  Linux\nPartition 1 does not end on cylinder boundary.\n/dev/vda2            1018       16645     7875584   8e  Linux LVM\nPartition 2 does not end on cylinder boundary.\n\nDisk /dev/mapper/vg_rhellab1-lv_root: 7205 MB, 7205814272 bytes\n255 heads, 63 sectors/track, 876 cylinders\nUnits = cylinders of 16065 * 512 = 8225280 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x00000000\n\n\nDisk /dev/mapper/vg_rhellab1-lv_swap: 855 MB, 855638016 bytes\n255 heads, 63 sectors/track, 104 cylinders\nUnits = cylinders of 16065 * 512 = 8225280 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x00000000\n\nDisk /dev/vdb: 8589 MB, 8589934592 bytes\n16 heads, 63 sectors/track, 16644 cylinders\nUnits = cylinders of 1008 * 512 = 516096 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x00000000\n<</code>>\n\n=== Create 1 partition on /dev/vdb\n\nNormally this should not be needed and we could just use /dev/vdb but it is good practice to use a partition \n<<code ext=bash>>\n[root@rhel-lab1 ~]# fdisk /dev/vdb\n<</code>>\n\n==  Extend the VolumeGroup that contains the / to this new PhysicalVolume\n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# pvcreate /dev/vdb1\n  Physical volume \"/dev/vdb1\" successfully created\n[root@rhel-lab1 ~]# pvdisplay\n  --- Physical volume ---\n  PV Name               /dev/vda2\n  VG Name               vg_rhellab1\n  PV Size               7.51 GiB / not usable 3.00 MiB\n  Allocatable           yes (but full)\n  PE Size               4.00 MiB\n  Total PE              1922\n  Free PE               0\n  Allocated PE          1922\n  PV UUID               5V7W0j-e28x-08OO-oZnh-Xkjv-8e09-tYd30m\n   \n  \"/dev/vdb1\" is a new physical volume of \"8.00 GiB\"\n  --- NEW Physical volume ---\n  PV Name               /dev/vdb1\n  VG Name               \n  PV Size               8.00 GiB\n  Allocatable           NO\n  PE Size               0   \n  Total PE              0\n  Free PE               0\n  Allocated PE          0\n  PV UUID               9uigVa-ZsEF-I51J-snNL-2tXn-LvLo-vseIGm\n  <</code>>\n\n== Since our task is to extend the add extra space to the root partition, we need to extend the VolumeGroup that is used by the root partition onto this physical volume.\n\n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# vgextend vg_rhellab1 /dev/vdb1 \n  Volume group \"vg_rhellab1\" successfully extended\n<</code>>\n\nWe can use the **pvscan** command to display our physical volumes and confirm that we now have our VolumeGroup called vg_rhellab1 extended onto the /dev/vdb1\n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# pvscan\n  PV /dev/vda2   VG vg_rhellab1   lvm2 [7.51 GiB / 0    free]\n  PV /dev/vdb1   VG vg_rhellab1   lvm2 [8.00 GiB / 8.00 GiB free]\n  Total: 2 [15.50 GiB] / in use: 2 [15.50 GiB] / in no VG: 0 [0   ]\n<</code>>\n\n== Extend the Logical Volume. \n\nAt this point if you do df, the root partition is still the same size as it was. We have the final step of extending the logical volume for the root partitionthat resides on vg_rhellab1.\n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# lvdisplay \n  --- Logical volume ---\n  LV Path                /dev/vg_rhellab1/lv_root\n  LV Name                lv_root\n  VG Name                vg_rhellab1\n  LV UUID                WZOdt5-iZuV-ZD0j-aEG1-kGMT-MJ5m-rqTlQp\n  LV Write Access        read/write\n  LV Creation host, time rhel-lab1.localhost, 2014-12-16 09:23:07 +0100\n  LV Status              available\n  # open                 1\n  LV Size                6.71 GiB\n  Current LE             1718\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           253:0\n   \n  --- Logical volume ---\n  LV Path                /dev/vg_rhellab1/lv_swap\n  LV Name                lv_swap\n  VG Name                vg_rhellab1\n  LV UUID                sa8S0F-g2Mk-TRw6-5VSa-bKce-9jvA-DodNiI\n  LV Write Access        read/write\n  LV Creation host, time rhel-lab1.localhost, 2014-12-16 09:23:10 +0100\n  LV Status              available\n  # open                 1\n  LV Size                816.00 MiB\n  Current LE             204\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           253:1\n  <</code>>\n\n*And now we arrive to the final step lvextend*\n\n<<code ext=bash>>\n[root@rhel-lab1 ~]# lvextend -L +4G /dev/vg_rhellab1/lv_root /dev/vdb1 \n  Extending logical volume lv_root to 10.71 GiB\n  Logical volume lv_root successfully resized\n[root@rhel-lab1 ~]# lvdisplay\n  --- Logical volume ---\n  LV Path                /dev/vg_rhellab1/lv_root\n  LV Name                lv_root\n  VG Name                vg_rhellab1\n  LV UUID                WZOdt5-iZuV-ZD0j-aEG1-kGMT-MJ5m-rqTlQp\n  LV Write Access        read/write\n  LV Creation host, time rhel-lab1.localhost, 2014-12-16 09:23:07 +0100\n  LV Status              available\n  # open                 1\n  LV Size                10.71 GiB\n  Current LE             2742\n  Segments               2\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           253:0\n   \n  --- Logical volume ---\n  LV Path                /dev/vg_rhellab1/lv_swap\n  LV Name                lv_swap\n  VG Name                vg_rhellab1\n  LV UUID                sa8S0F-g2Mk-TRw6-5VSa-bKce-9jvA-DodNiI\n  LV Write Access        read/write\n  LV Creation host, time rhel-lab1.localhost, 2014-12-16 09:23:10 +0100\n  LV Status              available\n  # open                 1\n  LV Size                816.00 MiB\n  Current LE             204\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           253:1\n <</code>>  \n\nWe can see that the lv_root has grown but if we do a **du -h** the disk size is still small. We have one more step: **resize2fs**\n\n<<code ext=bash>>\nFilesystem at /dev/vg_rhellab1/lv_root is mounted on /; on-line resizing required\nold desc_blocks = 1, new_desc_blocks = 1\nPerforming an on-line resize of /dev/vg_rhellab1/lv_root to 2807808 (4k) blocks.\nThe filesystem on /dev/vg_rhellab1/lv_root is now 2807808 blocks long.\n\n[root@rhel-lab1 ~]# df -h\nFilesystem                       Size  Used Avail Use% Mounted on\n/dev/mapper/vg_rhellab1-lv_root   11G  1.3G  8.8G  13% /\ntmpfs                            499M     0  499M   0% /dev/shm\n/dev/vda1                        485M   33M  427M   8% /boot\n\n<</code>>", "timestamp": "2017-03-21T21:37:51.559Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 68, "fields": {"title": null, "content": "The gui virt-manager is nice to have and helps us manage/create KVM guests easily, but today I ran into a situation where X and VNC was not installed on the host and I was not allowed to install them. As a result, had to resort to command line tools to do the task. This tutorial/howto documents all the required knowledge to install , clone, edit KVM machines using the command line. \n\n== The required tools\n\nWe shall need the virt-install command line tool so if that is not available go ahead and as root or with sudo install it., \n\n<<code ext=None>>\nyum install virt-install \n<</code>>\n\nvirt-install has a lot of options and you can have a look with **virt-install -h**\n\n\n==Install A Basic KVM Guest Using \n\n<<code ext=None>>\nvirt-install \\\n   --name=guest1-rhel6 \\\n   --file=/var/lib/libvirt/images/guest1-rhel6.dsk \\\n   --file-size=8 \\\n   --nonsparse --graphics spice \\\n   --vcpus=2 --ram=2048 \\\n   --cdrom=/var/lib/libvirt/images/CentOS-6.5-x86_64-bin-DVD1.iso \\\n   --os-type=linux \\\n   --os-variant=rhel6\n\nStarting install...\nAllocating 'guest1-rhel6.dsk'                                                                                                                                                            | 8.0 GB  00:00:00     \nCreating domain...                                                                                                                                                                       |    0 B  00:00:00     \nWARNING  Unable to connect to graphical console: virt-viewer not installed. Please install the 'virt-viewer' package.\nDomain installation still in progress. You can reconnect to \nthe console to complete the installation process.\n<</code>>\n\nThe above command will create a VM and starts the installation process. The problem is that you will still need a GUI such as virt-manager to be able to continue the installation. What we need to do is to use a **kickstart** file to do an unattended installation.\n\n==Installing the KVM Guest using Kickstart.\n\nFirst we need to create a kickstart. The simplest way is to use **system-config-kickstart** so let's install it if we don't have it. \n\n<<code ext=bash>>\nyum install system-config-kickstart\n<</code>>\n\nUsing system-config-kickstart, I created a simple kickstart file as shown below:\n\n<<code ext=bash>>\n#platform=x86, AMD64, or Intel EM64T\n#version=DEVEL\n# Install OS instead of upgrade\ninstall\n# Keyboard layouts\nkeyboard 'us'\n# Reboot after installation\nreboot\n# Root password\nrootpw --iscrypted $1$1MJ9RQhy$kiQRjjvRruQcGFCKTsg5f0\n# System timezone\ntimezone Europe/Madrid --isUtc\n# System language\nlang en_US\n# Firewall configuration\nfirewall --disabled\n# Network information\nnetwork  --bootproto=dhcp --device=eth0\n# System authorization information\nauth  --useshadow  --passalgo=sha512\n# Use CDROM installation media\ncdrom\n# Use text mode install\ntext\nfirstboot --disable\n# SELinux configuration\nselinux --enforcing\n\n# System bootloader configuration\nbootloader --location=mbr\n# Clear the Master Boot Record\nzerombr\n# Partition clearing information\nclearpart --all --initlabel\n<</code>>\n\nNow that we have a  kickstart file, we need a webserver to put it on. This is out of the scope of this tutorial. In my case, i simply installed httpd on the KVM host \n", "timestamp": "2017-03-21T21:38:51.364Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 69, "fields": {"title": null, "content": "This blog post tackles the  use of the _ in Python. You surely have seen variables like _foo or method names such as _bar or the most common __baz__. You may also have seen _ by itself. In this post we shall see the different usages of _ . \n\n==Single Underscore   _ \n\n===In the interactive interpreter \n\nWhen running the interactive interpreter via python or ipython, the _ variable contains the result of the last executed statement. \n\n<<code ext=.py>>\n>>> a,b=5,4\n>>> a+b\n9\n>>> _\n9\n>>> \n<</code>>\n\n=== As a variable name\n\nYou may have seen code like this:\n\n<<code ext=.py>>\n  instance, _ = function_returns_a_tuple()\n<</code>>\n\nIn the above code, the function returns a tuple of 2 values but the programmer is interested only in the first result, so he uses the _ to assign the second result to. The _ is used as a throwaway variable. We don't care what it contains but instead of putting a proper name of it, we use _ to signify to the next programmer reading our code that we do not use the second variable. \n\nAnother example is in a for loop. [Some might say looping like this is not pythonic but it illiustrates the point:\n\n<<code ext=python>>\nfor _ in range(5):\n     function_called_5_times_in_the_loop()\n<</code>>\n\n===Used as a function name\n\nFor some reason the convention to create internationalization functions and use _ as the name has become the norm. This was copied from a corresponding C convention. We can see this in the django documentation for example:\n\n<<code ext=python>>\nfrom django.utils.translation import ugettext as _\nfrom django.http import HttpResponse\n\ndef my_view(request):\n    output = _(\"Welcome to jnvilo.com.\")\n    return HttpResponse(output)\n<</code>>\n\n\n==Prefix A Variable Name with _ \n\nHave you ever seen variable names like:\n<<code ext=python>>\nclass MyClass(object):\n    def __init__(self, foo, bar):\n         self._foo = foo\n         self._bar = bar\n<</code>>\n\nIn the above code we see the internal instance variables _foo, _bar starting with _.  This is a convention used so that anyone using the class and reading the code knows that variables starting with _ are internal implementation only and can change in the next iteration of the MyClass. \n\n<<alert-info>>\na name prefixed with an underscore (e.g. _spam) should be treated as a non-public part of the API (whether it is a function, a method or a data member). It should be considered an implementation detail and subject to change without notice.\n\n* I say kind of a convention because it actually does mean something to the interpreter; if you from <module/package> import *, none of the names that start with an _ will be imported unless the module\u2019s/package\u2019s __all__ list explicitly contains them. See \u201cImporting * in Python\u201d for more on this.\n<</alert-info>>\n\n== Double Underscore Before a Name. The \"Dunder\" names. \n\nThe use of doubler underscores __ to prefix a varialbe name or method is not a convention. When the python interpreter encounters a  method name starting with __, it mangles these names to avoid clashes with names defined by subclasses. \n\n<<code ext=python>>\n>>> class A(object):\n...     def __dunder(self):\n...             print(\"I AM A\")\n... \n>>> dir(A)\n['_A__dunder', '__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__']\n<</code>>\n\nThe exercise above shows that __dunder has been replaced with _A_dunder. If we now update our class A to call __dunder() we can see:\n\n<<code>>\n>>> class A(object):\n...     def call_dunder(self):\n...             self.__dunder()\n...     def __dunder(self):\n...             print(\"I AM A\")\n... \n>>> A().call_dunder()\nI AM A\n>>\n<</code>>\n\nNothing is different. Underneath python has replaced the self.__dunder() to self._A_dunder(). We can further see what happens when now A is subclassed by B. \n\n<<code ext=python>>\n>>> class B(A):\n...     def b_calls_dunder(self):\n...             self.__dunder()\n... \n>>> B().b_calls_dunder()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"<stdin>\", line 3, in b_calls_dunder\nAttributeError: 'B' object has no attribute '_B__dunder'\n<</code>>\n\nPython tried to call _B_dunder. It did not call the __dunder method defined in A. \n\n==Finally Double Underscores Before and After a Name. \n\nYou are not supposed to use these. These are special method names used by Python. This is however just a convention where Python system. Internal methods have the format __foo__ , which you can then overrided in in your classes. \n\nThere is nothing to stop you from writing your own dunder methods like these but by convention, you should not.  Only python defined special names should follow this convention.\n \n", "timestamp": "2017-03-22T07:30:10.245Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 70, "fields": {"title": null, "content": "\"Signals and slots are used for communication between objects. The signals and slots mechanism is a central feature of Qt and probably the part that differs most from the features provided by other frameworks\". I literally copied that off from the QT Signals and Slots documentation. Until recently I didn't really use signal and slots much in my python code. I knew about them but did not really see the need. Until I started using QT and realized how great they are at decoupling my classes. \n\nBelow is an implemntation that I use a lot.  I have edited this page. And more edits are coming.\n\n<<code ext=\"python\">>\nfrom __future__ import print_function\nimport inspect\nfrom weakref import WeakSet, WeakKeyDictionary\n\nclass Signal(object): \n    def __init__(self):\n        self._functions = WeakSet()\n        self._methods = WeakKeyDictionary()\n\n    def __call__(self, *args, **kargs):\n        # Call handler functions\n        for func in self._functions:\n            func(*args, **kargs)\n\n        # Call handler methods\n        for obj, funcs in self._methods.items():\n            for func in funcs:\n                func(obj, *args, **kargs)\n\n    def connect(self, slot):\n        if inspect.ismethod(slot):\n            if slot.__self__ not in self._methods:\n                self._methods[slot.__self__] = set()\n\n            self._methods[slot.__self__].add(slot.__func__)\n\n        else:\n            self._functions.add(slot)\n\n    def disconnect(self, slot):\n        if inspect.ismethod(slot):\n            if slot.__self__ in self._methods:\n                self._methods[slot.__self__].remove(slot.__func__)\n        else:\n            if slot in self._functions:\n                self._functions.remove(slot)\n\n    def clear(self):\n        self._functions.clear()\n        self._methods.clear()\n\n\nclass Emitter(object):\n    \n    def __init__(self):\n        self.changed= Signal()\n        self.second_value_changed = Signal()\n        \n        self.value = None\n        \n    def set_value(self, value):\n        self.changed(value)\n    \n    def set_second_value(self, value):\n        self.second_valued_changed()\n        \nclass Reciever(object):\n    \n    def emitter_updated(self, *args, **kwargs):\n        \n        print(\"Signal recieved\")\n        print(*args)\n        print(**args)\n              \n              \ne = Emitter()\nr = Reciever()\n\ne.changed.connect(r.emitter_updated)\n                                                                                                    \n<</code>>\n\n== Class Emitter\n\nThe \"Emitter\" class is an example of a class that will send a message whenever  \"value\" is changed.  \n\n== Class Receiver\n\nThe \"Receiver\" class has a method called \"emitter_updated\". This receives the signal whenever \"value\" is changed in the \"Emitter\" class. \n\n== Emitter and Receiver are decoupled. \n\nThe code snippet shows the Emitter and the Receiver class know nothing about each other. When we create an instance , we \"connect\" them as follows:\n\n<<code ext=\"python\">>\ne = Emitter()\nr = Reciever()\n\ne.changed.connect(r.emitter_updated)\n<</code>>", "timestamp": "2018-03-28T14:49:49.815Z", "markup": 1, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 71, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2017-09-20T09:13:50.151Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 72, "fields": {"title": null, "content": "No content. Edit me.", "timestamp": "2017-09-20T09:14:45.198Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 73, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:18:39.924Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 74, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:20:20.812Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 75, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:21:03.485Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 76, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:23:42.237Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 77, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:24:42.174Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 78, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:25:49.164Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 79, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:26:15.092Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 80, "fields": {"title": null, "content": "= I would really like to edit this page right now if I could but i do not have the time and I am just testing at the moment so as a result this should just work right now. \n\n==This is an H2 title\n\n=== And as we increate the numbers of equal signs.", "timestamp": "2018-03-27T08:29:33.087Z", "markup": 1, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 81, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:28:12.372Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 82, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:28:29.232Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 83, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:40:54.474Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 84, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:41:30.227Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 85, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:42:47.567Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 86, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:42:55.158Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 87, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:43:40.007Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 88, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:43:47.578Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 89, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T08:52:38.928Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 90, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T09:04:53.211Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 91, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-27T09:05:09.684Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmscontents", "pk": 92, "fields": {"title": null, "content": "New Page. Please Edit Me!!!", "timestamp": "2018-03-28T15:34:54.867Z", "markup": null, "meta_description": "", "page": 1, "tags": []}}, {"model": "mycms.cmspagetypes", "pk": 1, "fields": {"page_type": "SINGLEPAGE", "text": "Single Page HTML", "view_class": "SinglePage", "view_template": "SinglePage.html"}}, {"model": "mycms.cmspagetypes", "pk": 2, "fields": {"page_type": "CATEGORY", "text": "Category Page", "view_class": "CategoryPage", "view_template": "CategoryPage.html"}}, {"model": "mycms.cmspagetypes", "pk": 3, "fields": {"page_type": "MULTIPAGE", "text": "MultPage Article", "view_class": "MultiPage", "view_template": "MultiPage.html"}}, {"model": "mycms.cmspagetypes", "pk": 4, "fields": {"page_type": "MEMBERPAGE", "text": "MemberPage Article", "view_class": "MemberPage", "view_template": "MemberPage.html"}}, {"model": "auth.permission", "pk": 1, "fields": {"name": "Can add log entry", "content_type": 1, "codename": "add_logentry"}}, {"model": "auth.permission", "pk": 2, "fields": {"name": "Can change log entry", "content_type": 1, "codename": "change_logentry"}}, {"model": "auth.permission", "pk": 3, "fields": {"name": "Can delete log entry", "content_type": 1, "codename": "delete_logentry"}}, {"model": "auth.permission", "pk": 4, "fields": {"name": "Can add permission", "content_type": 2, "codename": "add_permission"}}, {"model": "auth.permission", "pk": 5, "fields": {"name": "Can change permission", "content_type": 2, "codename": "change_permission"}}, {"model": "auth.permission", "pk": 6, "fields": {"name": "Can delete permission", "content_type": 2, "codename": "delete_permission"}}, {"model": "auth.permission", "pk": 7, "fields": {"name": "Can add group", "content_type": 3, "codename": "add_group"}}, {"model": "auth.permission", "pk": 8, "fields": {"name": "Can change group", "content_type": 3, "codename": "change_group"}}, {"model": "auth.permission", "pk": 9, "fields": {"name": "Can delete group", "content_type": 3, "codename": "delete_group"}}, {"model": "auth.permission", "pk": 10, "fields": {"name": "Can add user", "content_type": 4, "codename": "add_user"}}, {"model": "auth.permission", "pk": 11, "fields": {"name": "Can change user", "content_type": 4, "codename": "change_user"}}, {"model": "auth.permission", "pk": 12, "fields": {"name": "Can delete user", "content_type": 4, "codename": "delete_user"}}, {"model": "auth.permission", "pk": 13, "fields": {"name": "Can add content type", "content_type": 5, "codename": "add_contenttype"}}, {"model": "auth.permission", "pk": 14, "fields": {"name": "Can change content type", "content_type": 5, "codename": "change_contenttype"}}, {"model": "auth.permission", "pk": 15, "fields": {"name": "Can delete content type", "content_type": 5, "codename": "delete_contenttype"}}, {"model": "auth.permission", "pk": 16, "fields": {"name": "Can add session", "content_type": 6, "codename": "add_session"}}, {"model": "auth.permission", "pk": 17, "fields": {"name": "Can change session", "content_type": 6, "codename": "change_session"}}, {"model": "auth.permission", "pk": 18, "fields": {"name": "Can delete session", "content_type": 6, "codename": "delete_session"}}, {"model": "auth.permission", "pk": 19, "fields": {"name": "Can add cms paths", "content_type": 7, "codename": "add_cmspaths"}}, {"model": "auth.permission", "pk": 20, "fields": {"name": "Can change cms paths", "content_type": 7, "codename": "change_cmspaths"}}, {"model": "auth.permission", "pk": 21, "fields": {"name": "Can delete cms paths", "content_type": 7, "codename": "delete_cmspaths"}}, {"model": "auth.permission", "pk": 22, "fields": {"name": "Can add cms tags", "content_type": 8, "codename": "add_cmstags"}}, {"model": "auth.permission", "pk": 23, "fields": {"name": "Can change cms tags", "content_type": 8, "codename": "change_cmstags"}}, {"model": "auth.permission", "pk": 24, "fields": {"name": "Can delete cms tags", "content_type": 8, "codename": "delete_cmstags"}}, {"model": "auth.permission", "pk": 25, "fields": {"name": "Can add cms mark ups", "content_type": 9, "codename": "add_cmsmarkups"}}, {"model": "auth.permission", "pk": 26, "fields": {"name": "Can change cms mark ups", "content_type": 9, "codename": "change_cmsmarkups"}}, {"model": "auth.permission", "pk": 27, "fields": {"name": "Can delete cms mark ups", "content_type": 9, "codename": "delete_cmsmarkups"}}, {"model": "auth.permission", "pk": 28, "fields": {"name": "Can add cms contents", "content_type": 10, "codename": "add_cmscontents"}}, {"model": "auth.permission", "pk": 29, "fields": {"name": "Can change cms contents", "content_type": 10, "codename": "change_cmscontents"}}, {"model": "auth.permission", "pk": 30, "fields": {"name": "Can delete cms contents", "content_type": 10, "codename": "delete_cmscontents"}}, {"model": "auth.permission", "pk": 31, "fields": {"name": "Can add cms templates", "content_type": 11, "codename": "add_cmstemplates"}}, {"model": "auth.permission", "pk": 32, "fields": {"name": "Can change cms templates", "content_type": 11, "codename": "change_cmstemplates"}}, {"model": "auth.permission", "pk": 33, "fields": {"name": "Can delete cms templates", "content_type": 11, "codename": "delete_cmstemplates"}}, {"model": "auth.permission", "pk": 34, "fields": {"name": "Can add cms page types", "content_type": 12, "codename": "add_cmspagetypes"}}, {"model": "auth.permission", "pk": 35, "fields": {"name": "Can change cms page types", "content_type": 12, "codename": "change_cmspagetypes"}}, {"model": "auth.permission", "pk": 36, "fields": {"name": "Can delete cms page types", "content_type": 12, "codename": "delete_cmspagetypes"}}, {"model": "auth.permission", "pk": 37, "fields": {"name": "Can add cms entries", "content_type": 13, "codename": "add_cmsentries"}}, {"model": "auth.permission", "pk": 38, "fields": {"name": "Can change cms entries", "content_type": 13, "codename": "change_cmsentries"}}, {"model": "auth.permission", "pk": 39, "fields": {"name": "Can delete cms entries", "content_type": 13, "codename": "delete_cmsentries"}}, {"model": "auth.permission", "pk": 40, "fields": {"name": "Can add cms contents", "content_type": 14, "codename": "add_cmscontents"}}, {"model": "auth.permission", "pk": 41, "fields": {"name": "Can change cms contents", "content_type": 14, "codename": "change_cmscontents"}}, {"model": "auth.permission", "pk": 42, "fields": {"name": "Can delete cms contents", "content_type": 14, "codename": "delete_cmscontents"}}, {"model": "auth.permission", "pk": 43, "fields": {"name": "Can add cms entries", "content_type": 15, "codename": "add_cmsentries"}}, {"model": "auth.permission", "pk": 44, "fields": {"name": "Can change cms entries", "content_type": 15, "codename": "change_cmsentries"}}, {"model": "auth.permission", "pk": 45, "fields": {"name": "Can delete cms entries", "content_type": 15, "codename": "delete_cmsentries"}}, {"model": "auth.permission", "pk": 46, "fields": {"name": "Can add cms mark ups", "content_type": 16, "codename": "add_cmsmarkups"}}, {"model": "auth.permission", "pk": 47, "fields": {"name": "Can change cms mark ups", "content_type": 16, "codename": "change_cmsmarkups"}}, {"model": "auth.permission", "pk": 48, "fields": {"name": "Can delete cms mark ups", "content_type": 16, "codename": "delete_cmsmarkups"}}, {"model": "auth.permission", "pk": 49, "fields": {"name": "Can add cms page types", "content_type": 17, "codename": "add_cmspagetypes"}}, {"model": "auth.permission", "pk": 50, "fields": {"name": "Can change cms page types", "content_type": 17, "codename": "change_cmspagetypes"}}, {"model": "auth.permission", "pk": 51, "fields": {"name": "Can delete cms page types", "content_type": 17, "codename": "delete_cmspagetypes"}}, {"model": "auth.permission", "pk": 52, "fields": {"name": "Can add cms paths", "content_type": 18, "codename": "add_cmspaths"}}, {"model": "auth.permission", "pk": 53, "fields": {"name": "Can change cms paths", "content_type": 18, "codename": "change_cmspaths"}}, {"model": "auth.permission", "pk": 54, "fields": {"name": "Can delete cms paths", "content_type": 18, "codename": "delete_cmspaths"}}, {"model": "auth.permission", "pk": 55, "fields": {"name": "Can add cms tags", "content_type": 19, "codename": "add_cmstags"}}, {"model": "auth.permission", "pk": 56, "fields": {"name": "Can change cms tags", "content_type": 19, "codename": "change_cmstags"}}, {"model": "auth.permission", "pk": 57, "fields": {"name": "Can delete cms tags", "content_type": 19, "codename": "delete_cmstags"}}, {"model": "auth.permission", "pk": 58, "fields": {"name": "Can add cms templates", "content_type": 20, "codename": "add_cmstemplates"}}, {"model": "auth.permission", "pk": 59, "fields": {"name": "Can change cms templates", "content_type": 20, "codename": "change_cmstemplates"}}, {"model": "auth.permission", "pk": 60, "fields": {"name": "Can delete cms templates", "content_type": 20, "codename": "delete_cmstemplates"}}, {"model": "auth.permission", "pk": 61, "fields": {"name": "Can add Token", "content_type": 21, "codename": "add_token"}}, {"model": "auth.permission", "pk": 62, "fields": {"name": "Can change Token", "content_type": 21, "codename": "change_token"}}, {"model": "auth.permission", "pk": 63, "fields": {"name": "Can delete Token", "content_type": 21, "codename": "delete_token"}}, {"model": "auth.user", "pk": 1, "fields": {"password": "pbkdf2_sha256$36000$ECa50G495KJT$Pm8J8O9rUjsG9mNnppscBiIj0YSItuDlTC2mrylOVcE=", "last_login": "2018-04-11T17:16:05.206Z", "is_superuser": true, "username": "admin", "first_name": "", "last_name": "", "email": "jnvilo@gmail.com", "is_staff": true, "is_active": true, "date_joined": "2016-04-09T21:34:41Z", "groups": [], "user_permissions": []}}, {"model": "auth.user", "pk": 2, "fields": {"password": "pbkdf2_sha256$36000$1EX0cSrFBt2k$yPT92xcEj0KzkAlR4HbD8ix7+FOEzwpqvaQ+kOmKmIE=", "last_login": "2018-04-05T13:39:36.843Z", "is_superuser": true, "username": "jason", "first_name": "", "last_name": "", "email": "jasonviloria@lnxystems.com", "is_staff": true, "is_active": true, "date_joined": "2018-03-08T13:19:01.773Z", "groups": [], "user_permissions": []}}, {"model": "auth.user", "pk": 3, "fields": {"password": "pbkdf2_sha256$36000$SXoNTgrpl5gX$PZvi7dgAfX4+KLjoqbCrm3S3oz5bnqUrzS7LL0eudZ8=", "last_login": null, "is_superuser": true, "username": "superuser", "first_name": "", "last_name": "", "email": "superusers@local.com", "is_staff": true, "is_active": true, "date_joined": "2018-04-06T21:11:56.554Z", "groups": [], "user_permissions": []}}, {"model": "auth.user", "pk": 4, "fields": {"password": "pbkdf2_sha256$36000$cgzhhTvA4qip$ffdbq5XasSZgSeJWfGTssuzkG7VnZpDSvA88p8tjo5w=", "last_login": null, "is_superuser": true, "username": "super1", "first_name": "", "last_name": "", "email": "super1@lo.com", "is_staff": true, "is_active": true, "date_joined": "2018-04-06T21:15:13.050Z", "groups": [], "user_permissions": []}}, {"model": "auth.user", "pk": 5, "fields": {"password": "pbkdf2_sha256$36000$34QcWdRdMICV$/82UYoEzXRVQ5Xg3pWk6iBTUYlplmXEl8DuZGtP17n0=", "last_login": null, "is_superuser": true, "username": "super23", "first_name": "", "last_name": "", "email": "s@l.com", "is_staff": true, "is_active": true, "date_joined": "2018-04-06T21:17:57.563Z", "groups": [], "user_permissions": []}}, {"model": "auth.user", "pk": 6, "fields": {"password": "pbkdf2_sha256$36000$ZnzWG971OmWR$9V/p5SXa46sXq8/a+FyWVijbEa1Fasxdw5EvmISd2Ag=", "last_login": null, "is_superuser": true, "username": "jas", "first_name": "", "last_name": "", "email": "jas@l.com", "is_staff": true, "is_active": true, "date_joined": "2018-04-06T21:28:26.459Z", "groups": [], "user_permissions": []}}, {"model": "mycms.cmsentries", "pk": 1, "fields": {"title": "Yet Another CMS.", "path": 1, "slug": "", "date_created": "2016-04-09T21:34:59.770Z", "date_modified": "2016-04-09T21:34:59.771Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": []}}, {"model": "mycms.cmsentries", "pk": 2, "fields": {"title": "SysAdmin/DevOps", "path": 2, "slug": "sysadmindevops", "date_created": "2016-04-09T21:36:00.952Z", "date_modified": "2016-04-09T21:36:00.952Z", "page_type": 2, "template": null, "frontpage": false, "published": true, "page_number": 1, "created_by": 1, "content": [1]}}, {"model": "mycms.cmsentries", "pk": 3, "fields": {"title": "Programming", "path": 3, "slug": "programming", "date_created": "2016-04-09T21:36:11.413Z", "date_modified": "2016-04-09T21:36:11.413Z", "page_type": 2, "template": null, "frontpage": false, "published": true, "page_number": 1, "created_by": 1, "content": [2]}}, {"model": "mycms.cmsentries", "pk": 4, "fields": {"title": "Blogs", "path": 4, "slug": "blogs", "date_created": "2016-04-09T21:36:19.812Z", "date_modified": "2016-04-09T21:36:19.812Z", "page_type": 2, "template": null, "frontpage": false, "published": true, "page_number": 1, "created_by": 1, "content": [3]}}, {"model": "mycms.cmsentries", "pk": 5, "fields": {"title": "Linux", "path": 5, "slug": "linux", "date_created": "2016-04-09T21:36:42.208Z", "date_modified": "2016-04-09T21:36:42.208Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [4]}}, {"model": "mycms.cmsentries", "pk": 6, "fields": {"title": "About", "path": 6, "slug": "about", "date_created": "2016-04-09T21:37:28.083Z", "date_modified": "2016-04-09T21:37:28.083Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [5]}}, {"model": "mycms.cmsentries", "pk": 7, "fields": {"title": "LVM Resources", "path": 7, "slug": "lvm-resources", "date_created": "2016-04-09T21:39:37.670Z", "date_modified": "2016-04-09T21:39:37.670Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [6]}}, {"model": "mycms.cmsentries", "pk": 8, "fields": {"title": "Create a new LVM partition on an extra disk", "path": 8, "slug": "create-a-new-lvm-partition-on-an-extra-disk", "date_created": "2014-12-16T13:00:00Z", "date_modified": "2014-12-16T13:00:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [7]}}, {"model": "mycms.cmsentries", "pk": 9, "fields": {"title": "Top Ten Linux Commands To Check Hardware Information On Linux", "path": 9, "slug": "top-ten-linux-commands-to-check-hardware-information-on-linux", "date_created": "2015-02-06T20:13:00Z", "date_modified": "2015-02-06T20:13:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [8]}}, {"model": "mycms.cmsentries", "pk": 10, "fields": {"title": "How to create an init script for Redhat or Centos or Fedora", "path": 10, "slug": "how-to-create-an-init-script-for-redhat-or-centos-or-fedora", "date_created": "2014-12-19T21:47:00Z", "date_modified": "2014-12-19T21:47:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [9]}}, {"model": "mycms.cmsentries", "pk": 11, "fields": {"title": "Label a Linux Partition", "path": 11, "slug": "label-a-linux-partition", "date_created": "2014-12-16T21:49:00Z", "date_modified": "2014-12-16T21:49:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [10]}}, {"model": "mycms.cmsentries", "pk": 12, "fields": {"title": "How-To: Recover Root Password Under CentOS With Single User Mode", "path": 12, "slug": "how-to-recover-root-password-under-centos-with-single-user-mode", "date_created": "2012-05-09T19:00:00Z", "date_modified": "2012-05-09T19:00:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [11]}}, {"model": "mycms.cmsentries", "pk": 13, "fields": {"title": "How To Setup Crontab Under Linux Or Unix", "path": 13, "slug": "how-to-setup-crontab-under-linux-or-unix", "date_created": "2010-02-09T21:00:00Z", "date_modified": "2010-02-09T21:00:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [12]}}, {"model": "mycms.cmsentries", "pk": 14, "fields": {"title": "How To Check Swap Usage On Linux", "path": 14, "slug": "how-to-check-swap-usage-on-linux", "date_created": "2008-04-11T19:00:00Z", "date_modified": "2009-12-09T22:00:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [13]}}, {"model": "mycms.cmsentries", "pk": 15, "fields": {"title": "How to list all hidden files in a directory recursively", "path": 15, "slug": "how-to-list-all-hidden-files-in-a-directory-recursively", "date_created": "2009-10-01T10:10:00Z", "date_modified": "2009-10-01T10:10:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [14]}}, {"model": "mycms.cmsentries", "pk": 16, "fields": {"title": "RHEL", "path": 16, "slug": "rhel", "date_created": "2016-04-09T22:28:32.527Z", "date_modified": "2016-04-09T22:28:32.527Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [15]}}, {"model": "mycms.cmsentries", "pk": 17, "fields": {"title": "HowTo: Change, Add, Remove LUKS passphrases", "path": 17, "slug": "howto-change-add-remove-luks-passphrases", "date_created": "2014-12-16T15:12:00Z", "date_modified": "2014-12-16T15:12:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [16]}}, {"model": "mycms.cmsentries", "pk": 18, "fields": {"title": "HowTo: Configure LUKS on CentOS / RHEL", "path": 18, "slug": "howto-configure-luks-on-centos-rhel", "date_created": "2014-12-16T14:19:00Z", "date_modified": "2014-12-16T14:19:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [17]}}, {"model": "mycms.cmsentries", "pk": 19, "fields": {"title": "Mail Server Administration", "path": 19, "slug": "mail-server-administration", "date_created": "2016-04-09T22:33:29.063Z", "date_modified": "2016-04-09T22:33:29.063Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [18]}}, {"model": "mycms.cmsentries", "pk": 20, "fields": {"title": "Postfix Store and Foreward Howto With Anti-Spam Configuration", "path": 20, "slug": "postfix-store-and-foreward-howto-with-anti-spam-configuration", "date_created": "2015-02-27T22:33:00Z", "date_modified": "2015-02-27T22:33:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [19]}}, {"model": "mycms.cmsentries", "pk": 21, "fields": {"title": "SystemD", "path": 21, "slug": "systemd", "date_created": "2016-04-09T22:36:00.627Z", "date_modified": "2016-04-09T22:36:00.627Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [20]}}, {"model": "mycms.cmsentries", "pk": 22, "fields": {"title": "Switch from NetworkManager to systemd-networkd on Linux", "path": 22, "slug": "switch-from-networkmanager-to-systemd-networkd-on-linux", "date_created": "2016-02-09T22:36:00Z", "date_modified": "2016-02-09T22:36:00Z", "page_type": 1, "template": null, "frontpage": true, "published": false, "page_number": 1, "created_by": 1, "content": [21]}}, {"model": "mycms.cmsentries", "pk": 23, "fields": {"title": "OS X", "path": 23, "slug": "os-x", "date_created": "2016-04-09T22:38:28.544Z", "date_modified": "2016-04-09T22:38:28.544Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [22]}}, {"model": "mycms.cmsentries", "pk": 24, "fields": {"title": "Installing Nginx And PHP on OS X", "path": 24, "slug": "installing-nginx-and-php-on-os-x", "date_created": "2012-08-22T10:00:00Z", "date_modified": "2012-08-22T10:00:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [23]}}, {"model": "mycms.cmsentries", "pk": 25, "fields": {"title": "Install Node.js and npm using Homebrew on OS X", "path": 25, "slug": "install-nodejs-and-npm-using-homebrew-on-os-x", "date_created": "2015-02-06T21:17:00Z", "date_modified": "2015-02-06T21:17:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [24]}}, {"model": "mycms.cmsentries", "pk": 26, "fields": {"title": "Bash", "path": 26, "slug": "bash", "date_created": "2016-04-10T10:11:21.592Z", "date_modified": "2016-04-10T10:11:21.592Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [25]}}, {"model": "mycms.cmsentries", "pk": 27, "fields": {"title": "Javascript", "path": 27, "slug": "javascript", "date_created": "2016-04-10T10:11:33.345Z", "date_modified": "2016-04-10T10:11:33.345Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [26]}}, {"model": "mycms.cmsentries", "pk": 28, "fields": {"title": "Python", "path": 28, "slug": "python", "date_created": "2016-04-10T10:11:44.431Z", "date_modified": "2016-04-10T10:11:44.431Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [27]}}, {"model": "mycms.cmsentries", "pk": 29, "fields": {"title": "Programming in Python", "path": 29, "slug": "programming-in-python", "date_created": "2016-04-10T10:12:16.243Z", "date_modified": "2016-04-10T10:12:16.243Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [28]}}, {"model": "mycms.cmsentries", "pk": 30, "fields": {"title": "Python HowTo's", "path": 30, "slug": "python-howtos", "date_created": "2016-04-10T10:12:28.418Z", "date_modified": "2016-04-10T10:12:28.418Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [29]}}, {"model": "mycms.cmsentries", "pk": 31, "fields": {"title": "Git", "path": 31, "slug": "git", "date_created": "2016-04-10T10:13:17.261Z", "date_modified": "2016-04-10T10:13:17.261Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [30]}}, {"model": "mycms.cmsentries", "pk": 32, "fields": {"title": "Create and Manage Git Branches", "path": 32, "slug": "create-and-manage-git-branches", "date_created": "2015-02-28T20:17:00Z", "date_modified": "2015-02-28T20:17:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [31]}}, {"model": "mycms.cmsentries", "pk": 33, "fields": {"title": "RHCSA 7 Exam Guide", "path": 33, "slug": "rhcsa-7-exam-guide", "date_created": "2016-04-11T09:54:31.931Z", "date_modified": "2016-04-11T09:54:31.931Z", "page_type": 3, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [32]}}, {"model": "mycms.cmsentries", "pk": 34, "fields": {"title": "Understand and use essential tools", "path": 34, "slug": "understand-and-use-essential-tools", "date_created": "2016-04-12T10:09:31.422Z", "date_modified": "2016-04-12T10:09:31.422Z", "page_type": 4, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [33]}}, {"model": "mycms.cmsentries", "pk": 36, "fields": {"title": "Python Design Patterns", "path": 36, "slug": "python-design-patterns", "date_created": "2016-04-12T10:13:49.887Z", "date_modified": "2016-04-12T10:13:49.887Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [35]}}, {"model": "mycms.cmsentries", "pk": 37, "fields": {"title": "Publish Subscribe Pattern", "path": 37, "slug": "publish-subscribe-pattern", "date_created": "2016-04-12T10:15:07.517Z", "date_modified": "2016-04-12T10:15:07.517Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [36]}}, {"model": "mycms.cmsentries", "pk": 38, "fields": {"title": "Observer Pattern", "path": 38, "slug": "observer-pattern", "date_created": "2016-04-12T10:17:55.000Z", "date_modified": "2016-04-12T10:17:55.000Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [37]}}, {"model": "mycms.cmsentries", "pk": 39, "fields": {"title": "Operate Running Systems", "path": 39, "slug": "operate-running-systems", "date_created": "2016-04-15T09:58:58.918Z", "date_modified": "2016-04-15T09:58:58.918Z", "page_type": 4, "template": null, "frontpage": false, "published": false, "page_number": 3, "created_by": 1, "content": [38]}}, {"model": "mycms.cmsentries", "pk": 40, "fields": {"title": "Configure local storage", "path": 40, "slug": "configure-local-storage", "date_created": "2016-04-15T10:01:09.635Z", "date_modified": "2016-04-15T10:01:09.636Z", "page_type": 4, "template": null, "frontpage": false, "published": false, "page_number": 5, "created_by": 1, "content": [39]}}, {"model": "mycms.cmsentries", "pk": 41, "fields": {"title": "Create and configure file systems", "path": 41, "slug": "create-and-configure-file-systems", "date_created": "2016-04-15T10:01:20.443Z", "date_modified": "2016-04-15T10:01:20.443Z", "page_type": 4, "template": null, "frontpage": false, "published": false, "page_number": 7, "created_by": 1, "content": [40]}}, {"model": "mycms.cmsentries", "pk": 42, "fields": {"title": "Deploy, configure, and maintain systems", "path": 42, "slug": "deploy-configure-and-maintain-systems", "date_created": "2016-04-15T10:01:29.827Z", "date_modified": "2016-04-15T10:01:29.827Z", "page_type": 4, "template": null, "frontpage": false, "published": false, "page_number": 9, "created_by": 1, "content": [41]}}, {"model": "mycms.cmsentries", "pk": 43, "fields": {"title": "Manage users and groups", "path": 43, "slug": "manage-users-and-groups", "date_created": "2016-04-15T10:01:39.625Z", "date_modified": "2016-04-15T10:01:39.626Z", "page_type": 4, "template": null, "frontpage": false, "published": false, "page_number": 11, "created_by": 1, "content": [42]}}, {"model": "mycms.cmsentries", "pk": 44, "fields": {"title": "The Singleton Design Pattern", "path": 44, "slug": "the-singleton-design-pattern", "date_created": "2016-04-15T10:10:52.727Z", "date_modified": "2016-04-15T10:10:52.727Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [43]}}, {"model": "mycms.cmsentries", "pk": 45, "fields": {"title": "RHCSA 7 Exam Objective Tutorials", "path": 45, "slug": "rhcsa-7-exam-objective-tutorials", "date_created": "2016-04-18T09:31:27.584Z", "date_modified": "2016-04-18T09:31:27.584Z", "page_type": 2, "template": null, "frontpage": false, "published": true, "page_number": 1, "created_by": 1, "content": [44]}}, {"model": "mycms.cmsentries", "pk": 46, "fields": {"title": "Archiving", "path": 46, "slug": "archiving", "date_created": "2016-04-18T09:32:56.267Z", "date_modified": "2016-04-18T09:32:56.267Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [45]}}, {"model": "mycms.cmsentries", "pk": 47, "fields": {"title": "A Close Look At The Systemd Boot Process ", "path": 47, "slug": "a-close-look-at-the-systemd-boot-process", "date_created": "2016-04-18T09:42:49.436Z", "date_modified": "2016-04-18T09:42:49.436Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [46]}}, {"model": "mycms.cmsentries", "pk": 48, "fields": {"title": "Puppet CookBook", "path": 48, "slug": "puppet-cookbook", "date_created": "2016-04-24T18:16:57.521Z", "date_modified": "2016-04-24T18:16:57.522Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [47]}}, {"model": "mycms.cmsentries", "pk": 49, "fields": {"title": "Puppet apply a local manifest or  module", "path": 49, "slug": "puppet-apply-a-local-manifest-or-module", "date_created": "2016-04-24T18:20:09.914Z", "date_modified": "2016-04-24T18:20:09.914Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [48]}}, {"model": "mycms.cmsentries", "pk": 50, "fields": {"title": "DNS Servers", "path": 50, "slug": "dns-servers", "date_created": "2016-04-25T12:54:10.406Z", "date_modified": "2016-04-25T12:54:10.406Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [49]}}, {"model": "mycms.cmsentries", "pk": 51, "fields": {"title": "How to configure Bind for your internal network", "path": 51, "slug": "how-to-configure-bind-for-your-internal-network", "date_created": "2015-10-19T17:00:00Z", "date_modified": "2015-10-19T17:00:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [50]}}, {"model": "mycms.cmsentries", "pk": 52, "fields": {"title": "Linux  ACLs - Access Control Lists", "path": 52, "slug": "linux-acls-access-control-lists", "date_created": "2016-04-27T14:50:28.666Z", "date_modified": "2016-04-27T14:50:28.666Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [51]}}, {"model": "mycms.cmsentries", "pk": 53, "fields": {"title": "Logging User Actions with Audit", "path": 53, "slug": "logging-user-actions-with-audit", "date_created": "2016-04-28T14:51:40.071Z", "date_modified": "2016-04-28T14:51:40.071Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [52]}}, {"model": "mycms.cmsentries", "pk": 54, "fields": {"title": "How To Change Timezone on a CentOS 6 and 7", "path": 54, "slug": "how-to-change-timezone-on-a-centos-6-and-7", "date_created": "2015-07-15T19:00:00Z", "date_modified": "2015-07-15T19:00:00Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [53]}}, {"model": "mycms.cmsentries", "pk": 55, "fields": {"title": "Scheduling jobs with Cron ", "path": 55, "slug": "scheduling-jobs-with-cron", "date_created": "2016-04-30T23:19:31.755Z", "date_modified": "2016-04-30T23:19:31.755Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [54]}}, {"model": "mycms.cmsentries", "pk": 56, "fields": {"title": "Install Vagrant on OSX 10.11 El Capitan", "path": 56, "slug": "install-vagrant-on-osx-1011-el-capitan", "date_created": "2016-05-01T20:43:37.132Z", "date_modified": "2016-05-01T20:43:37.132Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [55]}}, {"model": "mycms.cmsentries", "pk": 57, "fields": {"title": "How To Use SSH Config File For Multiple SSH Keys", "path": 57, "slug": "how-to-use-ssh-config-file-for-multiple-ssh-keys", "date_created": "2016-05-06T13:06:21.419Z", "date_modified": "2016-05-06T13:06:21.419Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [56]}}, {"model": "mycms.cmsentries", "pk": 58, "fields": {"title": "Databases", "path": 58, "slug": "databases", "date_created": "2017-02-28T13:38:56.258Z", "date_modified": "2017-02-28T13:38:56.258Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [57]}}, {"model": "mycms.cmsentries", "pk": 59, "fields": {"title": "Postgresql", "path": 59, "slug": "postgresql", "date_created": "2017-02-28T13:39:24.652Z", "date_modified": "2017-02-28T13:39:24.652Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [58]}}, {"model": "mycms.cmsentries", "pk": 60, "fields": {"title": "Install phpPgAdmin on CentOS 7", "path": 60, "slug": "install-phppgadmin-on-centos-7", "date_created": "2017-02-28T13:40:00.051Z", "date_modified": "2017-02-28T13:40:00.052Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [59]}}, {"model": "mycms.cmsentries", "pk": 61, "fields": {"title": "Install Postgresql On Centos 6.5 Via-Yum", "path": 61, "slug": "install-postgresql-on-centos-65-via-yum", "date_created": "2017-02-28T13:43:04.178Z", "date_modified": "2017-02-28T13:43:04.178Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [60]}}, {"model": "mycms.cmsentries", "pk": 62, "fields": {"title": "Howto Backup and Restore your PostgreSQL databases", "path": 62, "slug": "howto-backup-and-restore-your-postgresql-databases", "date_created": "2017-02-28T13:44:06.793Z", "date_modified": "2017-02-28T13:44:06.793Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [61]}}, {"model": "mycms.cmsentries", "pk": 63, "fields": {"title": "Virtualisation", "path": 63, "slug": "virtualisation", "date_created": "2017-03-21T20:28:48.856Z", "date_modified": "2017-03-21T20:28:48.856Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [62]}}, {"model": "mycms.cmsentries", "pk": 64, "fields": {"title": "Virtualization", "path": 64, "slug": "virtualization", "date_created": "2017-03-21T20:29:26.658Z", "date_modified": "2017-03-21T20:29:26.658Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [63]}}, {"model": "mycms.cmsentries", "pk": 65, "fields": {"title": "VMware", "path": 65, "slug": "vmware", "date_created": "2017-03-21T20:30:29.422Z", "date_modified": "2017-03-21T20:30:29.422Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [64]}}, {"model": "mycms.cmsentries", "pk": 66, "fields": {"title": "KVM", "path": 66, "slug": "kvm", "date_created": "2017-03-21T20:31:18.624Z", "date_modified": "2017-03-21T20:31:18.624Z", "page_type": 2, "template": null, "frontpage": false, "published": true, "page_number": 1, "created_by": 1, "content": [65]}}, {"model": "mycms.cmsentries", "pk": 67, "fields": {"title": "Install VMware on ESXi in KVM", "path": 67, "slug": "install-vmware-on-esxi-in-kvm", "date_created": "2017-03-21T20:34:16.577Z", "date_modified": "2017-03-21T20:34:16.577Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [66]}}, {"model": "mycms.cmsentries", "pk": 68, "fields": {"title": "Add extra space to KVM Guest root partition", "path": 68, "slug": "add-extra-space-to-kvm-guest-root-partition", "date_created": "2017-03-21T21:37:29.544Z", "date_modified": "2017-03-21T21:37:29.544Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [67]}}, {"model": "mycms.cmsentries", "pk": 69, "fields": {"title": "Install KVM guest using command line", "path": 69, "slug": "install-kvm-guest-using-command-line", "date_created": "2017-03-21T21:38:35.161Z", "date_modified": "2017-03-21T21:38:35.161Z", "page_type": 1, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [68]}}, {"model": "mycms.cmsentries", "pk": 70, "fields": {"title": "Underscores in Python", "path": 70, "slug": "underscores-in-python", "date_created": "2017-03-22T07:30:00.533Z", "date_modified": "2017-03-22T07:30:00.533Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [69]}}, {"model": "mycms.cmsentries", "pk": 71, "fields": {"title": "Signals and Slots Implementation In Python", "path": 71, "slug": "signals-and-slots-implementation-in-python", "date_created": "2017-03-22T07:30:57.580Z", "date_modified": "2017-03-22T07:30:57.580Z", "page_type": 1, "template": null, "frontpage": true, "published": true, "page_number": 1, "created_by": 1, "content": [70]}}, {"model": "mycms.cmsentries", "pk": 72, "fields": {"title": "Ramblings and Stupid Things And Whatever", "path": 72, "slug": "ramblings-and-stupid-things-and-whatever", "date_created": "2017-09-20T09:13:50.136Z", "date_modified": "2017-09-20T09:13:50.136Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [71]}}, {"model": "mycms.cmsentries", "pk": 73, "fields": {"title": "Tech Stuff", "path": 73, "slug": "tech-stuff", "date_created": "2017-09-20T09:14:45.190Z", "date_modified": "2017-09-20T09:14:45.190Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [72]}}, {"model": "mycms.cmsentries", "pk": 103, "fields": {"title": "Adding A Test", "path": 97, "slug": "adding-a-test", "date_created": "2018-03-28T15:34:54.856Z", "date_modified": "2018-03-28T15:34:54.857Z", "page_type": 2, "template": null, "frontpage": false, "published": false, "page_number": 1, "created_by": 1, "content": [92]}}, {"model": "authtoken.token", "pk": "73170a913804452cec913e702b68dd34a69431bb", "fields": {"user": 6, "created": "2018-04-06T21:28:26.494Z"}}, {"model": "authtoken.token", "pk": "93c5cefef4568959aa7bdbe029df158f5b89d141", "fields": {"user": 1, "created": "2018-04-06T21:31:28.780Z"}}, {"model": "authtoken.token", "pk": "9d7a5e6964295f4e7f81166f0ef01e294422c4f0", "fields": {"user": 2, "created": "2018-04-06T21:31:23.784Z"}}, {"model": "authtoken.token", "pk": "f62a90dba10b82794b13167a59fd9b02c4866479", "fields": {"user": 5, "created": "2018-04-06T21:17:57.602Z"}}, {"model": "admin.logentry", "pk": 1, "fields": {"action_time": "2016-04-09T21:55:37.530Z", "user": 1, "content_type": 13, "object_id": "12", "object_repr": "How-To: Recover Root Password Under CentOS With Single User Mode Home / SysAdmin/DevOps/ Linux/", "action_flag": 2, "change_message": "Changed slug."}}, {"model": "admin.logentry", "pk": 2, "fields": {"action_time": "2016-04-09T21:55:48.661Z", "user": 1, "content_type": 13, "object_id": "12", "object_repr": "How-To: Recover Root Password Under CentOS With Single User Mode Home / SysAdmin/DevOps/ Linux/", "action_flag": 2, "change_message": "No fields changed."}}, {"model": "admin.logentry", "pk": 3, "fields": {"action_time": "2016-04-09T21:56:08.111Z", "user": 1, "content_type": 13, "object_id": "12", "object_repr": "How-To: Recover Root Password Under CentOS With Single User Mode Home", "action_flag": 2, "change_message": "Changed title."}}, {"model": "admin.logentry", "pk": 4, "fields": {"action_time": "2016-04-09T21:56:27.739Z", "user": 1, "content_type": 13, "object_id": "12", "object_repr": "How-To: Recover Root Password Under CentOS With Single User Mode", "action_flag": 2, "change_message": "Changed title."}}, {"model": "admin.logentry", "pk": 5, "fields": {"action_time": "2016-04-09T21:56:53.946Z", "user": 1, "content_type": 7, "object_id": "12", "object_repr": "/sysadmin/linux/how-to-recover-root-password-under-centos-with-single-user", "action_flag": 2, "change_message": "Changed path."}}, {"model": "admin.logentry", "pk": 6, "fields": {"action_time": "2016-04-09T21:57:09.404Z", "user": 1, "content_type": 7, "object_id": "12", "object_repr": "/sysadmin/linux/how-to-recover-root-password-under-centos-with-single-user-mode", "action_flag": 2, "change_message": "Changed path."}}, {"model": "admin.logentry", "pk": 7, "fields": {"action_time": "2016-04-18T09:57:19.277Z", "user": 1, "content_type": 7, "object_id": "47", "object_repr": "/sysadmin/linux/a-close-look-at-the-systemd-boot-process", "action_flag": 2, "change_message": "Changed path."}}, {"model": "admin.logentry", "pk": 8, "fields": {"action_time": "2016-04-22T18:42:14.189Z", "user": 1, "content_type": 7, "object_id": "44", "object_repr": "/programming/python/python-design-patterns/the-singleton-design-pattern", "action_flag": 2, "change_message": "Changed path and parent."}}, {"model": "admin.logentry", "pk": 9, "fields": {"action_time": "2016-04-25T08:33:01.652Z", "user": 1, "content_type": 7, "object_id": "35", "object_repr": "/programming/python/python-patterns", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 10, "fields": {"action_time": "2017-03-21T20:32:38.893Z", "user": 1, "content_type": 13, "object_id": "66", "object_repr": "KVM", "action_flag": 2, "change_message": "Changed page_type and published."}}, {"model": "admin.logentry", "pk": 11, "fields": {"action_time": "2017-09-19T13:46:40.039Z", "user": 1, "content_type": 13, "object_id": "3", "object_repr": "Programming", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"published\"]}}]"}}, {"model": "admin.logentry", "pk": 12, "fields": {"action_time": "2017-09-19T13:46:50.044Z", "user": 1, "content_type": 13, "object_id": "2", "object_repr": "SysAdmin/DevOps", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"published\"]}}]"}}, {"model": "admin.logentry", "pk": 13, "fields": {"action_time": "2017-09-19T13:47:04.974Z", "user": 1, "content_type": 13, "object_id": "4", "object_repr": "Blogs", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"published\"]}}]"}}, {"model": "admin.logentry", "pk": 14, "fields": {"action_time": "2018-03-13T17:46:04.752Z", "user": 2, "content_type": 9, "object_id": "1", "object_repr": "Creole", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 15, "fields": {"action_time": "2018-03-26T18:45:24.486Z", "user": 2, "content_type": 11, "object_id": "1", "object_repr": "page.html", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 16, "fields": {"action_time": "2018-03-27T07:25:00.248Z", "user": 2, "content_type": 11, "object_id": "1", "object_repr": "page.html", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 17, "fields": {"action_time": "2018-03-27T07:26:30.078Z", "user": 2, "content_type": 13, "object_id": "80", "object_repr": "A New Dir", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"template\"]}}]"}}, {"model": "admin.logentry", "pk": 18, "fields": {"action_time": "2018-03-27T07:29:22.895Z", "user": 2, "content_type": 13, "object_id": "80", "object_repr": "A New Dir", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 19, "fields": {"action_time": "2018-03-27T08:53:47.218Z", "user": 2, "content_type": 13, "object_id": "100", "object_repr": "A New Category 1", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"frontpage\", \"published\"]}}]"}}, {"model": "admin.logentry", "pk": 20, "fields": {"action_time": "2018-03-27T09:48:13.759Z", "user": 2, "content_type": 13, "object_id": "102", "object_repr": "And here we have an", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 21, "fields": {"action_time": "2018-03-27T09:48:13.768Z", "user": 2, "content_type": 13, "object_id": "101", "object_repr": "This is a sub sub sub Category", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 22, "fields": {"action_time": "2018-03-27T09:48:13.778Z", "user": 2, "content_type": 13, "object_id": "100", "object_repr": "A New Category 1", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 23, "fields": {"action_time": "2018-03-27T09:48:13.786Z", "user": 2, "content_type": 13, "object_id": "99", "object_repr": "Category2", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 24, "fields": {"action_time": "2018-03-27T09:48:13.803Z", "user": 2, "content_type": 13, "object_id": "98", "object_repr": "Category1", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 25, "fields": {"action_time": "2018-03-27T09:48:13.817Z", "user": 2, "content_type": 13, "object_id": "97", "object_repr": "HTML2", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 26, "fields": {"action_time": "2018-03-27T09:48:13.831Z", "user": 2, "content_type": 13, "object_id": "96", "object_repr": "HTML1", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 27, "fields": {"action_time": "2018-03-27T09:48:13.846Z", "user": 2, "content_type": 13, "object_id": "95", "object_repr": "Title For Child", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 28, "fields": {"action_time": "2018-03-27T09:48:13.860Z", "user": 2, "content_type": 13, "object_id": "94", "object_repr": "Adding A Category", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 29, "fields": {"action_time": "2018-03-27T09:48:13.875Z", "user": 2, "content_type": 13, "object_id": "93", "object_repr": "An yet another one too", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 30, "fields": {"action_time": "2018-03-27T09:48:13.888Z", "user": 2, "content_type": 13, "object_id": "92", "object_repr": "This is another article", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 31, "fields": {"action_time": "2018-03-27T09:48:13.900Z", "user": 2, "content_type": 13, "object_id": "91", "object_repr": "This is an article", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 32, "fields": {"action_time": "2018-03-27T09:48:13.911Z", "user": 2, "content_type": 13, "object_id": "90", "object_repr": "OK This is the last Category2", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 33, "fields": {"action_time": "2018-03-27T09:48:13.920Z", "user": 2, "content_type": 13, "object_id": "89", "object_repr": "OK This is the last Category", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 34, "fields": {"action_time": "2018-03-27T09:48:13.930Z", "user": 2, "content_type": 13, "object_id": "88", "object_repr": "Finally this will work for Category 2", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 35, "fields": {"action_time": "2018-03-27T09:48:13.939Z", "user": 2, "content_type": 13, "object_id": "87", "object_repr": "Finally this will work for Category", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 36, "fields": {"action_time": "2018-03-27T09:48:13.948Z", "user": 2, "content_type": 13, "object_id": "86", "object_repr": "Title For a 34", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 37, "fields": {"action_time": "2018-03-27T09:48:13.958Z", "user": 2, "content_type": 13, "object_id": "85", "object_repr": "Title For a 3", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 38, "fields": {"action_time": "2018-03-27T09:48:13.967Z", "user": 2, "content_type": 13, "object_id": "84", "object_repr": "Title For a Category234", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 39, "fields": {"action_time": "2018-03-27T09:48:13.976Z", "user": 2, "content_type": 13, "object_id": "83", "object_repr": "Title For a Category23", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 40, "fields": {"action_time": "2018-03-27T09:48:13.987Z", "user": 2, "content_type": 13, "object_id": "82", "object_repr": "Title For a Category", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 41, "fields": {"action_time": "2018-03-27T09:48:13.997Z", "user": 2, "content_type": 13, "object_id": "81", "object_repr": "A New Dir2", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 42, "fields": {"action_time": "2018-03-27T09:48:14.006Z", "user": 2, "content_type": 13, "object_id": "79", "object_repr": "Sooner or later he is going to call.22", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 43, "fields": {"action_time": "2018-03-27T09:48:14.015Z", "user": 2, "content_type": 13, "object_id": "78", "object_repr": "Sooner or later he is going to call.22", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 44, "fields": {"action_time": "2018-03-27T09:48:14.024Z", "user": 2, "content_type": 13, "object_id": "77", "object_repr": "Sooner or later he is going to call.", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 45, "fields": {"action_time": "2018-03-27T09:48:14.034Z", "user": 2, "content_type": 13, "object_id": "76", "object_repr": "The title of the page is a huge problem", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 46, "fields": {"action_time": "2018-03-27T09:48:14.045Z", "user": 2, "content_type": 13, "object_id": "75", "object_repr": "Test Title2", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 47, "fields": {"action_time": "2018-03-27T09:48:14.055Z", "user": 2, "content_type": 13, "object_id": "74", "object_repr": "Test Title", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 48, "fields": {"action_time": "2018-03-27T09:49:11.980Z", "user": 2, "content_type": 7, "object_id": "96", "object_repr": "/sysadmin/a-new-dir/adding-a-category/and-here-we-have-an", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 49, "fields": {"action_time": "2018-03-27T09:49:11.996Z", "user": 2, "content_type": 7, "object_id": "95", "object_repr": "/sysadmin/a-new-dir/adding-a-category/this-is-a-sub-sub-sub-category", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 50, "fields": {"action_time": "2018-03-27T09:49:12.006Z", "user": 2, "content_type": 7, "object_id": "94", "object_repr": "/sysadmin/a-new-dir/a-new-category-1", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 51, "fields": {"action_time": "2018-03-27T09:49:12.016Z", "user": 2, "content_type": 7, "object_id": "93", "object_repr": "/sysadmin/a-new-dir/category2", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 52, "fields": {"action_time": "2018-03-27T09:49:12.024Z", "user": 2, "content_type": 7, "object_id": "92", "object_repr": "/sysadmin/a-new-dir/category1", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 53, "fields": {"action_time": "2018-03-27T09:49:12.033Z", "user": 2, "content_type": 7, "object_id": "91", "object_repr": "/sysadmin/a-new-dir/html2", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 54, "fields": {"action_time": "2018-03-27T09:49:12.042Z", "user": 2, "content_type": 7, "object_id": "90", "object_repr": "/sysadmin/a-new-dir/html1", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 55, "fields": {"action_time": "2018-03-27T09:49:12.051Z", "user": 2, "content_type": 7, "object_id": "89", "object_repr": "/sysadmin/a-new-dir/title-for-child", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 56, "fields": {"action_time": "2018-03-27T09:49:12.059Z", "user": 2, "content_type": 7, "object_id": "88", "object_repr": "/sysadmin/a-new-dir/adding-a-category", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 57, "fields": {"action_time": "2018-03-27T09:49:12.067Z", "user": 2, "content_type": 7, "object_id": "87", "object_repr": "/sysadmin/a-new-dir/ok-this-is-the-last-category2/an-yet-another-one-too", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 58, "fields": {"action_time": "2018-03-27T09:49:12.076Z", "user": 2, "content_type": 7, "object_id": "86", "object_repr": "/sysadmin/a-new-dir/ok-this-is-the-last-category2/this-is-another-article", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 59, "fields": {"action_time": "2018-03-27T09:49:12.085Z", "user": 2, "content_type": 7, "object_id": "85", "object_repr": "/sysadmin/a-new-dir/ok-this-is-the-last-category2/this-is-an-article", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 60, "fields": {"action_time": "2018-03-27T09:49:12.093Z", "user": 2, "content_type": 7, "object_id": "84", "object_repr": "/sysadmin/a-new-dir/ok-this-is-the-last-category2", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 61, "fields": {"action_time": "2018-03-27T09:49:12.110Z", "user": 2, "content_type": 7, "object_id": "83", "object_repr": "/sysadmin/a-new-dir/ok-this-is-the-last-category", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 62, "fields": {"action_time": "2018-03-27T09:49:12.120Z", "user": 2, "content_type": 7, "object_id": "82", "object_repr": "/sysadmin/a-new-dir/finally-this-will-work-for-category-2", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 63, "fields": {"action_time": "2018-03-27T09:49:12.129Z", "user": 2, "content_type": 7, "object_id": "81", "object_repr": "/sysadmin/a-new-dir/finally-this-will-work-for-category", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 64, "fields": {"action_time": "2018-03-27T09:49:12.139Z", "user": 2, "content_type": 7, "object_id": "80", "object_repr": "/sysadmin/a-new-dir/title-for-a-34", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 65, "fields": {"action_time": "2018-03-27T09:49:12.148Z", "user": 2, "content_type": 7, "object_id": "79", "object_repr": "/sysadmin/a-new-dir/title-for-a-3", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 66, "fields": {"action_time": "2018-03-27T09:49:12.158Z", "user": 2, "content_type": 7, "object_id": "78", "object_repr": "/sysadmin/a-new-dir/title-for-a-category234", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 67, "fields": {"action_time": "2018-03-27T09:49:12.167Z", "user": 2, "content_type": 7, "object_id": "77", "object_repr": "/sysadmin/a-new-dir/title-for-a-category23", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 68, "fields": {"action_time": "2018-03-27T09:49:12.177Z", "user": 2, "content_type": 7, "object_id": "76", "object_repr": "/sysadmin/a-new-dir/title-for-a-category", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 69, "fields": {"action_time": "2018-03-27T09:49:12.187Z", "user": 2, "content_type": 7, "object_id": "75", "object_repr": "/sysadmin/a-new-dir", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 70, "fields": {"action_time": "2018-04-06T21:18:28.370Z", "user": 2, "content_type": 4, "object_id": "1", "object_repr": "admin", "action_flag": 2, "change_message": "[]"}}]